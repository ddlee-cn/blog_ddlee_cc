{"pages":[{"title":"关于","text":"呦呦鹿鸣，食野之苹。我有嘉宾，鼓瑟吹笙。 我鼓励信息的流动、交换与分享，我期待思想的交流、碰撞与融合。 我倡导多样的视角、自洽的理由和真诚的态度，我推崇健壮、自信地生活。 我相信人人有自主的品味、有独立的判断，在沟通、讨论和筛选中，理解会建立，如果足够幸运，共识会达成。 关于博客博客叫萧爽楼，取自《浮生六记》。主要是对自己学习、思考内容的记录，关注计算机视觉、泛互联网、个人管理等话题，您可以查看标签云了解更多。 本人学历尚浅，文章中有不实和不当之处，还请批评斧正。如果您想定期获得博客文章的更新，请通过RSS订阅或使用邮箱订阅东东月报。 2019年2月14日起，本博客已通过审核并加入项目十年之约。 关于我现居上海。在为成为一流的研究者作准备。 联系我的最佳方式是邮箱me[at]ddlee[dot]cc和Telegram，我鼓励您使用这两种方式跟我沟通交流。 个人主页：ddlee.cc 我的其他博客： ddlee每周分享：每周推送我认为值得分享的信息 从前慢：随笔和小说收纳处 格物志：致力于以简单、精准的语言解释事物 此页面版本：2018.10其他版本：2016.07","link":"/about/index.html"},{"title":"关于","text":"呦呦鹿鸣，食野之苹。我有嘉宾，鼓瑟吹笙。 每个人都有隐藏的一隅。 一个人，安静下来，想一些没那么重要又如此重要的一些人，做一些喜欢又没那么喜欢的事儿，在烦恼与忙碌终于远去的时光的罅隙里。 有人说，照片是凝固了的时光。所以很多人着迷于摄影，用镜头记录想要回味和分享的瞬间。 有人说，凝固了的时光不好，流动的时光才有趣。所以每天拍一段几秒的视频，过个三年五载，再将它们串联起来，像串珍珠那样。 而我觉得，文字记录的时光，却是每时每刻都与现在流淌着的日子融合了的。 每次重读一行行文字，便是一趟联接着当下、过去，还有未来的心灵旅程。 文字太模糊了，不足以让你记起全部的细节，你只好亲自走回去，回到青葱的岁月，像看故事里的人物那样看看那时的自己； 文字又太准确了，这些陌生又熟悉的字眼，这些亲切又早已忘却的句子，就像当年的自己把故事亲口哼唱给你听，此时此刻，恰如彼时彼刻。 文字脆弱，却又力量无穷。 关于博客博客叫萧爽楼，从《浮生六记》中借来的名字。身边，很难寻找古人春游、结社、集会之乐趣。只愿文字在这个小小的空间里仍然能够发挥古老的力量。 博客的内容主要包括个人的生活、读书感想，也包括数学、互联网、编程语言、科学计算等方面的学习侧记。 关于我我现在在同济念书，学的是数学。对统计学习、数据分析、传播学、个人管理等感兴趣。摄影控，喜欢游泳和长跑。 我非常崇敬古代文人的这一人生理想： 为天地立心为生民立命为往圣继绝学为万世开太平 在这里(右击复制RSS源)订阅我的博客。 更多关于我的情况请访问我的主页。 我也在写一个生活化的博客丞喃旧事，关于我这个生于96，长于00和10年代的男生的微不足道的故事，您有兴趣也可以看看。","link":"/about/ver-2016.html"},{"title":"归档","text":"","link":"/archives/index.html"},{"title":"书影陈列室","text":"最近在读 最近想看 我读过的 我看过的 欢迎访问我的豆瓣主页","link":"/douban/index.html"},{"title":"友情链接","text":"考拉的网络日志-坚信技术/数据能够产生价值 Makito’s Notebook-Makito的生活觀察筆記 WWY’S BLOG !-这里是千千，曾喜欢VOCALOID CHINA，曾玩 PenBeat，现在在学习编程 梦魇小栈-心，若没有栖息的地方，到哪里都是流浪…… Project Aurora-仁者心动 Vincent Studio-一只只会敲代码的死肥宅 Resistence-关注计算机视觉领域的low level问题 高糖少女张小万-豆瓣日记-“现在是结局，或某些人所谓的盛开。” Zeyu Xiao’s Blog-一个会在周一和周二更新上周该更新文章的博客 欢迎各位博主朋友与我交换友情链接，请在本页面评论或发送邮件至me[at]ddlee[dot]cn，内容包含博客名称、URL和简短介绍（或关键词）即可。 您可以这样介绍本博客： 博客名称：萧爽楼博客链接：https://blog.ddlee.cc简短介绍：关注计算机视觉、泛互联网、个人管理等话题。","link":"/links/index.html"},{"title":"和光同尘，湛兮或存","text":"2018.11.17 杭州 长乐林场 2018.10.01 云南 大理/丽江/楚雄2018.09.28 故乡2018.08.17 北京 清河2016.07.30 崇明岛2016.10.13 杭州 西湖/西溪湿地2016.10.01 南京 总统府2016.09.06 苏州 沧浪亭/苏州中学/苏州大学/太湖西山岛2016.07.07 乌镇2016.01.01 上海 田子坊/新天地2015.12.25 上海 外滩2015.11.27 上海 同济大学2015.11.22 上海 世纪公园2015.07.10 黄山/宏村2015.04.08 绍兴 东湖 我的私人相册：时间而已","link":"/gallery/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"Chrome扩展推荐","text":"大部分来自Chrome平台，但FireFox应也有对应插件。如果您不能使用Chrome的账户同步功能或者对隐私问题比较在意，推荐您使用FireFox浏览器。 Adblock Plus，用于屏蔽广告，效果出众，必备 Chrono Download Manager，下载任务管理，必备 Draw.io Desktop，流程图编辑，轻量方便 Emoji Keyboard (2016) by EmojiOne，表情输入 Evernote Web Clipper，保存有价值的信息到Evernote Fatkun Batch Download Image，批量下载图片的插件，配合Google搜图 Follow Feed(by Feedly)，在当前网页搜索RSS订阅源并订阅至Feedly，用于订阅浏览到的价值博客等 GNOME Shell Integration，GNOME插件集成，用于在extension.gnome.org给GNOME安装插件，GNOME用户必备（有关GNOME可参考这里） Google Dictionary (by Google)，字典，设置快捷键Ctrl+D，搜词很方便 Google Input Tools，Google输入工具，应急之用 Google Scholar Button，用于在当前网页识别论文并在Google Scholar上检索相关内容 Google Translate，选取网页内容，可进行方便翻译 Inbox by Gmail，用于保存连接等内容到邮箱，方便分享 LastPass，跨平台的免费密码管理 Mega，大容量网盘 Mendeley Importer，导入文章到Mendeley Library Mercury Reader，渲染网页到阅读模式，清爽干净 Momentum，增强新标签页，显示时钟、天气、To Do List等 Octotree，显示Github Repo的目录结构，必备 One-Click Extensions Manager，管理扩展用，用于节省内存 PDF Viewer，用于阅读PDF（免于直接下载），记得勾选Allow access to file URLs Proxy SwitchyOmega，代理，善用auto switch和备份等功能 Pushbullet，跨设备文字通信，精分（PC用Ubuntu，平板iOS，手机Android）推荐 Quick QRCode，利器，用于把文字、连接等转成二维码，方便分享 Save to Google，保存网页到Google Save to Pocket，保存到Pocket，稍后再读工具 SimpRead简阅， 网页阅读模式插件 Secure Shell，网页版SSH Tab Snooze，折叠暂时不必要的标签页，利器 Text，轻量文本编辑器 Turn Off the Lights，利器，关灯。YouTube和Bilibili可用，其他未测试 Vimium，利器，脱离鼠标的网页浏览体验 微软雅黑字体，Windows上对所有页面进行字体渲染","link":"/recommendation/chrome-extension.html"},{"title":"私人书单","text":"这个页面列出的都是那种我很乐意买来送给朋友的书，如果您恰好感兴趣，请毫不犹豫地联系我，我会这样做的。 如果您在寻找某些书籍方面遇到困难，也请联系我。 这个列表会不定期地更新，关注更新的最好方法是收藏某一主题的对应豆列。 这里可以找到我通过豆瓣标记的想读和在读书目。 国家文化政治脉络（豆列）从帝制遗产到近代（民国）碰撞、融合和取舍、再至建国后冒进与纠偏、21世纪传承和当前状态等 《走出帝制》秦晖 重述近代转型历程，“大共同体-小共同体-个人”之论、“儒释道互补”、对日式个人主义的厘清等相当精彩。 《乡土中国》费孝通 日常认知和思维习惯的概念化体系化之作 《改革历程》赵紫阳 领导人视角的八十年代政治与经济改革 《中国近代史》徐中约 客观、冷静、克制，基于事实的史观革新，请确保阅读港中文版本。 《万历十五年》黄仁宇 从平凡处起笔，串联政治运作、文化背景及地理人情，力透纸背。 《中国文化要义》梁漱溟 一本“说理”之书，对文化观察和剖析相当深入，也有相当的解释力。认识近代历史之文化视角的上佳读物。 《兴盛与危机》金观涛、刘青峰 控制论方法引入古代社会结构研究，“超稳定”假说解释力相当强。 《开放中的变迁》金观涛、刘青峰 作者的系统控制论研究视角应用于近代变迁，解释力依然强大（或言之符合理科生视角）。序言表白研究心路历程，令人扼腕。 《历史的巨镜》金观涛 工具理性、个人权利、民族认同，三大基石建立现代性，再至第二层次的全球化、民族主义和国际组织，系统演化史观分析社会结构演变和现代化进程，解释力很强。 《中国历代政治得失》钱穆 谈“汉、唐、宋、明、清”五代政治制度要害处，提纲挈领，丰富历史认识，提倡多元视角和落地的史观，不陷于主义，对近代变法革命的讨论也很精彩。 《中国现代思想史论》李泽厚 “救亡压倒启蒙”论之肇始； 历史决定论和阶级斗争说是马克思主义在中国最具吸引力的说法； 二十世纪文艺一瞥 《中国文化的深层结构》孙隆基 内容虽显老，但角度却属罕见；虽重例证乏立论，但细处给人颇多警醒。 《中国国家治理的制度逻辑》周雪光 作者的组织学视角将日常有亲身经历的治理方式及衍生现象梳理得非常清楚，实证研究部分也相当有乡土气息。 《治理中国：从革命到改革》李侃如 帝制时代的遗产、毛时代政权特色的梳理、对成书时（21世纪初）权力结构和执政方式的叙述（外部和内部视角）等是比较精彩的地方，提供了一个认识当前国内政治的框架以及历史沿革的分析视角。改革时代删减非常多，建议对照英文版本。 《天朝的崩溃：鸦片战争再研究》茅海建 作者治史，细节考证不烦，评价中肯有理，分析满怀家国之情，更传达出往事钩沉的厚重和警示，值得重读。 国家现代经济沿革与现状（豆列）关注改革开放后对命令经济的改革历程和开放步伐、支线了解全球化视角下的定位与其他东亚国家的经济发展历程，经济和金融问题与出路 《重启改革议程》吴敬琏 改革派观点的精华之作，对很多现实问题都有深入的剖析和建议。 《现代化的陷阱》何清涟 指出快节奏、粗放型经济改革的另一面，资料翔实，分析清晰。 《渐行渐远的红利》彭文生 对二十一世纪头两个十年的经济运行情况有相当清晰的判断和论证，且不止于人口红利视角，比较分析了其他国家类似阶段的特征，现实意义很强。 《渐行渐近的金融周期》彭文生 金融周期视角分析当前经济状况，影子银行、土地财政、汇率问题等均有涉及。介绍经济分析流派、阐明各章思路，可读性很强。 《中国经济：转型与增长》诺里·巴顿 资料翔实、视角广阔的教材，可以为了解近现代中国经济（20世纪至21世纪初）提供多方面的宏观视角，值得收藏参考。 《当音乐停止之后》艾伦·布林德 最初对金融危机的理解来自《监守自盗》的原因解释和问责、《大而不倒》的人物纪实。这本书为我提供了更全面和宏观的视角，了解到美联储和联邦政府所做的努力，以及这场危机带来的制度性遗产。 西方宪政体制理论和历史实践（豆列）从启蒙时期思想源头到近现代主流政体评论、再至美国建国史和宪法实践，东欧转型经验等 《社会契约论》卢梭 国家建立之必然和所以然，启蒙之作。 《近距离看美国系列》林达 信件来往形式，文字可亲，平凡人和局外人视角的社会观察。 《通往奴役之路》哈耶克（殷海光译） 极权特性的分析，警世意义很强，选好译本非常重要。 国际关系分析框架和国际组织运作基本情况（豆列）经典国际关系理论，地缘政治案例，国际事件处理原则等 《理解国际冲突》小约瑟夫·奈 建立“体系-国家-个人”的三层国际问题认知分析框架，并应用于典型国际事件中，很简明的教材。 《文明的冲突与世界秩序的重建》亨廷顿 本书提供了一个具有极强描述力的视角，以文明的角度来梳理和分析当前国家间关系，强调不同国家及国家集合体间文化背景上的差异对于合作和冲突行为的影响。 以互联网为代表的信息技术革命给社会和生活带来的变革（豆列）硅谷人物和公司的传记，媒体形式变革带给社会的影响等 《浪潮之巅》吴军 讲技术史、公司史，通俗简明。 《必然》凯文·凯利 对趋势的把握相当准确，比《失控》思路叙述更清晰，更具现实意义。 《娱乐至死》尼尔·波兹曼 从印刷时代到电视时代，媒体形式如何改变了我们。 《黑客与画家》保罗·格雷汉姆 Hacker之名的正本清源，请千万不要误解，这可是个很cool的称谓，不要跟Cracker混淆。 《理解媒介：论人的延伸》麦克卢汉 对媒介的深入考察，行文略显晦涩，需要耐心。 《史蒂夫·乔布斯传》沃尔特·艾萨克森 乔布斯仙逝之时，正值我辈懵钝初开之日。 “谢谢您启发了我”。 文学作品（豆列）《活着》余华 每一次读都会非常感动，所谓生活的无奈和生命的坚韧。 《围城》钱钟书 文字功力深厚老练，在微小处见大道理。围城之喻精彩精彩。 《黄金时代》王小波 讲述式的叙事风格深深影响了我。我爱你，若“春藤绕树，小鸟依人”。 《文化苦旅》余秋雨 文化人的行记，苍茫、热诚与感念。 《平凡的世界》路遥 很广博的作品，时代印记、亲情、担当使命、爱情、自我探索，平凡处往往不凡。 《一九八四》乔治·奥维尔 战争即和平？自由即奴役？无知即力量？ 《古文观止》吴楚材、吴调侯（编） 文言文作品之精粹，幼时常放声而读。 《红楼梦》（脂评汇校本）曹雪芹、脂砚斋 附带脂评版本，更显深意苦心。 其他（豆列）《真实世界的脉络》戴维·多伊奇 稍偏形而上，谈四大理论之融合处，视角独特。 《20世纪简史：从无线电到柏林墙》杰弗里·布莱内 文字非常亲切，写历史写得像生活。 《如何阅读一本书》莫提默·艾德勒 关于读书的书，乃至知识体系建立之书，可以陪伴整个阅读生活。 《上帝掷骰子吗：量子物理史话》曹天元 行文流畅，逻辑脉络清晰，科普佳作。 《人类简史：从动物到上帝》尤瓦尔·赫拉利 视角广阔，观点新颖深刻。 《哥德尔、埃舍尔、巴赫：集异璧之大成》侯世达 逻辑、语言的盛宴，案头常备多读。 《电影艺术：形式与风格》大卫·波德维尔、克里斯汀·汤普森 我认为的最适合入门的读物，比《认识电影》更为体系化：从形式和风格两个角度来分析电影，并给出了分析某一镜头的体系化的思路。举例虽不如《认识电影》翔实，倒没有特别破坏体系化的论述。 《故事：材质、结构、风格和银幕剧作的原理》罗伯特・麦基 排版风格上重点内容被加粗和分离，阅读节奏容易把握。 行文风格通俗，讲故事的创作也是讲生活态度，不少语句可以作为人生哲理来看。 对剧本创作有一套成体系、操作性强的描述和分析框架，术语选择和描述上也易懂，且有适当的案例和图表用以说明。","link":"/recommendation/books.html"},{"title":"paper-notes","text":"","link":"/paper-notes/index.html"},{"title":"我的个人设备矩阵","text":"（正在建设中） 我所使用的操作系统平台包括Android, iOS, MacOS, GNU/Linux（Windows仅做娱乐功能，故不表）。","link":"/recommendation/hardware.html"},{"title":"信息获取与处理工具","text":"我对信息获取和处理的态度和实践，详见我的信息方法论。 跨平台服务 Feedly/Inoreader: RSS订阅的主力渠道，二者均自有跨平台的APP，但更重要的使其提供的账号功能和订阅源聚合服务，可以通过账号体系在不同平台使用不同的客户端来同步收藏文章和文章的阅读状态。我目前的实践是中文和英文两个账号，Android端使用FeedMe快速浏览，iPad和Mac上使用Reeder细读。 Medium/Quora: 高质量的英文内容，版面设计上也很适合阅读 Evernote/OneNote: 这里要强调的是，Evernote的护城河是其作为一项服务，富文本内容的收集、整理和聚合平台，有很多服务支持导入到Evernote，这一点是其跟其他笔记应用最不一样的。OneNote则在与Office系统的整合上有优势，且编辑功能要远远强大很多，适合Surface设备。 InstaPaper/Pocket/RainDrop: 这三者都可以用作稍后再读工具，区别是前两者都提供离线存储和相对无干扰的阅读器，适合长文离线阅读，而RainDrop更适合收集链接。 IFTTT: 辅助建立一些处理流，当然iOS平台现在也有了Shortcuts，Android平台则有Tasker。 Dropbox/NutStore/Box/iCloud/OneDrive: 文档同步网盘，参考我的数字内容管理实践。 GitHub/BitBucket: 结合Markdown这种“纯文本+”的格式，进行文档、草稿版本控制 PushBullet: 文字、链接、小文件等跨平台传递 Android FeedMe: RSS客户端，同步速度快，订阅资讯快速处理的主力工具，每天大概80条订阅咨询，用时约一刻钟 Pockets Casts(Paid): Podcasts订阅工具，Material Design设计 Sync: Reddit论坛的第三方客户端 Google News: 新闻推荐引擎（来源方面也比较靠谱）、杂志订阅平台（订阅了Wired） Kiwix: 随身的Wikipedia（英文无图片版大概20G），方便查询（当然现在已是无限流量时代了，用的便少了） MDict/Google Translate: 查询生词，翻译等 FireFox Focus/Tor: 无痕浏览，非常喜欢前者的设计，隐私程度上自然是后者更好，但速度较慢 Solid Explorer/Mixplorer: 文档客户端，用于网盘同步和设备间文档互传，前者是付费应用，后者可以在XDA下载 iOS(iPad) Documents + PDF Expert(Paid): Documents作为文档中心，同样支持网盘同步。使用后者标注PDF MaginNote + 多看阅读 + Kindle, : 阅读的主力工具，分别对应PDF, EPUB, MOBI/AZW3格式 Reeder3(Paid): 英文RSS订阅和细读文章（通过手机标记） Overcast: Podcasts订阅 Mac Reeder: 英文RSS订阅和细读文章（通过手机标记） MarginNote: 教材学习、论文阅读等 Calibre: 功能强大的电子书管理中心及阅读器 Ulysses: 篇幅相对较短的文字写作 Scrivener: 长篇写作，专业论文写作 Zotero: 文献管理，配合ZotFile插件，选择的主要原因是其浏览器导入工具比较好用","link":"/recommendation/info-service.html"},{"title":"推荐","text":"这个页面收集了我使用（过）和推荐的服务、工具、产品等。无任何广告利益关系，也没有推广链接。 如果您有好的建议，或者对某些服务、书籍等有想法分享，欢迎联系我（参见关于页面）。 信息获取与处理服务、各平台工具 个人信息获取来源 智库 我使用的硬件 GNU/Linux工具 macOS应用 浏览器扩展插件 付费订阅 Podcasts播客 私人书单 私人看单 音乐随记 视频 游戏","link":"/recommendation/index.html"},{"title":"GNU/Linux软件推荐","text":"Text Editor: 我目前使用VS Code，Atom和Sublime Text也值得推荐，只不过前者启动速度较慢，后者需要付费使用。 tmux: tmux是一个终端多窗口管理器，可以打开多个终端窗口、挂起和挂载终端回话等，利器。 GitKraken: Git的图形客户端 Whatever-Evernote alternative: Evernote的第三方客户端，调用网页API，不占用免费版的客户端限制个数 Stacer-System Cleaner: 提供系统监视器和清理功能，也可以卸载包 Synapse-App Launcher: 一个类似lauchy的应用启动器，可以直接用apt安装 Gdebi-Package Installer: 包安装程序，比自带的安装好用一些（安装deb包等） Mailspring-Mail Client: 邮件客户端，比thunderbird, evolution等界面美观现代一些 Gparted-Disk Management: 磁盘管理程序，用于分区、格式化等等 Okular-PDF Reader: 功能强大的PDF阅读器 WPS Office: WPS的Linux版本，比Libre要好用很多 Shutter: 截屏软件，可以通过ubunut软件中心安装 Wewechat-Wechat client: 微信的第三方客户端，还有electron-wechat，wewechat界面更好，而后者可以看公众号的文章。 IeaseMusic-Netease Music Client: 网易云音乐的第三方客户端，界面漂亮，我一般用于听FM。功能上更全的自然是官方版本。","link":"/recommendation/linux-apps.html"},{"title":"个人信息来源","text":"我推荐您使用RSS服务订阅如下内容，您可以阅读博文RSS：给你所爱的人以自由来了解RSS。下面所有提供链接的信息来源均为RSS源，可复制后添加到订阅列表，其他未提供链接的，相信您通过名字可以很容易检索得到。 关于我对信息获取和处理的态度和实践，详见我的信息方法论。 我本人也在维护一份Newsletter：ddlee每周分享，关注视觉、智能、泛互联网话题，欢迎订阅。 新闻媒体综合类： 国际性媒体：New York Times（feedx.net提供：纽约时报中文网）, Wall Street Journal, Financial Times（feedx.net提供：FT中文网）, The Economists 写作、问答平台上相关话题和作者：Medium, Quora 泛IT综合类：The Verge, Wired, InfoQ, LifeHacker, 少数派 Android相关：Android Authority（评测，APP推荐） GNU/Linux相关：It’s FOSS 知名公司、研究机构的技术博客：Google、FAIR、MSRA、OpenAI、DeepMind、Distill等 行业评论/调研 Stratechery（关注互联网、IT产业，观点独立） 199IT互联网数据中心（行业调研报告） 麦肯锡大中华区 甲子光年的知乎动态（互联网行业评论） 爱思想一周文章排行（经济、文化等学者文章） 人工推荐 社交平台上行业相关的朋友、同事等推荐的信息 湾区日报（每天推送5篇英文文章，附评论，关注互联网、创业等话题） YouTube频道视频信息主要发挥其形象性，可以比较容易地理解某一事物。 Linus Tech Tips（硬件评测、改装等） Two Minute Papers（人工智能相关论文介绍） ColdFusion（技术史、科技公司史） The Artificial Intelligence Channel（人工智能相关的演讲） 论坛论坛中噪音较多，优点是实时性。 Reddit相关话题 V2EX（泛互联网话题） XDA Developers Forum（玩机工具、评测） Newsletter通过邮件订阅 Hacker News（泛IT话题） Pycoder’s Weekly（Python语言相关） GitXiv Top Post（人工智能相关论文推荐）","link":"/recommendation/info-source.html"},{"title":"macOS应用推荐","text":"（正在建设中） Alfred+Powerpack: 快速启动器，效率工作流 MarginNote: 学习材料梳理、精读与笔记，结合标注与思维导图整理 Spark: 邮箱应用 Reeder: RSS订阅中心，资讯阅读 Zotero: 文献管理 Ulysess: 写作 Scapple: 灵活的脑图工具，计划与表达 Scrivener: 严肃作品创作 Downie: 多平台视频下载 Popclip: 粘贴板增强 Quitter: 管理不活跃应用 Calibre: 电子书整理中心 Bartender: 顶部拦图表整理 DropZone: 文件整理辅助区域","link":"/recommendation/mac-apps.html"},{"title":"我喜欢的游戏","text":"（正在建设中） 玩的游戏偏向独立解密类，当作参与式电影来消费，通常不超过半天的剧情。 纪念碑谷 Momentum Valley第一部是自我，第二部是亲子。一个艾舍尔三角形，演变出各种形式和结构，穿插于精美的几何场景里。其他元素的互动，朋友、阻挠你的人、启迪者、子女，也都非常自然地融合到整个探险经历里。作者也通过机关的设计和启迪者的台词提醒着我们生活的感悟。 机械迷城 Machinarium 画中世界 Smarost 地狱边境 Limbo 致命框架 Framed INSIDE","link":"/recommendation/games.html"},{"title":"私人看单","text":"(正在建设中) 这里可以找到通过豆瓣标记的想看和在看的影片、剧集。 电影低俗小说 Pulp Fiction 穆赫兰道 致命魔术 搏击俱乐部 星际穿越 盗梦空间 蝙蝠侠：黑暗骑士 谍影重重三部曲 碟中谍 终结者2 活着 大话西游之大圣娶亲 剧集真探 西部世界 绝命毒师 纪录片浮生一日 监守自盗 作者昆汀： 杀死比尔 无耻混蛋 姜文： 鬼子来了 太阳照常升起 让子弹飞 一步之遥 邪不压正","link":"/recommendation/movies.html"},{"title":"Podcast 订阅推荐","text":"推荐的客户端 IOS: Overcast, Castro Android: Pocket Casts(Paid), Podcast Addict macOS: PodcastMenu GNU/Linux &amp; Windows: WINDS(https://getstream.io/winds/) 订阅节目 Planet Money: NPR出品，节目较短，20min左右，介绍有趣的经济现象 TED Radio Hour: NPR出品，串联某一话题的TED演讲，截取部分演讲内容和对讲者的访谈，对比观点，50min左右 Intelligence US Debates: 围绕某一热点社会话题的辩论，来自现场实录，辩手大多来自对相关话题有研究的教授、作者、政策制定者等，50min左右 Tech Stuff: 对某项技术、某个公司的历史介绍，30-40min Recode/Decode: 对知名公司CEO的访谈 Exponet: Stratechery博客作者Ben Thompson的Podcast，阐释他对IT行业的观察和评论 翻转电台: 系统性介绍某一历史、文化主题，几期节目构成一个专题 一天世界: 前身IT公论，谈论泛互联网话题，不鸟万如一主持","link":"/recommendation/podcasts.html"},{"title":"音乐随记","text":"2018.07.07 update: Pandora: Classical Goes Pop Radio用古典器乐演绎流行乐，古典的风味配流行旋律，很搭。 Never Be the Same - Camila Cabello 女声副歌部分很有感染力。“啊，我的宝贝，这再也不比往前了。” When I Was Your Man - Bruno Mars一定要看一下现场，火星哥的声线将这首唱给前女友的歌演绎得分外动情。“一个男人可以有多逗比，就可以有多深情。” Someone Like You - Adele这首歌同样要看现场，万人合唱。同样是唱给前任的歌。 “不必担心，我会找到一个像你那样的。我只希望，你以后的日子里永远有晴天。” 纸短情长 - 花粥一度单曲循环了好久，旋律倒还简单，只是歌词触人软弱之处。酒桌版的MV也值得一看，嘿，他们唱的其实是我们每一个人。“听得到吗？我的故事都是关于你啊。” 窃爱 - 周杰伦编曲很有古典风味，副歌部分节奏和停顿感很好，MV非常赞，歌词晦涩难懂。“我在画里的桥，吹着口哨。烟火城堡，还空一角等，你的拥抱。” 印第安老斑鸠 - 周杰伦歌词天马行空，说唱节奏非常舒服，耐听不厌。同样推荐看一下陈怡良的演绎版本。 500 Miles Away from Home - Bobby Bare“我相信每个人都会有自己的旅程，而你的旅程总会将你指向我身边。” 我到了远方，也回过家乡，但留不住和你分享过的时光。 One Call Away - Charlie Puth我会是谁的The one call away，谁又是我的one call away。 2018.01.26 Bikini Body - Dwain/R.City我非常喜欢副歌部分的器乐，尤其是小号、萨克斯这种管乐。当然，发现这首歌最开始是在1 Million，舞蹈很棒。 Seve - Tungevaag &amp; Raaban鬼步舞神曲，妹子腿很长。同样是因为副歌部分的器乐，节奏很好，心情舒畅。 5 Years Time - Sun Sun Sun - Noah and the Whale前奏的口哨很诱人，而我就从没学会过吹口哨。整首歌很随性，慵懒的午后，躺椅上晒个太阳，草帽盖住脸庞。 The Failing Song - Matt Elliott前奏是我目前的手机铃声。多年以后，会是哪两张苍白的面庞相对，诉说曾经的故事；会是哪片冷风裹挟来的雪花，落在红灯闪耀的火炉旁。 7 Days - Craig David小黄歌，但是副歌好听啊，转音很舒服，嗓音慵懒，软在周日的沙发上。 Larrons En Foire - Raphae Beau“恰恰恰”的四三拍从头到尾，适合起舞也适合做些鬼鬼祟祟的事情。中间有一段是把尺子压在桌子边缘，用力摁下晃出来的声音，挺有意思。 If I Die Young - The Band Perry请葬我以花，咏我以歌，送我以诗，赞我以爱。我的谢幕，请不要悲伤，不要流泪。我的血液顺流而下，借着晨光，流过大江南北。我的头发缠住青草，错开过去，长出新的生命。我的眼，望穿深山，透过云彩，高而俯瞰大地。我的耳，闻声于万里，贴着尘埃，听见岁月深处的叹息。所以，请不要为我悲伤、流泪。 Your Song - Poema你是人间的四月天，是明媚，鲜妍。 Young and Beautiful - Lana Dei Rey配合MV听最好。人声跟弦乐互相衬托，听的时候呼吸总是紧绷的。花落花飞花满天，红消香断有谁怜。再美再难得的承诺，如何抵得过这似水流年。 Free Loop - Dniel Powter印象最深的是曲子最后的渐弱，像一滴红墨水，无意滴在澄澈的小溪里，就这样消散开来，流啊流啊，流向跟过去不相关的远方。 9 Crimes - Damien Rice近乎清唱，伴奏轻且压抑，男声女声交织。听完怅然若失。 Vampire - Laziboy Empire最喜欢的萨克斯。那种把烦恼都扫去的旋律，只留给你飘扬的心情。","link":"/recommendation/music.html"},{"title":"智库推荐","text":"（正在建设中） 天则经济研究所https://unirule.cloud 对当前社会诸多问题（国企改革、原油市场、民企税负等）都有研究报告，博客经常更新，每周有电子周刊，在FT中文网有固定专栏。 概况“天则”取自古籍《诗经》，“天生烝民，有物有则”“天则”意为合乎天道自然之制度规则，在经济、社会、政治和文化等方面发挥作用。天则经济研究所（天则所）由茅于轼、张曙光、盛洪、樊纲和唐寿宁等五位中国著名经济学家，与大象文化有限公司一起，于1993年创办，是一家独立、非营利的非政府智库。他们关注并投身于制度经济学研究、政治和经济领域的改革以及中国传统文化的传承。天则所主要向社会提供知识的公共物品。目标中国正在经历巨大的变革。天则所在致力于推进经济学和社会科学研究的同时，为各种社会问题提供政策建议和制度解决方案，并与公众分享经济自由主义，宪政民主，珍视文化传统与多元化，天下主义和宽容的常识和理念。 Congressional Research Service(CRS)https://fas.org/sgp/crs/ 为美国国会议员提供报告的智囊，经常更新，涉及议题广泛。报告形式既有对某一问题的深入研究，也有短小简明的纲要性小册子。 The Congressional Research Service, a component of the Library of Congress, conducts research and analysis for Congress on a broad range of national policy issues. WTOhttps://www.wto.org/english/res_e/reser_e/reser_e.htm 世界贸易组织每年都会出具国际贸易方面的报告，包括贸易数据、单个国家的经贸情况、贸易纠纷的调解结果等。 The WTO provides economic analysis and research that aims to deepen understanding about trends in trade, trade policy issues and the multilateral trading system. Its annual publications include the World Trade Report and World Trade Statistical Review. The WTO organizes economic seminars and cooperates with other international organizations and the academic community through co-publications, conferences, courses and other events. International Crisis Grouphttps://www.crisisgroup.org/ 国际危机组织关注国际间关系，不少报告都有中文版本。 The International Crisis Group is an independent organisation working to prevent wars and shape policies that will build a more peaceful world. Crisis Group sounds the alarm to prevent deadly conflict. We build support for the good governance and inclusive politics that enable societies to flourish. We engage directly with a range of conflict actors to seek and share information, and to encourage intelligent action for peace. ECFRhttps://ecfr.eu 欧洲外交关系议会关注欧洲相关的外交和安全事务，关注议题广泛（欧洲视角），报告更新频次高。 The European Council on Foreign Relations (ECFR) is an award-winning international think-tank that aims to conduct cutting-edge independent research on European foreign and security policy and to provide a safe meeting space for decision-makers, activists and influencers to share ideas. We build coalitions for change at the European level and promote informed debate about Europe’s role in the world. In 2007, ECFR’s founders set about creating a pan-European institution that could combine establishment credibility with intellectual insurgency. Today, ECFR remains uniquely placed to continue providing a pan-European perspective on some of the biggest strategic challenges and choices Europeans need to confront, with a network of offices in seven European capitals, over 60 staff from more than 25 different countries and a team of associated researchers in the EU 28 member states. NBERhttps://www.nber.org 美国国家经济调研局关注相对偏理论的经济问题建模和研究，报告篇幅通常较短且理论性强。 Founded in 1920, the NBER is a private, non-profit, non-partisan organization dedicated to conducting economic research and to disseminating research findings among academics, public policy makers, and business professionals. NBER-affiliated researchers study a wide range of topics and they employ many different methods in their work. Key focus areas include developing new statistical measurements, estimating quantitative models of economic behavior, and analyzing the effects of public policies. Chatham Househttps://www.chathamhouse.org/ Chatham House关注国际热点事务，博文报告都很活跃，提供订阅渠道也很多样。 To help build a sustainably secure, prosperous and just world, through informed debate, independent analysis, new policy ideas, and outreach to audiences.","link":"/recommendation/think-tanks.html"},{"title":"订阅东东月报","text":"东东月报是我每月对自己学习、阅读、创作等活动的精要总结，包括计算机视觉类论文的笔记和推荐、书评影评、想法随笔和收藏的文章等。您可以在这里查看往期发送的内容。 请将邮箱填写入下面的文本框以订阅，如果您在订阅所需的reCAPTCHA验证（由Google提供）遇到困难，请在下方评论或直接使用邮箱以“订阅月报”为主题向我(me@ddlee.cc)发送邮件。","link":"/subscribe/index.html"},{"title":"付费订阅","text":"当前订阅 Wall Stree Journal：相对客观的国际新闻 The Wired：技术类新闻及评论，可以浏览网站内容并每月会有一本杂志 哈佛商业评论中文版：财经、管理类文章，拓展视野和思路所用，尝试以一个经营者的思维运营自己本身 Apple Music：曲库较为丰富，对学生价格优惠 网易云音乐豪华会员：离线许多红心歌曲所用，但曲库确实做得不好 腾讯视频会员：美剧和电影资源相对丰富，看了一些自己感兴趣的剧，但总会有不全的时候，各家服务的差别也主要是在内容方面 Evernote Premium: 信息收集中心 SetApps: Mac App集合包，可满足大部分日常需求 服务器及域名：用于伺服网站 弃用订阅 Stratechery：独立分析师Ben Thompson的个人博客，观点独立且有自己的一套认识和分析框架，由于价格较高且个人处理英文信息的效率并不高取消订阅 迅雷会员：几年前下载视频教程的时候订阅过 百度网盘超级会员：因为限速问题不得不订阅过一次，目前对其态度是作为资源站，不会将个人资料进行存储 种草 Medium Member: 高质量内容社区","link":"/recommendation/subscription.html"},{"title":"收藏的视频","text":"本页面收录了部分我收藏的视频，包含演讲、科普、表演等，视频链接主要来自YouTube和Bilibili。 演讲 Steve Jobs’ 2005 Stanford Commencement Address Facebook Founder Mark Zuckerberg Commencement Address - Harvard Commencement 2017 Bill and Melinda Gates’ 2014 Stanford Commencement Address Steve Jobs Introducing The iPhone At MacWorld 2007 Windows 10 devices event keynote: Hololens,Surface 4 pro,Surface Book,Lumia 950&amp;950XL 舞蹈 PUMPED UP KICKS|DUBSTEP 表演 艾怡良 - 印第安老斑鳩 The Lady Lifers: A moving song from women in prison for life 周杰伦 - 默 刘欢&amp;郎朗&amp;吕思清 - 从前慢 (2015央视春晚 Live版） 周杰伦&amp;陈奕迅 - 谢谢侬+印第安老斑鸠（中国新歌声2） 宋祖英 - 大地飞歌（鸟巢音乐会） 卢冠廷 - 一生所爱 MV 周杰倫 - 竊愛 MV 王菲&amp;陈奕迅 - 因为爱情（2012年春晚） 教程 Dawn of the Net - How the Internet works How The Economic Machine Works by Ray Dalio 其他 2015 Year in Review(by Facebook) Microsoft Christmas Commercial ft. Apple “70 Years of the NBA Finals” featuring Metallica True Detective Season 1 Opening Credits | HBO Westworld Season 1 Opening Credits | HBO Thank You for 15 Years of Open Sharing - MIT OpenCourseWare","link":"/recommendation/videos.html"}],"posts":[{"title":"Coroutine,Generator,Async与Await","text":"GeneratorGenerator能保存自己的状态，进入一种“Paused”状态，再次调用时会继续执行。 Generator的好处之一是节省了存储空间开销，带一些”流处理”的思想。 其实，我们也可以对Generator进行传入数据的操作： def coro(): hello = yield &quot;Hello&quot; yield hello c = coro() print(next(c)) print(c.send(&quot;World&quot;)) Coroutinecoroutine可以认为是generator思想的泛化： generator一个一个地吐出数据（返回值） coroutine一个一个地吃掉数据（传入参数）并返回结果，即可控地执行函数 关键点在于，generator与coroutine都能保存自己的状态，而这种特点正可以用于任务切换。yield可以看做是操作系统在进行进程管理时的traps: 实际上，coroutine可以看做”用户自定义”的进程，状态、启用和暂停都可控，David Beazley就利用这一点用coroutine实现了Python上的操作系统（参见Reference)。 Conroutine与Concurrent ProgrammingConcurrent Programming中有Task的概念，有如下特点： 独立的控制流 内部状态变量 支持计划任务（暂停、恢复执行） 与其他Task通信 @coroutine def grep(pattern): #正则匹配 print &quot;Looking for %s&quot; % pattern while True: line = (yield) if pattern in line: print line, conroutine有自己的控制流（while/if），有局部变量（pattern, line），能暂停和恢复（yield()/send()），能相互通信（send()） ====》coroutine就是一种Task！ Python Docs中提供了一个例子： import asyncio async def compute(x, y): print(&quot;Compute %s + %s ...&quot; % (x, y)) await asyncio.sleep(1.0) return x + y async def print_sum(x, y): result = await compute(x, y) print(&quot;%s + %s = %s&quot; % (x, y, result)) loop = asyncio.get_event_loop() loop.run_until_complete(print_sum(1, 2)) loop.close() 执行方式如下图： 利用coroutine，可以在一个线程(Task)上实现异步。 Impletationcoroutine有两种实现方式，基于generator和原生async, awati关键字。 generator based coroutineimport asyncio import datetime import random @asyncio.coroutine def display_date(num, loop): end_time = loop.time() + 50.0 while True: print(&quot;Loop: {} Time: {}&quot;.format(num, datetime.datetime.now())) if (loop.time() + 1.0) &gt;= end_time: break yield from asyncio.sleep(random.randint(0, 5)) loop = asyncio.get_event_loop() asyncio.ensure_future(display_date(1, loop)) asyncio.ensure_future(display_date(2, loop)) loop.run_forever() 上面的程序实现了在同一个线程里交互执行两个函数（sleep），而又能保持各自的状态 Native support(python 3.5+)只需要修改函数定义头和yield from为关键字await即可。 async def display_date(num, loop, ): end_time = loop.time() + 50.0 while True: print(&quot;Loop: {} Time: {}&quot;.format(num, datetime.datetime.now())) if (loop.time() + 1.0) &gt;= end_time: break await asyncio.sleep(random.randint(0, 5)) 拾遗Coroutine常翻译成“协程”。 Reference: David Beazley @ PyCon2009 Slides PYTHON: GENERATORS, COROUTINES, NATIVE COROUTINES AND ASYNC/AWAIT Python 3.6 Docs: Taks and coroutines @ddlee","link":"/posts/8a684efc/"},{"title":"FlintOS轻体验","text":"呃，我在2016版的个人主页里曾表达自己特别想拥有一台Chromebook，可终于还是屈服在了网络环境面前。 离了我的路由器，我的Chromebook几乎就是个废物了。 不过，FlintOS的出现让我重拾了这个想法，我可能还是需要一台轻便的上网本。 FlintOS是Chromium OS的中文本地化项目，而后者正是Chromebook的操作系统，在美国的低端笔记本市场和教育市场占有很大的份额。 只不过在大陆呵呵。 言归正传，FlintOS背后的公司是成立不久的燧炻科技，这里是他们的官网，可以在这个页面了解更多FlintOS的信息，本篇中的版本是在论坛的DEV3.2中国版。 安装DEV3.2中国版的最大亮点是支持本地账户。这意味着在大陆的网络环境下也有使用的可能性。而且，这个版本内置了可供科学上网的服务，测试可用。另外，FlintOS settings里面也包括了安装Flash的快捷方式。 目前建议是在U盘上体验，安装教程在这里。 也可以选择安装双启动和硬盘独占安装，可以参考社区的置顶帖。 界面UI桌面和右下角的通知栏，遵从了Material Design，看着舒服。 APP Launcher，跟Gnome的风格很像。搜索栏可以直接Google搜索，也可以搜索文件和APP。实际上大部分APP可以当做交互逻辑级别更高的书签，打开即是新建相应网站的标签页（如YouTube）。 这个是Chrome Web Store，跟作为浏览器的Chrome完全一致，只不过这个平台上可没有homebrew也没有dpkg。 文件管理应用，跟Google Drive深度集成。 编程相关我也尝试探索用于开发的可能性，由于ssh的存在，可操作性还是很高的。 Texts是一个比较轻亮的文本编辑器。当然也有仿atom的付费APP。 crosh（通过Crtl+Shift+T打开）是内置的shell，功能上还有待探索，图为运行top的效果。 小结Chromium OS的理念是web为王，浏览器即一切。这种理念配合Google相当完整的生态使得Chromebook在廉价本市场几乎是统治地位。去年的MS build上，微软也发布了对标的Windows版本，demo用的场景就是老师为每个学生配备PC。 相比之下，大陆的这个市场还是空白（或许不一定有，毕竟教育方面并不普及）。看到有把这种理念本地化的公司出现还是很惊艳，在此默默祝福他们。","link":"/posts/4213a4c1/"},{"title":"Dropout-Pytorch实现","text":"Dropout技术是Srivastava等人在2012年提出的技术，现在已然成为各种深度模型的标配。其中心思想是随机地冻结一部分模型参数，用于提高模型的泛化性能。 Dropout的洞察关于Dropout，一个流行的解释是，通过随机行为训练网络，并平均多个随机决定的结果，实现了参数共享的Bagging。如下图，通过随机地冻结/抛弃某些隐藏单元，我们得到了新的子网络，而参数共享是说，与Bagging中子模型相互独立的参数不同，深度网络中Dropout生成的子网络是串行的，后一个子模型继承了前一个子模型的某些参数。 Dropout是模型自我破坏的一种形式，这种破坏使得存活下来的部分更加鲁棒。例如，某一隐藏单元学得了脸部鼻子的特征，而在Dropout中遭到破坏，则在之后的迭代中，要么该隐藏单元重新学习到鼻子的特征，要么学到别的特征，后者则说明，鼻子特征对该任务来说是冗余的，因而，通过Dropout，保留下来的特征更加稳定和富有信息。 Hinton曾用生物学的观点解释这一点。神经网络的训练过程可以看做是生物种群逐渐适应环境的过程，在迭代中传递的模型参数可以看做种群的基因，Dropout以随机信号的方式给环境随机的干扰，使得传递的基因不得不适应更多的情况才能存活。 另一个需要指出的地方是，Dropout给隐藏单元加入的噪声是乘性的，不像Bias那样加在隐藏单元上，这样在进行反向传播时，Dropout引入的噪声仍能够起作用。 代码实现下面看在实践中，Dropout层是如何实现的。简单来说，就是生成一系列随机数作为mask，然后再用mask点乘原有的输入，达到引入噪声的效果。 From Scratch# forward pass def dropout_forward(x, dropout_param): p, mode = dropout_param[&apos;p&apos;], dropout_param[&apos;mode&apos;] # p: dropout rate; mode: train or test if &apos;seed&apos; in dropout_param: np.random_seed(dropout_param[&apos;seed&apos;]) # seed: random seed mask = None out = None if mode == &apos;train&apos;: mask = (np.random.rand(*x.shape) &gt;= p)/(1-p) # 1-p as normalization multiplier: to keep the size of input out = x * mask elif mode == &apos;test&apos;: # do nothing when perform inference out = x cache = (dropout_param, mask) out = out.astype(x.dtype, copy=False) return out, cache # backward pass def dropout_backward(dout, cache): dropout_param, mask = cache mode = dropout_param[&apos;mode&apos;] dx = None if mode == &apos;train&apos;: dx = dout * mask elif mode == &apos;test&apos;: dx = dout return dx Pytorch实现file: /torch/nn/_functions/dropout.py class Dropout(InplaceFunction): def __init__(self, p=0.5, train=False, inplace=False): super(Dropout, self).__init__() if p &lt; 0 or p &gt; 1: raise ValueError(&quot;dropout probability has to be between 0 and 1, &quot; &quot;but got {}&quot;.format(p)) self.p = p self.train = train self.inplace = inplace def _make_noise(self, input): # generate random signal return input.new().resize_as_(input) def forward(self, input): if self.inplace: self.mark_dirty(input) output = input else: output = input.clone() if self.p &gt; 0 and self.train: self.noise = self._make_noise(input) # multiply mask to input self.noise.bernoulli_(1 - self.p).div_(1 - self.p) if self.p == 1: self.noise.fill_(0) self.noise = self.noise.expand_as(input) output.mul_(self.noise) return output def backward(self, grad_output): if self.p &gt; 0 and self.train: return grad_output.mul(self.noise) else: return grad_output","link":"/posts/5556c57b/"},{"title":"求导的哲学","text":"按：此文为个人公众号的欢迎文章，烦请想象自己是在微信里读到这些文字。 由是则生，而有不用也；由是则可以避患，而有不为也。——孟子 你好，欢迎你关注求导Derivative。 一个比喻假如你是奥特曼，前面有个路口怪兽正在那里吃人，可你注意到还有一个人往那个方向走，你该怎么办？A. 大声呼喊，“疯了吧你，再往那走你会没命的，有个怪兽在吃人！”B. 跑过去，拦住他，死活也不让他再往前走了C. 你仔细观察，发现这个人是个高度近视，但忘了戴眼镜，你过去把眼镜递给他 我的选择是C。但真正的奥特曼应该出现在路口那里，忙着把怪兽赶走，很遗憾我不是真正的奥特曼。 求导的哲学其实这就是我想用“求导”表达的意思。我们应该多看一层，注意到问题还远远不够，我们应该去探寻造成问题的那个问题，即是，求一次导。而且，这个过程是能够迭代的。正如你想改变速度，你应该在加速度的层面操作，你想说服一个人，只在现象和结论上跟他对着干是徒劳的，你应该去找到他的论据和论证过程（同时，检视自己的论据和论证过程）。这也是我正在做的事情。我从自己的博客里搬运了几篇文章过来，方便朋友们能够看到。《我的信息方法论》讲我自己抗拒信息洪流所进行的努力和思考，梳理了自己的原则和思路。《在线文字创作不完全指南》则写给有表达愿望的读者，建立编辑接口、定制性和分发渠道三个指标来点评在线写作的各种方式，并提供选择建议。而《RSS：给你所爱的人以自由》，则着力介绍RSS订阅这一信息获取方式，指出平台之恶和RSS之轻量通用。这些原则/技术帮助了我，我很希望能跟朋友们分享。 本公众号的命运我会选择性地将自己未来写作的关于“求导”的文章搬运到这里，可以预计的主题包括：个人管理、读书/找书经验、知识整理归类的原则等等。这里不会有任何“求导”主题之外的内容，考虑到更新的速度，大概率会成为一具安静无比的尸体。“求导”之名，本来是为我现已搁浅的播客（一种音频节目）制作计划而想的，原本的设想是邀请各行业的朋友们一起聊聊他们日常生活和专业领域“求导”思想的展示，但愧于自己的贫乏和价值输出能力，恐怕很久之后才能重启这个项目了。如果您在阅读了下面的内容后仍然决定不取消关注这个公众号，我同样承诺之后重启的播客计划会被搬运到这里。 为什么我不鼓励您关注本公众号最简单的原因，是因为本公众号是最容易被替代的。如果更详细些，我们从链接开始讲起吧。本来的链接，就是代表“连接”，意思是你点击一下，就可以从这个网页跳转到那个网页，这个允许跳转的过程，意味着两个网页是连接着的。如果没有任何链接指向某个页面，那这个页面我们还可以访问吗？当然可以，我们可以手动输入其地址，也就是URL，URL就是网络世界里的门牌号。然而这很麻烦，即便是门牌号，也并不好记，而且我们也记不了这么多。于是，门户网站，一种专门提供指向到其他网站的链接的网站，应运而生，最成功的例子之一便是Yahoo!。再后来网站增长的速度超出了分类整理的速度，分类的层级也越来越多，另一种索引网站的方式越来越受欢迎，这便是搜索引擎。搜索引擎的成功之处在于挖掘了链接行为的高层信息：一个网页被链接越多，那它应该越有价值，从它链接出去的网页，也应该更有价值。这其实是PageRank算法的理念，它不仅解决了一个网页质量评估的问题，也催生了一家堪称（过）伟大的公司。 我讲述上面这些，是想说，链接是互联网之“互联”二字的本源。然而，很不幸，您读到这段文字的页面，是反链接的。在正文里，我没办法像在别的网站上那样，输入这样一句很自然的话：“有关PageRank算法和搜索引擎，您可以在【这里】阅读更多Google创立早期的故事”。这句话本应该出现在上面一段的末尾，作为创作者而言，我浅短地描述了一个故事，但自觉不够生动和具体，我有义务为我的读者提供更多他们可能想要进一步了解的信息。但我在这里做不到。你也许注意到，这个页面的左下角是有一个“阅读原文”（英文显示Read More）的链接的，你看，抱怨什么，你可以把这个链接放在那里嘛。那我不禁疑惑，我们该如何理解“原文”的含义？如果这个链接果真是应这样使用，为什么我作为创作者却无权决定这个“阅读原文”四字？我能够改成“Google的故事”，这样岂不是更符合链接的目的？不不不，不是让你这样用的，你填入的的那个链接就应该是字面意义上的“原文”。那事情变得更加吊诡了。既然读者在这里已然能够把文章读完，哪来的动机去读“原文”？难道这个“原文”跟我们现在看到的文章有不一样的地方，还是这是一句所谓的“侵删”声明，代表我这篇文章是从“原文”链接那里转载过来的？如果是后者，那真是令人更不得解：为什么不直接分享这个“原文”链接到平台里，而是要辛辛苦苦把人家的文字复制粘贴过来，再链接回去？试问，我们是否在浏览网页时，经常看到正文没有一处链接，却在文章末尾有一个“阅读原文”链接，指向一个公众号平台的文章？如果这样的景象令你感到滑稽，但为什么反过来的情景却被默认是合理的？“阅读原文”链接，是一种暴行，和一块伤疤。 请原谅我的聒噪。我只是试图指出，这个平台不是鼓励原创的，而是鼓励搬运和抄袭，它也不以链接为价值，而是互联网世界的一处黑洞，任何被它吞噬进的注意力，都很难逃逸出来了，何况从其中出发者。它不是在做内容的生意，而是在做注意力的生意，而注意力赋权了平台，平台则筛查了内容，胁迫了作者。请观察您读到的媒体文章，大部分是“编译”和“转载”的，而且相当一部分是不添加“阅读原文”链接的，甚至连原作者、原文章名都不提。更加过分的，任意在作者文章里添加自己的其他抄袭文章和广告，不遵守真正的“原文”之转载规范。我无意追问各公众号采编之责，我对帮读者打破语言隔阂的译者致以敬意。但若平台上充斥着这样的内容，而平台规则的设计无罪，那错在何处呢？如果再进一步，对于这个平台上的原创文章，按照Robot.txt规则（这一文件是爬虫领域自律的规范），这些文章是不能被任何爬虫Agent爬取的，连搜狗的独家微信搜索爬虫都不能。于是当你试图在archive.org（一个致力于为所有网页内容建立存档的公益项目）检索任意一篇公众号文章时，都是一片空白，而且在将来也会如此。巨量的中文网页内容，很可能成为后人知识版图里的一片巨大残缺，他们将失去理解我们当前社会状态的重要材料，历史将被任意讲述。这整个平台，是一个事实上的局域网，处处立满高墙，分割和围堵一切在茁壮成长着的心灵。 我亲爱的读者，你们才是这个平台最具有影响力的因素。庞大的数量、高涨的热情，吸引着具有无边创造力和想象力的作者们。但在这个平台上，我们的互动方式显然被僵化地限制了：评论时必须关注公众号、提交的评论需要被审核、不能在其他读者的评论下继续评论（只有投票的权利），你·甚至不能在此篇文章底部批评我，因为新注册公众号的留言功能被关闭了。本应促成公共讨论的空间，被压缩成了“好看”“点赞”等简单行为，宛如一场没有任何议论的无声表演。如果仔细分析读者与作者间和读者与读者间这两对互动关系，相比十年前“人各有志”的博客时代和论坛、BBS兴盛之时，我们到底是在进步还是在退步？我相信人人有自主的品味、独立的判断，在沟通、讨论和筛选中，理解会建立，如果足够幸运，共识会达成。我也认为，这些在这个平台更难实现。因此，我仍然坚持我在公众号被关注自动回复里的建议：我恳请您取消关注所有可被替代的公众号，而显然本公众号是最容易被取代的之一——我本人通过其他方式发布的创作内容更容易找到、更全面、组织形式更好。关于如何取代，我想您已阅读过本公众号关于RSS订阅的文章（位置：“公众号菜单-推荐-RSS”），我真诚地希望您能够考虑一下。 本文遵从署名-相同方式共享4.0国际协议(CC BY-SA 4.0))，这意味着在遵守以下条件的情况下： 署名 您的作品同样遵从署名-相同方式共享4.0国际协议(CC BY-SA 4.0)您可以： 在任意媒介复制、分发本作品 在本作品基础上进行修改、再创作，并且可以用于商业目的我再加一句：若公众号平台内容协议与本文声明协议有冲突，以本文声明协议为准。但我并不清楚这句话是否在法理上有效，尽管按我开通公众号即默认签订的协议来看，此声明似乎为徒劳。我将本文的唯一“阅读原文”链接庄重地献给这一协议，请自行查看——如果您感兴趣且想体验这份滑稽的话。","link":"/posts/da5ae4d8/"},{"title":"Jekyll + GitHub Pages搭建博客笔记","text":"了解Jekyll与GitHub Pages的工作原理Jeklly是基于Ruby的静态网页生成器，可以用于从Markdown文件和Template生成静态网页。 GitHub Pages是GitHub对Repo的附加功能，可以渲染Markdown源文件和伺服生成的静态网页文件，用于部署和更新博客。 建站workflow： 本地搭建Jeklly的运行环境 选择Jeklly主题并进行个性化配置 建立GitHub Repo并开启Pages功能 建立单独的gh-pages分支并将修改后主题推送到远程 如果不需要个性主题，可直接在GitHub官方支持的主题中选择使用，也不需要搭建本地的Jeklly运行环境。 更新workflow： 更新Markdown文件 推送到远程 搭建Jekyll运行环境，安装主题（Linux）Jekyll环境参考： https://jekyllrb.com/docs/installation/ https://help.github.com/articles/setting-up-your-github-pages-site-locally-with-jekyll/ Ruby依赖及环境变量配置： sudo apt-get install ruby ruby-dev build-essential echo &apos;# Install Ruby Gems to ~/gems&apos; &gt;&gt; ~/.bashrc echo &apos;export GEM_HOME=$HOME/gems&apos; &gt;&gt; ~/.bashrc echo &apos;export PATH=$HOME/gems/bin:$PATH&apos; &gt;&gt; ~/.bashrc source ~/.bashrc （Optional）使用国内RubyGems和Bundle镜像（TUNA）： # rubygem gem sources --add https://mirrors.tuna.tsinghua.edu.cn/rubygems/ --remove https://rubygems.org/ # bundle bundle config mirror.https://rubygems.org https://mirrors.tuna.tsinghua.edu.cn/rubygems 安装Jekyll及Bundler gem install jekyll bundler 安装主题及其依赖选择主题：http://jekyllthemes.org/ 下载主题及安装主题所需依赖： git clone theme-source-url path-of-theme-repo cd path-of-theme-repo bundle install 根据主题文档配置_config.yml后进行本地预览： bundle exec jekyll serve 在浏览器打开http://localhost:4000 即可。 集成到GitHub Pages参考：https://jekyllrb.com/docs/github-pages/ 建立Repo存放配置过的主题文件，并将更新commit到新branch gh-pages上，即可去https://username.github.io/repo-name 预览效果。 小结相比Hexo等，使用Jekyll配合GitHub Pages的优势是热更新，一次搭建后只需要更新Markdown文件，无需回到本地运行环境生成网页后推送。","link":"/posts/ed30ba89/"},{"title":"PyCharm+PipEnv本地Python开发环境配置","text":"本文记录基于PyCharm的Python工作环境配置，最终实现的效果是本地修改，远程调试，运行环境可迁移。 准备该环境的配置需要如下准备： 开发用笔记本电脑和部署用服务器 PyCharm Pro版本，如果是学生，可以免费得到这一版本 依赖管理包Pipenv 逻辑是在本地编写和调试代码，调用服务器的计算资源运行，并通过PyCharm和Pipenv保证本地开发环境和服务器端运行环境的一致。 关于Pipenv：Pipenv是一个将pip和virtualenv功能整合在一起的依赖管理包，提倡一个项目一个环境，利用Pipfile存储依赖信息并提供可迁移性。Pipenv为每个项目建立一个virtualenv，并记录pip安装依赖包的版本信息。 环境配置1.（可选）在GitHub等版本控制服务建立repo。2.在服务器上建立项目文件夹，并用命令pipenv install初始化项目环境。3.本地使用PyCharm打开项目（从GitHub，或者新建在本地文件夹），并配置部署环境（Tools-&gt;Deployment-&gt;Configurations)，以SFTP方式连接，并在本地开发项目文件夹和服务器端项目文件夹建立映射。 4.打开Files-&gt;settings-&gt;project settings-&gt;project interpreter，选择add remote，勾选Deployment configuration到上一步建立的配置，选择Move this server to IDE settings。 最后指定好上一步pipenv建立的vitualenv（默认目录为~/.local/share/virtualenvs/）为Python解释器的路径。 5.在Tools-&gt;Deployment-&gt;Download from将服务器代码下载到本地（主要是Pipfile），之后右击项目，将项目文件上传到服务器（本地代码文件），并在Tools-&gt;Deployment勾选Automatic Upload，使本地代码跟服务器代码保持同步。 6.在Tools-&gt;Start SSH Session利用部署配置登录服务器，使用Pipenv来安装需要的依赖后，在本地新建脚本文件进行测试。 工作流1.本地修改代码，自动上传到服务器2.利用SSH处理数据存取路径等问题3.运行脚本（使用远程环境）并调试4.解决报错问题5.调试成功，将代码提交到版本控制服务6.重复","link":"/posts/2da92ac3/"},{"title":"LSTM:Pytorch实现","text":"本文讨论LSTM网络的Pytorch实现，兼论Pytorch库的代码组织方式和架构设计。 LSTMLSTM是一种循环神经网络，适用于对序列化的输入建模。Chris Olah的这篇文章细致地解释了一个LSTM单元的运作方式，建议阅读。 两个想法Gate：信息流动的闸门$$i_t = sigmoid(W_{xi} x_t + W_{hi}h_{t-1} + b_i)$$$$f_t = sigmoid(W_{xf} x_t + W_{hf}h_{t-1} + b_f)$$$$o_t = sigmoid(W_{xo} x_t + W_{ho}h_{t-1} + b_o)$$$x$ 表示输入，$h$表示隐藏状态，用$sigmoid$函数将输入二者的传递结果映射到$（0,1)$上，分别赋予输入门、遗忘门、输出门的含义，来控制不同神经单元（同一神经元不同时间点的状态）之间信息流动。 Cell：记忆池$$c_t = f_t \\odot c_{t - 1} + i_t \\odot tanh(W_{xc} x_t + W_{hc}h_{t-1} + b_c)\\h_t = o_t \\odot tanh(c_t)$$$h$表示隐藏状态，$C$表示记忆池，通过Gate，上一单元（状态）的信息有控制地遗忘，当前的输入有控制地流入，记忆池中的信息有控制地流入隐藏状态。 与普通RNN的对比普通RNN只有一个自更新的隐藏状态单元。 LSTM增加了记忆池Cell，并通过几个Gate将信息有控制地更新在记忆池中，并通过记忆池中的信息来决定隐藏状态。 From Scratch下面是手动实现LSTM的代码，继承了基类nn.Module。 import torch.nn as nn import torch from torch.autograd import Variable class LSTM(nn.Module): def __init__(self, input_size, hidden_size, cell_size, output_size): super(LSTM, self).__init__() self.hidden_size = hidden_size self.cell_size = cell_size self.gate = nn.Linear(input_size + hidden_size, cell_size) self.output = nn.Linear(hidden_size, output_size) self.sigmoid = nn.Sigmoid() self.tanh = nn.Tanh() self.softmax = nn.LogSoftmax() def forward(self, input, hidden, cell): combined = torch.cat((input, hidden), 1) f_gate = self.gate(combined) i_gate = self.gate(combined) o_gate = self.gate(combined) f_gate = self.sigmoid(f_gate) i_gate = self.sigmoid(i_gate) o_gate = self.sigmoid(o_gate) cell_helper = self.gate(combined) cell_helper = self.tanh(cell_helper) cell = torch.add(torch.mul(cell, f_gate), torch.mul(cell_helper, i_gate)) hidden = torch.mul(self.tanh(cell), o_gate) output = self.output(hidden) output = self.softmax(output) return output, hidden, cell def initHidden(self): return Variable(torch.zeros(1, self.hidden_size)) def initCell(self): return Variable(torch.zeros(1, self.cell_size)) 几个关键点： Tensor的大小 信息的传递顺序 Pytorch ModulePytorch库本身对LSTM的实现封装了更多功能，类和函数的组织也非常有借鉴意义。我对其实现的理解基于以下两点展开： 胞(cell)、层(layer)、栈(stacked layer)的层次化解耦，每一层抽象处理一部分参数（结构） 函数句柄的传递：处理好参数后返回函数句柄forward 下面开始按图索骥，源码见GitHub。 LSTM类文件：nn/modules/rnn.py # nn/modules/rnn.py class RNNBase(Module): def __init__(self, mode, input_size, output_size): pass def forward(self, input, hx=None): if hx is None: hx = torch.autograd.Variable() if self.mode == &apos;LSTM&apos;: hx = (hx, hx) func = self._backend.RNN() #!!! output, hidden = func(input, self.all_weights, hx) #!!! return output, hidden class LSTM(RNNBase): def __init__(self, *args, **kwargs): super(LSTM, self).__init__(&apos;LSTM&apos;, *args, **kwargs) LSTM类只是RNNBase类的一个装饰器。 在基类nn.Module中，把__call__()定义为调用forward()方法，因而真正的功能实现在_backend.RNN()中 AutogradRNN函数下面寻找_backend.RNN。文件：nn/backends/thnn.py # nn/backends/thnn.py def _initialize_backend(): from .._functions.rnn import RNN, LSTMCell 原来，_backend也是索引。 终于找到RNN()函数。文件：nn/_functions/rnn.py # nn/_functions/rnn.py def RNN(*args, **kwargs): def forward(input, *fargs, **fkwargs): func = AutogradRNN(*args, **kwargs) return func(input, *fargs, **fkwargs) return forward def AutogradRNN(mode, input_size, hidden_size): cell = LSTMCell rec_factory = Recurrent layer = (rec_factory(cell),) func = StackedRNN(layer, num_layers) def forward(input, weight, hidden): nexth, output = func(input, hidden, weight) return output, nexth return forward RNN()是一个装饰器，根据是否有cudnn库决定调用AutogradRNN()还是CudnnRNN()，这里仅观察AutogradRNN() AutogradRNN()选用了LSTMCell，用Recurrent()函数处理了Cell构成Layer，再将Layer传入StackedRNN()函数 RNN()和AutogradRNN()返回的都是其forward()函数句柄 下面是Recurrent()函数： def Recurrent(inner): def forward(input, hidden, weight): output = [] steps = range(input.size(0) - 1, -1, -1) for i in steps: hidden = inner(input[i], hidden, *weight) output.append(hidden[0]) return hidden, output return forward Recurrent()函数实现了“递归”的结构，根据输入的大小组合Cell，完成了隐藏状态和参数的迭代。 Recurrent()函数将Cell(inner)组合为Layer。 StackedRNN()函数def StackedRNN(inners, num_layers): num_directions = len(inners) total_layers = num_layers * num_directions def forward(input, hidden, weight): next_hidden = [] hidden = list(zip(*hidden)) for i in range(num_layers): all_output = [] for j, inner in enumerate(inners): hy, output = inner(input, hidden[l], weight[l]) next_hidden.append(hy) all_output.append(output) input = torch.cat(all_output, input.dim() - 1) next_h, next_c = zip(*next_hidden) next_hidden = (torch.cat(next_h, 0).view(total_layers, *next_h[0].size()), torch.cat(next_c, 0).view(total_layers, *next_c[0].size())) return next_hidden, input return forward StackedRNN()函数将Layer(inner)组合为栈 最后的最后，一个基本的LSTM单元内的计算由LSTMCell()函数实现。 LSTMCell()函数def LSTMCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None): if input.is_cuda: igates = F.linear(input, w_ih) hgates = F.linear(hidden[0], w_hh) state = fusedBackend.LSTMFused() return state(igates, hgates, hidden[1]) if b_ih is None else state(igates, hgates, hidden[1], b_ih, b_hh) hx, cx = hidden gates = F.linear(input, w_ih, b_ih) + F.linear(hx, w_hh, b_hh) ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1) ingate = F.sigmoid(ingate) forgetgate = F.sigmoid(forgetgate) cellgate = F.tanh(cellgate) outgate = F.sigmoid(outgate) cy = (forgetgate * cx) + (ingate * cellgate) hy = outgate * F.tanh(cy) return hy, cy 观察上面的代码，即是LSTM的基本信息传递公式。至此，我们的旅程完成。 小结 没有什么是增加一层抽象不能解决的，如果不能，那就再加一层。 重复一下我对上述代码的理解： 胞(cell)、层(layer)、栈(stacked layer)的层次化解耦，每一层抽象处理一部分参数（结构） 函数句柄的传递：处理好参数后返回函数句柄forward 如洋葱一般，我们剥到最后，发现处理的信息正是输入、隐藏状态和LSTM单元几个控制门的参数。在一层一层的抽象之中，Pytorch在不同的层面处理了不同的参数，保证了扩展性和抽象层之间的解耦。","link":"/posts/7b4533bb/"},{"title":"MacBook启用侧记","text":"定位，功能的侧重我所使用的版本是12寸的New MacBook，给它的定位是便携的上网本，初衷是希望将iPad上不太方便的输入功能（我认为键盘要胜于触控笔）分离出来，在处理较为复杂的信息（如教材、论文等）能够方便进行检索和笔记等任务。它在我的个人设备中大概处于下面的位置： 生产力在这里主要指对个人学习和产出的帮助。如上图，手机和iPad等可以满足获取信息的需要，但在处理和内化信息方面则相对局限，而笔记本则很好地满足了查阅、创作等需要，但便携性不够。于是我给MacBook的定位即是在维持便携性的同时又能获取较强的生产力。 理想状态中，绿色区域需要一台高性能的台式机。目前笔记本品类中的超级本（如ThinkPad X1, Macbook Pro等）主要分布在红色区域，而从平板电脑的触控出发产生的变形笔记本（如Surface Pro等），则是分布在蓝色区域，这两类也是我日后的升级考虑。 有关硬件的评述硬件方面我是相当满意的。 Pros: 整体重量只有1kg，大小方面相当于一本A4的专业书，便携性非常好。 12寸的屏幕够用，色彩相当丰富。 触控板非常灵敏，手势操作配合系统和应用非常方便 重度使用的续航还不错，一个半天是够的（因人而异），尽管官方宣称是10个小时 Cons: 键盘键程太短，相当不习惯，倒是没有想象中累 接口太少，只有一个Type-C，好在我对其定位并非主力电脑，传输主要依靠网络 应用的选择多平台同步：一个精分的自我修养我的设备包括Mi Mix2(Android), iPad(iOS), MacBook(Mac), ThinkPad(Linux/Windows)，必须要考虑多平台同步的问题。下面是我按信息类型分的处理方式： 大型文件：移动硬盘、U盘、SCP传输等 小型文件：路由器NAS（Samba和FTP服务） 文档和电子书：主力Dropbox和NutStore, Drive, OneDrive, iCloud等，归档后用移动硬盘存储 照片、视频、录音等：源文件由移动硬盘存储，同步至Google Photos和iCloud服务 代码：GitHub和BitBucket托管，客户端Gitkraken(Linux), SourceTree(Mac), Git2Go(iOS), OpenHub(Android) 小型信息（链接、文字、少量图片等）：全平台的PushBullet、Telegram、专有的AirDrop、基于Web的InstaPaper(文章)和RainDrop(链接)等 备份内容（个人证件、配置文件、密钥、密码等）：文件类通过移动硬盘和同步服务，密码等通过LastPass、Google和iCloud账户 笔记和创作应用：富文本还是纯文本笔记指基于学习材料（如教材、论文、电子书）的批注和再创作，特点是需要跟原文进行交互，难以避免的要支持富文本，此时，Evernote, OneNote等笔记类应用比较适用。 而创作，主要指是文字为主的编辑过程。对文学性的创作，基于Markdown语法的写作类应用则更为适用；而知识性的创作，常涉及其他材料的编纂，此时支持富文本的笔记类应用更为合适。但在发布时，常常需要转化为Markdonw格式，笔记便成为草稿。 基于上述分析，我选择了如下几个应用： MarginNote(Mac, iOS)：对教材、专著等进行批注和知识组织，材料通过Dropbox同步，笔记使用iCloud同步 Mendeley(Linux, Mac)：论文的整理和批注，通过Dropbox同步 Evernote(Linux, Mac, Android)：富文本笔记创作（草稿）、知识整理归档等，自有服务同步 OneNote(Windows, Mac)：知识整理归档等，OneDrive同步 Typora/Mark Text(Linux, Mac), VS Code(Linux, Mac)：纯文本Markdown编辑，博文发布维护等，草稿Dropbox同步，代码Git同步 Duokan(iOS, Android), Kindle(Kindle, iOS, Android)：文学类电子书阅读与批注，自有服务同步，不定期导出笔记到Evernote Knotes(Mac), Calibre(Linux, Mac)：Kindle电子书管理，标注管理等，自有服务同步","link":"/posts/7af7bef8/"},{"title":"Python与SQL Server的交互：pyODBC, pymssql, SQLAlchemy","text":"Windows平台下Python读取、写入SQL Server相关的函数库，文章结构如下： Python DriversPyODBCAnnaconda下可以用pip install pyodbc安装，也可以到这里下载。 首先建立connection对象： import pyodbc conn = pyodbc.connect( r&apos;DRIVER={ODBC Driver 11 for SQL Server};&apos; #or {ODBC Driver 13 for SQL Server} r&apos;SERVER=ServerHostName;&apos; r&apos;DATABASE=DBName;&apos; r&apos;UID=user;&apos; r&apos;PWD=password&apos; ) 添加游标（Cursor）对象并执行SQL查询语句： cursor = conn.cursor() cursor.execute(&apos;SQL Query Goes Here&apos;) for row in cursor.fetchall(): print(rows.[column name]) 更多信息参见MSDN DOCs。 pymssql同样可以用pip install pymssql安装，也可以到这里，然后用pip安装wheel文件。 pymssql目前还不支持Python3.6，这点要注意下。 pymssql的用法跟pyODBC很像，下面是官网给出的例子： from os import getenv import pymssql server = getenv(&quot;PYMSSQL_TEST_SERVER&quot;) user = getenv(&quot;PYMSSQL_TEST_USERNAME&quot;) password = getenv(&quot;PYMSSQL_TEST_PASSWORD&quot;) conn = pymssql.connect(server, user, password, &quot;tempdb&quot;) cursor = conn.cursor() cursor.execute(&quot;&quot;&quot; IF OBJECT_ID(&apos;persons&apos;, &apos;U&apos;) IS NOT NULL DROP TABLE persons CREATE TABLE persons ( id INT NOT NULL, name VARCHAR(100), salesrep VARCHAR(100), PRIMARY KEY(id) ) &quot;&quot;&quot;) cursor.executemany( &quot;INSERT INTO persons VALUES (%d, %s, %s)&quot;, [(1, &apos;John Smith&apos;, &apos;John Doe&apos;), (2, &apos;Jane Doe&apos;, &apos;Joe Dog&apos;), (3, &apos;Mike T.&apos;, &apos;Sarah H.&apos;)]) # you must call commit() to persist your data if you don&apos;t set autocommit to True conn.commit() cursor.execute(&apos;SELECT * FROM persons WHERE salesrep=%s&apos;, &apos;John Doe&apos;) row = cursor.fetchone() while row: print(&quot;ID=%d, Name=%s&quot; % (row[0], row[1])) row = cursor.fetchone() conn.close() 详细用法参见pymssql docs和MSDN DOCs SQLAlchemy(Python SQL Toolkit)SQLAlchemy提供了一系列丰富、完整、（我看不懂）的API用于数据库操作。这里只谈其create_engine方法。 from sqlalchemy import create_engine # pyodbc engine = create_engine(&apos;mssql+pyodbc://user:password@DSNname&apos;) #需要配置DSN，参见最后一节 # pymssql engine = create_engine(&apos;mssql+pymssql://user:password@Hostname:port/DBname&apos;) 利用创建好的engine，可以结合pandas库进行批量的读取、写入操作。 用SQLAlchemy与其他类型的数据库建立链接的方法参见这里。 Pandas利用pyODBC和pymssql拉取的对象需要进一步处理才能进行常见的数据清洗等工作，而Pandas也提供了SQL相关的方法，在SQLAlchemy的辅助下，可以将DataFrame对象直接写入table。 读取：pd.read_sql()API： pandas.read_sql(sql, con, index_col=None, coerce_float=True, params=None, parse_dates=None, columns=None, chunksize=None) 其中的con参数，可以传入SQLAlchemy建立的engine对象，也可以是pyODBC或者pymssql建立的DBAPI2 connection对象。 写入:pd.DataFrame.to_sql()API: DataFrame.to_sql(name, con, flavor=None, schema=None, if_exists=&apos;fail&apos;, index=True, index_label=None, chunksize=None, dtype=None) 这里的con参数，只支持sqlite3的DBAPI2 connection对象，支持所有的SQLAlchemy engine对象。name参数传入表名，用if_exists参数控制表存在时的动作： ‘fail’: 啥也不干。 ’replace‘: 将原有表删除，新建表，插入数据。 ’append&apos;: 在表中插入数据。表不存在时新建表。 命令行利用Sqlcmd命令，也可以在命令行下执行SQL文件，用法如下： sqlcmd -U user -P password -S server -d DBName -i /path/to/myScript.sql 这样可以有如下思路，将数据写入.SQL文件，再生成.bat文件（批量）写入上述命令，之后完成执行。 DSNWindows下可以配置DSN(Data Source Names)预先存储数据库连接的信息，在Control Panel -&gt; Administrative Tools -&gt; ODBC Data Source 下添加即可。 配置好DSN后，pyODBC的连接过程可以简化为： conn = pyodbc.connect(r&apos;DSN=DSNname;UID=user;PWD=password&apos;) #UID和PWD也可以在DSN中配置 拾遗Python与文件的IO、SQL数据库的读写时有中文字符可能会有编码问题。一种方案是在中文字符串前添加N，如N&apos;python大法好&apos;；另一种方案是传入encoding参数，常用的中文编码有GB2123，GB18030，推荐的还是统一用UTF-8编码、解码。 利用如下命令，可以在SQLAlchemy中指定编码： engine = create_engine(&apos;mssql+pymssql://user:password@HostName\\DBname&apos;, connect_args = {&apos;charset&apos;:&apos;utf-8&apos;}) 其他自定义DBAPI connect()参数的方法参见这里。","link":"/posts/8f1c0ee0/"},{"title":"The Devtools Way: devtools+RStudio快速R程序包开发","text":"本文记录我的首个R程序包MCMI的开发过程。 参考资料 两本Hadley Wickham写的书：Advanced R和R Packages。 Coursera上的课程Mastering Software Development in R Specialization和配套教材Mastering Software Development in R。 感谢开源社区，以上的资料都可以免费获取得到（Coursera课程可以申请补助）。 Preparation开发R包还需要系统中存在编译工具，编译文档需要LaTeX支持。 Linux用户：sudo apt-get install r-base-dev texlive-full Windows用户：1.RTools;2.MikTeX 另外，请确保以下两个包已安装于系统中：devtools和roxygen2。推荐使用RStudio。 Get Started在RStudio中新建项目，选择R程序包类型即可。建议同时建立Git路径以监控开发流程。 在编写代码之前，先要修改DESCRIPTION文件，要注意的几个地方： Package的命名要容易记忆和查询 Depends指你所用开发环境的R版本 慎重选择License Imports指你所要调用的其他包，但在代码中，也要明确指出函数所处的包，如ggplot2::qplot() Git Workflow建议在GitHub上为本机申请SSH密钥，并在RStudo-&gt;Tools-&gt;Global Options-&gt;Git/SVN配置好路径，这样在执行git push时不用再次输入凭据。下面是有关Git的工作流： 修改代码/文档 编译，测试 git commit git push 重复以上循环 RStudio对Git的集成很好，以上三四步操作均可在Git的操作面板里完成。 Code Workflow 修改代码 Build&amp;Reload 用命令行测试功能 重复以上循环 上述第二步可以在命令行中devtools::load_all()完成，也可以使用快捷键”Ctrl + Shift + L”，也可以在RStudio的开发面板中执行”Build&amp;Reload”命令。之后，便可在命令行中调用编写好的函数，验证其功能。 Documentation Workflow 在.R文件中添加roxygen注释 Document 使用help面板或?命令预览文档 重复以上循环 同样地，第二步有三种实现方式：1.devtools::document();2.”Ctrl + Shift + D”；3. RStudio开发面板中的”Document”命令。 Test Workflow测试方面，除了上述Coding Workflow中提到的在命令行中调用函数进行测试之外，还可以利用testthat包来使测试自动化。 首先要安装testthat包，再使用devtools::ust_testthat()命令建立testthat路径。 下面是自动化测试的工作流： 修改代码 在testthat路径下编写相应的测试语句 Build&amp;Reload Test 排除Bug，重复上述过程 以上流程第四步同样有三种实现方式：1.devtools::test();2.”Ctrl + Shift + T”;3.RStudio中开发面板的“Test”命令。 Release按照上述过程开发的R程序包，每一次git push事实上都是一次发布。使用devtools::install_github(&quot;git_repo_goest_here&quot;)命令，可以很方便地安装R程序包。 Next Step使用devtools配合RStudio和Git，开发R包的过程已经非常亲民和流水线化。但要开发高质量的R包，需要对R的数据结构和S3等对象系统有更深的理解，而Advanced R则是你通往这一方向的最好伴侣。","link":"/posts/923b22f3/"},{"title":"Tensorflow最佳实践：试验管理","text":"本文主要记录使用TensorFlow训练模型中与试验管理相关的最佳实践，主要包括模型训练的大致代码框架、模型的保存与恢复、训练过程的监测、随机性的控制等。主要材料来自CS 20SI: Tensorflow for Deep Learning Research。 TensorFlow代码框架使用TensorFlow构建深度网络模型大致包括数据预处理、图的构建、模型训练、模型推断与评估等部分，大致的代码框架如下： import tensorflow as tf import numpy as np # Data X = tf.placeholder(&quot;float&quot;, [None, n_input]) Y = tf.placeholder(&quot;float&quot;, [None, n_output]) # Parameters W = tf.Variable(tf.random_normal([n_input, n_output])) b = tf.Variable(tf.random_normal([n_output])) # Define model y = tf.matmul(x, W) + b y_pred = tf.nn.relu(y) cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_pred, y_true)) optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(cost) # Training with tf.Session() as sess: tf.initialize_all_variables().run() sess.run(optimizer, feed_dict={X: x_data, Y: y_data}) # Prediction y_test = tf.nn.relu(tf.matmul(x_test, W) + b)) 模型的保存与恢复一个很深的网络训练成本是比较高的，因而将模型定期保存（写入硬盘）则有必要。这里的模型，实际上是有组织的一批数据，包括图的结构描述、参数当前值等。因而我们要保存的不仅是模型，还有模型当前的运行状态，实际上每一次保存可以作为一个还原点。 tf.train.Saver类使用tf.train.Saver类需传入以下参数：tf.train.Saver.save(sess, save_path, global_step=step)。 首先定义步数变量：self​.​global_step ​=​ tf​.​Variable​(​0​,​ dtype​=​tf​.​int32​,​ trainable​=​False​,name​=​&apos;global_step&apos;) 在模型训练的过程中插入还原点的保存： self​.​optimizer ​=​ tf​.​train​.​GradientDescentOptimizer​(​self​.​lr​).​minimize​(​self​.​loss​,global_step​=​self​.​global_step) saver ​=​ tf​.​train​.​Saver​()​​ ​with​ tf​.​Session​()​​as​ sess: sess​.​run​(​tf​.​global_variables_initializer​()) average_loss ​=​​0.0 for​ index ​in​ range​(​num_train_steps​): batch ​=​ batch_gen​.​next​() loss_batch​,​ _ ​=​ sess​.​run​([​model​.​loss​,​ model​.​optimizer​], feed_dict​={...}) average_loss ​+=​ loss_batch # Save model every 1000 steps ​if​​(​index ​+​​1​)​​%​​1000​​==​​0: saver​.​save​(​sess​,​​&apos;checkpoints/model&apos;​,​ global_step​=​model​.​global_step) 在训练过程中，在checkpoints路径下会存储一系列的还原点文件，要恢复session到某个还原点，可使用如下代码：saver.restore(sess, &apos;checkpoints/name_of_the_checkpoint&apos;)。 Keras封装：keras.callbacks.ModelCheckpoint()Keras对TensorFlow进行了高层的封装，使用一系列回调函数keras.callbacks.Callback()来进行试验管理。 模型保存ModelCheckpoint()需要传入的参数：keras.callbacks.ModelCheckpoint(filepath, monitor=&apos;val_loss&apos;, verbose=0, save_best_only=False, save_weights_only=False, mode=&apos;auto&apos;, period=1) 实际的使用中，将上述回调函数类传入model.fit()过程即可： from keras.callbacks import ModelCheckpoint model = Sequential() model.add(Dense(10, input_dim=784, kernel_initializer=&apos;uniform&apos;)) model.add(Activation(&apos;softmax&apos;)) model.compile(loss=&apos;categorical_crossentropy&apos;, optimizer=&apos;rmsprop&apos;) checkpointer = ModelCheckpoint(filepath=&apos;/checkpoints/weights.hdf5&apos;, verbose=1, save_best_only=True) model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=0, validation_data=(X_test, Y_test), callbacks=[checkpointer]) 模型训练过程的监测训练过程中，我们常常需要提取阶段性的信息来评估模型是否符合预期效果。 tf.summary首先创建想要观察指标的tf.summary对象： with tf.name_scope(&quot;summaries&quot;): tf.summary.scalar(&quot;loss&quot;, self.loss) tf.summary.scalar(&quot;accuracy&quot;, self.accuracy) tf.summary.histogram(&quot;histogram loss&quot;, self.loss) # merge them all self.summary_op = tf.summary.merge_all() tf.summary是一种operation，因而可以随训练过程一同运行：loss_batch, _, summary = sess.run([model.loss, model.optimizer, model.summary_op], feed_dict=feed_dict) 最后，将summary加入writer以写入文件： with tf.Session() as sess: writer ​=​ tf​.​summary​.​FileWriter​(​&apos;./summary&apos;​,​ sess​.​graph) for​ index ​in​ range​(​num_train_steps​): writer.add_summary(summary, global_step=step) writer.close() 这样，就可以用TensorBoard监测我们关心的指标在训练过程中的变化情况。 Keras封装：keras.callbacks.TensorBoard()Keras同样将TensorBoard封装成回调函数的形式，在模型训练时进行调用即可： from keras.callbacks import TensorBoard tensorboard = TensorBoard(log_dir=&quot;./logs&quot;) model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=0, validation_data=(X_test, Y_test), callbacks=[tensorboard] 随机性的控制TensorFlow中随机性的控制分为operation和graph两个层面。 Operation层面在Operation层面中，建立随机seed之后，新建立的Session每一次调用sess.run()都会遵循同一随机状态： c ​=​ tf​.​random_uniform​([],​​-​10​,​​10​,​ seed​=​2) with​ tf​.​Session​()​​as​ sess: print​ sess​.​run​(​c) # &gt;&gt; 3.57493 with​ tf​.​Session​()​​as​ sess: print​ sess​.​run​(​c) # &gt;&gt; 3.57493 而且，不同的operation可以保存自己的seed: c ​=​ tf​.​random_uniform​([],​​-​10​,​​10​,​ seed​=​1) d ​=​ tf​.​random_uniform​([],​​-​10​,​​10​,​ seed​=​2) with​ tf​.​Session​() ​​as​ sess: sess​.​run​(​c) sess​.​run​(​d) Graph层面在Graph层面，整张图公用一个随机状态，多次运行同一图模型的计算，其随机状态保持一致。 import​ tensorflow ​as​ tf tf​.​set_random_seed​(​2) c ​=​ tf​.​random_uniform​([],​​-​10​,​​10) d ​=​ tf​.​random_uniform​([],​​-​10​,​​10) with​ tf​.​Session​()​​ as​ sess: sess​.​run​(​c) sess​.​run​(​d) @ddlee","link":"/posts/55919299/"},{"title":"RSS：给你所爱的人以自由","text":"推荐您观看下面的介绍和演示视频（一首半歌的时间），音乐无内容，可以静音观看。若已看过，可以跳至下面的“常见问题”一节。 跳转到BiliBili播放：RSS订阅：介绍与演示 订阅的过去和现在粗看来，信息流动的参与主体可以分为信息提供者和信息消费者。 报纸、杂志等是相对原始的订阅模式，提供者和消费者构成二元图：提供者负责产出和发送内容，消费者选择是否订阅。后来，节点越来越多，分发上越来越困难。 平台，作为一个信息整合者（Aggregator）应运而生，互联网初期的门户网站（Yahoo!）、后来的搜索引擎（Google），都是当时最成功的信息整合者形态。对应到普通商品市场上，超市（相对品牌直营店），则扮演了整合者的角色。 一方面，平台方便了信息的分发；另一方面，平台也在隐性地筛选内容提供者：他们常常掌握了大量的消费者，议价能力更高。不仅如此，平台在信息流动过程中加入推荐内容和广告，进一步重塑了内容的形态。平台，也在影响着内容。 试思考： 哪些内容是我们自愿看到的？ 哪些内容是被平台推荐的？ 哪些内容又被平台忽略了？ 再思考： 我们做出了哪些选择？ 平台替我们做出了哪些选择？ 哪些本应成为选择的，却被剥夺了？ 那么，什么是RSS？RSS全称Rich Site Summary，是一项格式标准，允许内容提供者按一定格式组织和发布内容，方便内容消费者抓取。你甚至可以认为，它是一项信息提供者和消费者之间的“契约”。 所以，为什么使用RSS？在我看来，有这样几点好处： RSS不是平台，它是信息的一种组织方式而已，也就不存在准入。她是被Offer，而不是被Permit。 RSS不提供推荐，它最大限度地保持着原有信息形态。读者相对而言也较难落入“回声壁效应”（当你赞同某一观点时，你会听到越来越多赞同这个观点的声音，而且这一过程是自我强化的）。RSS很安静，她不去猜你喜欢什么。 RSS允许我们在一个应用内统一集中处理来自不同来源的信息。RSS是一层轻量的抽象，她让信息的提供方和信息的消费方解耦，进而给双方更多选择。这样对我们都好。 如何使用RSS？原则上来说，我们只需要一个支持RSS的客户端即可。但使用RSS服务提供的账号体系和同步功能，可以让我们在多个平台上无缝衔接自己的阅读体验。下面提供一个三步的使用方式： 寻找作者提供的RSS源 将RSS源添加到订阅列表 使用客户端按照订阅列表抓取文章内容 步骤一：寻找RSS源（URL）方法一：RSS标识 此为RSS的通用标识，循此LOGO便容易找到RSS源的链接 方法二：rss/atom文件 RSS内容常被组织为扩展名为“.xml”的静态文件（被命名为rss或atom），网络上的大部分博客往往以此形式提供自身内容。https://distill.pub/rss.xml便是这样的例子 方法三：检索关键词 检索“提供方名+RSS”这样的关键词，也能方便地找到我们需要的URL，而如果使用RSS服务的话，也可以在RSS服务提供的索引内检索。 步骤二：在RSS服务上添加源到订阅列表这里举例使用Feedly，替代品见文末。 注册账号（略） 找到“添加内容”，粘贴上一步中找到的URL链接 Feedly会自动抓取最新的内容，可以在线阅读内容成功抓取到内容后，事实上已经完成了信息的传递过程。不过，我们希望在多个平台上同步阅读，下面以macOS上的Reeder为例，说明配置RSS客户端的过程（当然，Feedly也提供了自己的客户端，但我们有更多选择）。 步骤三：使用客户端同步这里举例 Reeder ，替代品见文末。实际上只需要将我们的Feedly账户授权给Reeder，Reeder便会自动同步内容。阅读之后，我们可以选择收藏、分享等后续操作。使用RSS服务的好处便是，我们可以使用手机粗读文章，标记需要精读或是标注、分享的文章，在电脑端同步时，阅读状态和标记都是一致的。而跳过第二步，直接使用Reeder抓取RSS源时，便不能在其他设备上同步阅读状态了。即便如此，我们依然可以将自己的订阅列表导出为OPML文件，进而在不同设备上迁移自己的订阅。 常见问题Q：谁是Aaron Swartz？谁是李东东？A：Aaron Swartz是一名程序员、黑客、创业者、社会活动家，他参与RSS、Creative Commons和Reddit等的组织和开发工作，于2013年入选互联网名人堂（Internet Hall of Fame），纪录片《互联网之子》就是关于他的故事。李东东就是我啊老铁。 Q：所以RSS到底是什么的缩写？可以再说一遍吗？A：我在视频里选用的是Rich Site Summary，另外还有一个更流行的称谓是Really Simple Syndication（简易同步），前者强调其格式性，后者强调目的：方便更新同步。我在视频里更想跟平台做比较，突出其干净简洁之处。 Q：这个RSS到底跟微信订阅号有什么区别？A：从作者角度看，微信订阅号是一种发布平台，而RSS是一种发布格式，换言之，作者的内容可以先发布为RSS订阅源（RSS feed），再通过程序自动地抓取这一内容，上传至微信订阅号、头条号、Facebook主页、微博等处。从读者角度看，微信订阅号是微信公众平台的独占内容，你不能通过今日头条的APP阅读到微信订阅号的内容。但你可以通过支持RSS的客户端同时阅读到来自发布在微信公众号、今日头条、知乎专栏、豆瓣动态、普通的个人博客等等不同来源的内容（几乎，网络上的全部内容），只要将各自的RSS订阅源添加到订阅列表就可以做到。不过，微信越来越封闭，防止自家内容外流，很多爬取公众号文章的服务都被关停。仍然有别的方法可以试图取代或是减少依赖，请参见下一条问题。最后，从推送时机来看，微信订阅号的内容在作者发布之时被推送，对读者而言是分散的。但RSS的抓取时机则完全由读者掌控，抓取时会检查作者是否有更新，所有订阅的RSS源是一同被抓取的，而非时时刻刻在打扰你。 Q：有部分感兴趣的内容不提供RSS，怎么办？A：诚然，并不能保证RSS可以囊括网络上的一切内容（显然的例子是付费内容便不能被轻易完整获取），毕竟创作者也有自己的选择，部分作者仅仅在一个平台上发布内容，而那个平台却又足够封闭，这当然很无奈。不过，还是有下面几种可能的解决方式提供给你：寻找其他平台某些媒体往往会将内容上传多个平台，此时我们可以寻找其他平台上的同作者内容。例如，公众号文章相对较难获取，但知乎专栏的文章较容易抓取，这里便是一个知乎动态/专栏转RSS的服务。寻找第三方源部分内容的RSS难以获取是技术原因导致（而非内容不可得），但社区常常会有志愿者提供这些第三方源（如feedx）。此外，RSS服务也提供检索列表，我们可以尝试在这些列表内寻找。自己通过工具制作 静态网页：通过HTML Tag指定页面上需要的内容，如feed43 动态内容：自建RSS服务，如RSSHub（视频初的展示部分效果归功于此项目） 这些工具有一点儿门槛，但它们让我们更为强大（empower）。 Q：RSS的输出不是全文而只是摘要A：这一点上，RSS本身也算是一个catalog，仅输出摘要也是可以理解的（当然也有RSS格式版本的问题，这里不表）。除了向上一条问题那样自行检索第三方提供的源或是动手制作外，或许还可以通过工具转换：FeedEx.net, fivefilters。 Q：使用RSS还可以做什么？A：使用其他工具整合RSS很多邮箱（如Outlook）、浏览器（如FireFox）整合了RSS功能，此时，你可以基于这些工具打造集中的信息获取入口。 学术文献管理软件的RSS订阅跟踪新的研究动态是很基本的需求，我们可以为某一检索条件生成RSS。您可以在这里找到订阅arxiv文章RSS源的信息。 将RSS发送到Kindle如果订阅的RSS内容适合沉浸式的阅读，可以尝试这样的转换服务。 Q：你平时怎样使用RSS？A：我将RSS订阅分为了四部分，分别在不同客户端以不同频次处理。具体而言，论文查新单独开一个入口，书评动态、剧集更新、优惠信息等琐事内容单独一个入口，这两者都通过Telegram的bot处理。主要的新闻、博文等，分英文和中文内容两个账号同步，英文RSS一周阅读两次，都在电脑端，中文RSS内容每天约80-100条，先用手机粗读筛选，标记“需细读”或是“收藏”等状态，用时约8-10分钟，之后标记过的文章会在电脑端同步过来，进行细读或是收藏分享等。以上通过RSS获取的信息占我每天信息摄入量的50%左右，剩下有30%是网页搜索，10%来自邮件订阅，最后10%则来自社交网络、论坛等。 Q：好了我决定尝试一下，我该从哪开始？A：我建议您执行以下步骤： 审视自己每天获取信息的来源（网站、APP等），判断内容是否具有被平台过度重塑的特征（例如，某些内容被屏蔽，推荐内容过于标题党） 列出一份不同平台的作者列表，查询它们是否有便于整合为RSS的发布渠道，或者，直接在Feedly等服务上检索 根据下面的建议挑选适合自己硬件设备的RSS服务及客户端，检索RSS源，构建自己的订阅列表 减少1.中所述的APP/网站使用频次，在使用中修整和增长自己的RSS订阅列表 如果您只是开辟RSS为新的信息获取来源，我在这里维护了一份自己的信息来源列表，提供的链接均为RSS源，可以直接复制添加。另外，可以参考知乎讨论：你必读的RSS源有哪些-知乎，或者使用这一个RSS源搜索引擎。 推荐的服务与应用服务Feedly: Follow RSS extension(Chrome, FireFox&amp;Safari) Feedly APP(iOS&amp;Android) InoReader: InoReader Companion(Chrome, FireFox&amp;Opera) InoReader APP(iOS&amp;Android) NewsBlur少数派有一篇对三者的对比文章，我则在使用InoReader。 客户端您可以自行检索自己熟悉平台下的客户端选择。下面我仅推荐我正在使用的选项： Windows &amp; GNU/Linux: WINDS Android: FeedMe iOS &amp; macOS: Reeder如果无法使用Google Play服务，推荐在酷安、apkpure等处寻找和下载应用。 结语我鼓励您尝试RSS，尽管它可能难以全部将您自己的阅读体系替代，但至少提供了一个选项。如果您想了解更多我对于信息获取与处理的态度，推荐您阅读我的信息方法论。如果您想成为一个提供RSS内容的创作者，推荐您阅读在线文字创作不完全指南。感谢您的阅读时间。","link":"/posts/5768c6d/"},{"title":"个性化你的Ubuntu-2：GNOME安装与工具","text":"GNOME安装从上一篇文章，大家可以看到，GNOME是一系列软件的集合，安装时可以有不同的取舍。对于Ubuntu用户来说，可以有以下两类体验GNOME的方式。（参考：GNOME installation） 1.Ubuntu GNOME（系统）Ubuntu GNOME是Ubuntu的一个发行版本（也称Ubuntu variants），就像Ubuntu和Fedora等都是GNU/Linux的发行版那样。Ubuntu GNOME不仅包含了Ubuntu的核心部分、GNOME的核心部分，还有一系列的标准应用。 Install from DVD如果可以接受重新安装系统，请到这里下载Ubuntu GNOME。 Install with current system你也可以通过安装metapackage，这样在安装GNOME桌面环境时，你的系统中未安装的标准应用也会被同时安装。 sudo apt-get install ubuntu-gnome-desktop 2.GNOME（仅桌面环境）The “real” GNOME标准的GNOME桌面环境，没有Ubuntu的特性（尽管我区分不出哪些是Ubuntu提供的），也不安装附加的标准应用： sudo apt-get install gnome The minimux GNOMEGNOME的核心部分，不安装附加的标准应用： sudo apt-get install gnome-core GNOME shell仅安装GNOME的图形界面：sudo apt-get install gnome-shell 你还需要：sudo apt-get install gnome-session 注意在同一系统上安装不同的桌面环境可能会造成一些意料不到的问题（如锁屏界面丢失），最推荐的方案还是重新安装Ubuntu GNOME，其次，可以安装ubuntu-gnome-desktop。 使用新的桌面环境安装完毕后，重启，可在登录界面选择桌面环境。 GNOME配置工具：gnome-tweak-tool想要充分个性化GNOME桌面环境，扩展GNOME的功能，你还需要安装GNOME的配置工具：gnome tweak tool sudo apt-get install gnome-tweak-tool 利用gnome tweak tool，你可以管理桌面主题、调整窗口特性、调整显示字体、加载GNOME扩展、管理开机自启程序等等。 扩展插件在Ubuntu上，要调整桌面主题，可没有Windows上鼠标右击一下那么简单。你要先安装上面的tweak tool，然后有人告诉你需要User theme扩展插件，而你跑到extensions.gnome.org，遇到的却是这个： 我明明装了GNOME的啊！ 这是因为，extensions.gnome.org需要与浏览器通信，调用click-to-play的功能，我们需要安装GNOMNE shell intergration这个插件。 Chrome用户利用PPAsudo add-apt-repository ppa:ne0sight/chrome-gnome-shell sudo apt-get update sudo apt-get install chrome-gnome-shell 通过Chrome Web Store:GNOME Shell integration可能需要通过CMake安装native connector,请参考这一页面。 FireFox用户使用FireFox访问extensions.gnome.org时会有运行GNOME shell integration的通知，允许运行后刷新即可。 更多信息，请参考这一页面 安装好tweak-tool后，祝贺你已经打开了新世界的大门。下篇文章是关于扩展插件的推荐，欢迎继续阅读。 @ddlee","link":"/posts/938c3141/"},{"title":"个性化你的Ubuntu-3：主题，插件以及桌面小工具","text":"个性主题依赖于扩展User themes，分为GTK主题，shell主题和icon主题。 从gnome-look.org下载喜欢的主题（压缩文件）。 将下载的主题文件复制到用户文件夹 cd ~ mkdir .themes cp file_path_to_download_file ~/.themes 并使用unzip或tar xvzf命令解压，或者： sudo cp file_path_to_download_file /usr/local/themes/ 在gnome-tweak-tool的扩展User themes中选择主题。 推荐主题我使用的是Numix系列的主题（官网） Numix-GTK3 theme Numix-like GNOME Shell theme Numix-Circle Icons Numix开发者之一Satyajit Sahoo发布的GNOME shell theme:Gnome Shell - Elegance Colors 通过PPA安装 sudo apt-add-repository ppa:numix/ppa sudo apt-get update sudo apt-get install numix-gtk-theme sudo apt-get install numix-icon-theme-circle sudo add-apt-repository ppa:satyajit-happy/themes sudo apt-get update &amp;&amp; sudo apt-get install gnome-shell-theme-elegance-colors 扩展插件我当前使用的插件： hide dash：隐藏侧边的favorite栏 Pomotodo：番茄时钟 （荐）Clipboard indicator：剪贴板切换 ToDo.txt：待办事项整理 Places indicator：文件浏览器的快捷方式 Activities configurator: 当前活动程序管理 Alternatetab: alt-tab桌面切换 Applications menu：类似Windows下开始菜单 （荐）Drop down terminal：快捷启动终端 Netspeed：网速监控 Openweather：状态栏天气预报 Removable drive menu：弹出U盘等可移除硬件 （荐）Dynamic top bar：根据窗口颜色变换顶栏颜色 其他桌面工具DOCK推荐Cairo-Dock，效果如图，扩展性很高，自定义程度也很好。 CONKY：桌面监测工具推荐Conky，皮肤也有很多，效果如图。 本系列至此完结。欢迎入坑。 @ddlee 2016年6月","link":"/posts/f74f7d22/"},{"title":"再次折腾我的WNDR4300：OpenWrt文件共享","text":"生命不惜，折腾不止。 缘起再次成为IOS用户后，访问Google和文件共享成了两大需求。问题出现了，就要解决，于是有此文记录的活动。 重新安装OpenWrtOpenWrt已经到了15.05版本，版本代号是Chaos Calmer。重装需要的-factory.img，可以在这里下载。 我的WNDR4300平台是ar71xx，可以从OpenWrt对应的硬件主页找到固件镜像文件。 TFTP重装如果你的路由器还是出厂系统的话，可以通过登入后台在线上传镜像文件进行刷机，而我的已经是OpenWrt系统，只能通过网页端升级，故选用了TFTP方式刷机。 刷机步骤摘自OpenWrt wiki set a static IP on your computer, i.e 192.168.1.35, and connect the ethernet cable to the router power on the router press and hold the RESET button as soon as the switch LEDs light up. keep holding RESET until the power LED begins to flash orange and then green. once the power LED is flashing green, release RESET start the TFTP transfer to router at 192.168.1.1. In your computer execute:tftp 192.168.1.1 -m binary -c put factory.img 总体来说是分为三步： 将电脑与路由器设置在同一内网中 令路由器进入恢复模式 利用TFTP将刷机包推入路由器 U盘挂载，文件共享安装好OpenWrt后，就可以从网页端访问路由器，设置PPPoE拨号，设置WIFI等等。 U盘挂载U盘挂载部分主要参考了跟 UMU 一起玩 OpenWRT（入门篇6）：挂接 U 盘。 首先是安装相应的包： opkg update # 核心包 opkg install kmod-usb-storage opkg install kmod-scsi-generic # 文件系统 opkg install kmod-fs-ext4 # 辅助工具 opkg install usbutils fdisk e2fsprogs 利用lsusb命令查看U盘是否已经被路由器识别。 这时可以选择用fdisk进行重新分区，不需要分区的话，可以用命令ls /dev | grep sd查看/dev分区中是否已经出现U盘。 在OpenWrt上使用U盘，建议用ext4格式，可以用下面的命令进行格式化： # sda1为上一命令得到的结果 mkfs.ext4 /dev/sda1 接下来就可以用mount命令进行挂载了： # 路径/mnt/usb/即为挂载目标点 mkdir /mnt/usb touch /mnt/usb/USB_DISK_NOT_PRESENT chmod 555 /mnt/usb chmod 444 /mnt/usb/USB_DISK_NOT_PRESENT mount /dev/sda1 /mnt/usb 这时可以测试一下，如果U盘里面存储了文件，可以通过/mnt/usb访问的到。 下面是开机自动挂载U盘的命令。 # block-mount blkid用于查看U盘的UUID opkg install block-mount blkid # 实际上要操作的是fstab的配置文件/etc/config/fstab，要将enabled值改成1 block detect &gt; /etc/config/fstab uci set fstab.@mount[-1].target=&apos;/mnt/usb&apos; u ci set fstab.@mount[-1].enabled=1 uci commit fstab 更详细的信息可以参见这里 文件共享文件共享可以通过FTP和SAMBA，推荐的方式是SAMBA。 SAMBA安转SAMBA： opkg update opkg install samba36-server # luci程序，可选 opkg install luci-app-samba 安装好SAMBA后，主要配置两个参数，一是共享文件夹的路径，如/mnt/usb/sambashare，可以通过更改配置文件/etc/samba/smb.conf实现，也可以通过luci实现。 示例： [sambashare] path = /mnt/usb/sambashare valid users = root read only = no guest ok = yes create mask = 0750 directory mask = 0750 第二个参数是访问账户，可以通过命令sambpasswd -a将你的当前用户加入到SAMBA的组中，需要设置一个密码。另外，可能需要将配置文件/etc/samba/smb.conf的[global]中的invalid users = root注释掉。 最后，设置SAMBA服务启动和开机自启 /etc/init.d/samba start /etc/init.d/samba enable FTPFTP可以用vsftpd包来设置，大致过程与SAMBA类似：设置路径、添加用户、设置自启。 SAMBA服务可以在Windows文件资源管理器中自动检测的到，Linux下可以通过smb://Host/sharepath访问，在IOS系统中，类似Documents的应用也支持添加SAMBA的功能。 这里强推一下Documents这个应用，结合PDF EXPERT，已经成为了我的文档中心。 后记这天的活动，本来只有我和上帝知道，再过一个月，就只有上帝知道了。遂作笔记。 @ddlee","link":"/posts/c99180ec/"},{"title":"博客改版与优化","text":"最近，花了两个下午的时间更换了博客主题，并做了少许优化，朝向极简主义风格又迈进了一步。 缘起主要的动力还是访问速度上的需要。原先使用的Hexo主题Material为每篇博文都配有Material Design风格的图片，且支持很多插件功能，部署后公共文件夹的体积为18M左右。而且在今年7月份左右我无法继续享受腾讯云的1元主机优惠，伺服服务器迁移至美国西海岸，延迟上要远比国内的服务器高，便产生了改版的打算。现在更换的主题为Minos，吸引我之处在于其简洁和Medium风格。改版后抛弃了几乎所有的内容无关的图片（当然其实这些图片是存储于七牛云的CDN上的），且移除了很多我并不需要的插件，部署的公共文件夹大小只有不到5M。配色方面也回归原始的黑和白，更突出文字。 CDN优化添加了腾讯云的存储和CDN作为国内解析源，境外则使用了Netlify的服务，即目前域名的解析线路为： 境内：腾讯云CDN 境外：Netlify服务 默认：位于美国西海岸的VPS主机所幸部署方面Hexo都有相应的插件支持，通过ping检测工具也确认了这些解析归属。 分享链接所使用的主题提供了addThis的服务，可以实现自定义的分享按钮、推广banner等功能，但我测试后发现加载时间过长，遂提供了复制文章链接和二维码扫描两个按钮作为分享手段，回归到链接的方式，不必受各种平台API的限制。 评论系统改版后我移除了评论系统。主要的考虑自然仍是disqus的国内加载速度问题，况且以我的经验这一评论系统并没有带来很好的讨论效果。将来应该会考虑的方案是提供加载代理，但目前限于精力不再花费时间。 字体之前一直使用Chrome的微软雅黑字体渲染插件，对中文字体的认识相对单一。后来经常在Medium上读文章，并拥有了一台Mac设备，恍然发现字体对网页观感的重要性。于是，过去的几个月，我使用Adobe提供的TypeKit服务为自己的几个小站提供了思源字体的动态支持，虽需一定的加载时间，但观感上对全平台来说更为统一。在这一轮优化中，我将本博客的字体用重新换为各平台的安全字体，节省加载时间和渲染压力，非常喜欢的思源字体仅在随笔类的博客里使用。 添加Gallery添加了一个单独的“影像”页面来收集图片，同样采用七牛云的CDN作为图床。 拾遗我用archive.org给自己原来的主题建立了一份存档，可以在这里找到。也算是在互联网世界存在的证据了罢。","link":"/posts/8c36a959/"},{"title":"[论文笔记]Tensorflow White Paper","text":"论文：TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems 抽象Computation Graph整张图如同管道结构，数据流就是其中的水流。Control Dependency 描述了管道的有向结构，而反向传播可以通过增加新的管道节点来实现。 Operation即计算操作的抽象，相当于映射、函数。 Kernel执行计算的单元，CPU或GPU SessionClient-Server结构，进行计算或者调整图结构则视为一次会话 Variables特殊的Operation，返回一个句柄，指向持久化的张量，这些张量在整张图的计算中不会被释放。 Device对Kernel的封装，包含类型属性，实行注册机制维护可供使用的Device列表。 多机实现要考虑两个问题： 计算节点在Device间的分配问题 Devices之间的通信 针对这两个问题，分别建立了两个抽象层。 计算节点分配的C/S机制client提出计算请求，master负责切割计算图为子图，分配子图到Devices。分配时，会模拟执行子图，并采取贪心的策略分配。 不同Device之间的发送和接收节点 在每个Device上建立Receive和Send节点，负责与其他Device通信。 优化数据化并行 上：单线程，同步数据并行下：多线程，异步更新 拾遗文章中很多内容并没涉及到（看不懂）。 小结TensorFlow是个庞大的计算框架，不仅仅定位于深度网络。其对计算图的抽象和数据、计算资源的分配的处理是值得关注的。","link":"/posts/75be00ae/"},{"title":"我的信息方法论：原则与实践","text":"引言很多人都谈，我们处于一个信息过载的状态，这个时代唯一稀缺的资源便是我们的注意力。作为个人而言，如何在数字时代更健壮和自信地生活？我将在这篇文章里试图梳理自己在信息的获取和处理方面的态度和思考，以原则和实践分别叙述出来。 原则模型信息+信息所依托的形式—&gt;渠道—&gt;接收者—&gt;对接收者产生影响 上面的逻辑粗线条地描绘了我所理解的信息价值Pipeline，其中有三个关键点： 信息不仅包括内容，还包括来源。就我对自己的思维方式的观察来看，我有高度依赖先验的习惯。在对一条信息的内容做出处理时，以来源为代表的辅助信息就至关重要，它们是我在对内容做出判断之前的优先处理的对象。我们对信息的要求应该是严苛的：我们远不应止于读出构成语义的部分，对这部分语义来源的考察，支撑其语义成立的其他信息等等，都是必须要认真处理的部分。举例来讲，任何一个提供下载文件的连接旁都应该附加其某种编码（如MD5)，来方便验证这一文件的来源。 所使用的工具应该辅助我选择，而不是替我选择。这里“辅助”的边界有必要作进一步的解释，一般来讲，我仅仅要求工具帮我提供筛选信息的界面，但我也对相对准确的部分个性化推荐引擎保持容忍。我抵制“热门”式的大众化推荐。从这一点上讲，我对工具提供的接口水平保持高度的敏感，我常常会注意某项工具和服务替我做出了哪些选择。 信息在被应用之后才产生价值。这里的“价值”是指针对个人的发展来讲，而非通过倒卖信息等获得的经济利益。信息通过个人的验证、处理、应用后，构成个人观念或知识体系的一部分，并在之后个人的工作、决策等活动中起到帮助作用，这是我对信息对个人产生价值的基本逻辑。在无法将信息及时应用时，让信息参与自己的思维活动如写作，是最有效的处理方式。 “包装”：筛选信息的依据包装这个词其实有些笼统。我所指是信息在被理解为实际语义前被附加的部分，也是我们的语言系统所解构的部分。更具体地，这则信息所使用的表达方式、语气情感、论证方式与逻辑链条等等。解构这些包装是我们的语言系统自动完成的，而它们对精准理解信息所表达的语义又相当重要，甚至会影响我们对实际语义的判断。远如古诗文的修辞、近如信息传递人的表情等，都在影响着我们理解信息的过程。 因而，对信息“包装”的判断是筛选信息的关键之一。就我个人而言，情绪化、修辞/修饰语滥用、判断多于论证等现象常常是我主动屏蔽很多信息及其来源的依据，而不幸的是，就我的观察，大部分信息都存在这些弊病。 媒介：信息还是体验马克卢汉有个著名的论断：媒介即信息。信息本身依托媒介存在和传播，而它本身也被媒介所塑造和筛选着。 纵观我们的文明史，语言的产生无疑是推动人类文明进入高速发展的关键事件，再至，印刷术的发明和推广，让我们的文明信息找到了DNA之外更加廉价和方便的传承方式。从进化的角度看，文字，是最古老也是我们的语言系统最先适应的媒介形式。 我曾在自己的萧爽楼博客的关于页面这样赞美文字： 文字太模糊了，不足以让你记起全部的细节，你只好亲自走回去，回到青葱的岁月，像看故事里的人物那样看看那时的自己； 文字又太准确了，这些陌生又熟悉的字眼，这些亲切又早已忘却的句子，就像当年的自己把故事亲口哼唱给你听，此时此刻，恰如彼时彼刻。 文字脆弱，却又力量无穷。 用文字表达和理解文字的过程是要求大脑的语言系统充分参与的，而这也是塑造我们自己思考方式和思维习惯的重要时刻。相比后面要谈到的媒介，文字是最“累”的，但却是最有质量的。 近代以来，多媒体技术的发展让我们有机会通过更贴近感官的方式理解和传达信息。但需要引起注意的地方是，信息的内涵被扩展了：它有时退化成了并不需要语言系统参与的纯粹的体验。 从追求特效和视觉震撼效果的好莱坞电影和短小、高重复的视频流，这些媒介在事实上剥离了信息本身，它们仅仅在传达一种可以让你轻易触达的体验。在我看来，有这些特征的媒介应当引起警惕，它们并不是在传递和记载信息，那些只是体验而已。 习惯接收和处理体验而非信息会造成懒惰，也会让我们不自觉地简化原本需要复杂表达和精确表述的情感和语义。 举例来说，我几乎不用EMOJI之外的任何表情图片，我会尽力用语言文字来进行表达。在真正要描述自己的感受时，如果第一时间想到的是熊猫人的郁闷脸，对我是莫大的悲哀。遗憾的是，这些表情正蚕食着我们的聊天甚至阅读环境，它们所传达的体验正替代着本应由语言发挥的信息表达功能。 更令人痛心的是，我们的教育系统并没有在语言的表达能力方面给予学生健康的指导，而且就今年的高考作文题目看，作文竟然被迫还要承担一部分政治教化的功能。 作为接收者的交互，渠道之角色在信息的创造者和接受者之间，信息本来是一次性的传递。周期性的发送和接受，则构成了信息分发的最原始模式：订阅。 对接受者而言，订阅是其把控的主动选择。报纸、杂志是订阅模式较早的例子，在这些媒介下，信息的创造者（报社）自己控制分发的渠道，创造者和接收者之间形成简单的二元图关系。 而当传播和接受的需求逐渐扩大时，二元图模型维持这样庞大和规模化的分发任务的弊端就显现出来。这时，渠道，作为一个独立的信息传递节点，开始在信息的产生和接收两端起到标准化和整合的作用。这一点，映射到商品市场上，就是超市的产生：顾客无需去不同品类的商店分别购买商品，而是与作为中间商的超市交互。 在互联网领域，搜索引擎逐渐代替门户网站的功能，成为互联网这一媒介所承载和传播信息的整合者，而在整合过程中加入有目的的信息——广告，就形成了搜索引擎公司的商业模型。 随着渠道作为整合者角色的加入，对信息的接收者来说，推荐成为了一种新的信息分发模式，与订阅的二元化选择相比，推荐提供了更多的灵活性，也使得交互过程能够反复进行。 然而，推荐在某种程度上是渠道的夺权：作为接收者，我们让渡了一部分自由选择的权利和机会；作为创造者，我们接受了来自渠道的筛选；对于两方来说，都会不可避免地受到渠道的挟持。 认识到这一点在信息收集渠道的选择上至关重要，我需要认清渠道代表我作出了哪些选择和判断。 我为什么选择RSS我最推崇的一项技术（更多的应该是一份协议）是RSS，全称Rich Site Summary。 RSS可以理解为信息产出者和接收者之间约定的一份公约，它是遵循原始的订阅模式：由产生者为新内容提供一份标准化的摘要，而接收者则使用通用的代理程序定期检查和抓取这份摘要。RSS以不触及信息本身的方式标准化了产生者和接收者之间的交互，并保留了各自原本的权利。 用一个不太恰当的比喻来说，大部分渠道像个市场，到处充满了叫卖的商贩，它让你体会到选择的丰富之时，精力也被眼花缭乱的广告分散，而RSS则像是一份邀请你到某个并不相识的人家中（博客）做客的信函：呦呦鹿鸣，食野之苹。我有嘉宾，鼓瑟吹笙。 也谈社交平台对我来说，社交平台并不成为信息的来源，至少我不期待它能够发挥多少作为信息来源的作用。如我在信息的包装一节中所谈，微博和微信朋友圈这种短信息流是相当差的信息组织形式，它在很多情况下不能完整地传达一个可以自证的观点或是客观描述一项事实。我从来不会把它们当作是信息的来源，它们仅可作为一项索引，向我表明某件事情可能值得关注。 在这一过程中，好友也作为信息的筛选着和分发者，他们所提供的意见则可在相当程度上为信息提供是否值得进一步审阅的根据。大部分情况下，社交平台只会发挥其沟通和通讯的功能，我不会在上面花费更多时间。 实践我所理解的信息处理实践的框架，有三个关键的维度：信息类型、时间质量和处理状态。于是，信息处理的问题可以表述为：如何以合理的时间和精力投入，使不同类型的信息达到适合的处理状态？ 信息类型：质量有几何？按照信息密度和处理难度等，我将信息分为学习材料、观点评论、科普知识、资讯和噪音。这些类型间的边界，各人自有各自的尺度和偏好，重要的是给信息分类的意识：并不是所有的信息，都值得你的等价关注。 学习材料对学生而言，学习材料的一个明显例子就是教科书。更为深入一点，定义学习材料的应是其代表的权威性和复杂性。权威性意指其可靠程度，科学理论、实验事实等均在此列，也可延伸至领域经典的论文、专著、报告等。而从复杂性来讲，则是我们判定这一材料的价值和内化这一材料所含信息所需要付出的精力多少，如某一前沿的科研工作、某一门语言、某一个程序库、MOOCs等。 对学习材料的处理还应包括其收集过程，我们常需要针对某一主题建立材料库，这一过程也需要相当的判断力和精力投入。 观点评论这一类型可被认为是“二次知识“（乃至N次，又或许一次知识并不存在），通常是某人对某一事物的认识和观点，逻辑性和事实性兼具。对这类信息，比较重要的是判断其能否”自圆其说“。即论证的方式是否合乎逻辑。比较容易陷入的陷阱是从事实和结论出发去判断信息（即以自己预定的态度和判断来评定文章质量）。 科普知识科普知识是学习材料的易理解版本，可供快速、浅层地了解某一较为专业的概念和事物。 资讯和噪音这一类型信息应当说占据了我们平常所接收信息的绝大多数。它们常常比较碎片，可讨论和挖掘的空间很小或是价值不大，甚至跟自己毫不相关。 时间质量：精力有多少？作为信息处理的主体，自己的精神状态和可支配时间必定是一个关键的因素。有了对信息分类的意识后，时间和精力的安排也就不言自明：用精力充沛、较长的时间段去处理高质量的信息，如学习材料和观点评论等；而碎片化的时间用于浏览科普知识和过滤资讯。 再深入地，对自己的时间和精力管理要有节奏感，即也有分类意识：并不是每一分钟都有同样的质量。 处理状态：内化为自己的一部分如我在原则篇所述，信息处理的目的是内化为自己的知识、观点、技能等，以便在日后的决策中提供帮助。信息被内化才产生价值。 那么，如何内化信息？我认为最有效的方式是表达。 表达可以是某一主题的文献综述、总结报告，也可以是对某一观点的总结式评论或反驳，还可以是不经意的一次自言自语。 表达的实质是，用自己的话讲出来。 更精细一点，对于学习材料，我们可以通过练习性的实践来应用知识；对观点评论，应总结其逻辑、指出薄弱处；对科普知识、资讯和噪音等，概括、转述等都是一种表达。 表达的关键是完成从接收者到传播者的角色转换：写作、跟朋友交流都是很好的方式。另一个可操作的举动是：放下手头的文章，目光投向别处，回想和梳理文章的逻辑和要点，并默念出来。总之，不要让自己总是保持在信息的终点，努力成为一个起点。 内化为自己的东西是信息处理的最终状态，但也可有中间形态作为中转： 稍后再读：等待高质量的时间集中处理 收藏：收集相关的材料进行交叉阅读，或是等待查阅 总结信息，俨然已经成为当代社会的一个基本要素，跟它相处、使用它、内化它、创造它，是我们作为数字时代移民的终生话题。 最后，我在推荐页面提供了我所使用的工具和信息来源，供参考。","link":"/posts/3a6233e2/"},{"title":"个性化你的Ubuntu-1：GNOME桌面环境","text":"我与Ubuntu我最初是Windows98用户，再到Windows2003,Windows XP,Windows 7,上了大学后用Windows 8.1,Windows 10（想不到竟然能列这么长；我从没用过Windows Vista,不知道那是什么东西），我很喜欢8.1和10的开始屏幕和动态磁贴。非常偶然的机会，我在CS50的课程中接触了GNU/Linux，才知道，原来在MS　Windows和Mac OSＸ之外，还有一个GNU/Linux。换完SSD，学会了装操作系统，我便踏上了折腾GNU/Linux的不归路。 曾经被一个软院的同学安利Red Hat系的Fedora（尽管他现在已经投入了MacBook的怀抱）,普及各种内核之类的知识。然而，我只想安静的用它上上网，进行科学计算，并没有深入到考虑系统底层的需求层次。我还是安心地用Ubuntu吧。我也推荐第一次尝试GNU/Linux系统的小白从Ubuntu开始，相信我,askubuntu.com和stackoverflow.com会解决你的大部分问题的。 个性化你的Ubuntu（一）：GNOME桌面环境相信不少读者都是从Microsoft Windows转到GNU/Linux阵营的,早就习惯了用户图形界面。但是，配合桌面环境、主题和一些插件和软件，Ubuntu照样可以很酷炫。 什么是GNOME（大脚丫为什么这么大。。。） GNOME(pronounced /ɡˈnoʊm/ or /ˈnoʊm/) 最初是GNU Network Object Model Environment的缩写，但这一缩写已不再沿用（更多历史情况请参见这里）。 我们所说的GNOME，通常指的是由The GNOME Project开发的运行于Linux之上的桌面环境。 我们每天面对的，并不是全部的Microft Windows/OS X/Linux系统，而是系统提供给我们的人机接口，而桌面环境，则是统一在同一图形用户接口（GUI）之下的一揽子软件（X Window Manager, File manager, Terminal emulator, Text editor, Image viewer, E-mail client等）。 来源 Ubuntu自带的桌面环境是Unity（图形外壳）,其他流行的桌面环境还有KDE,Xfce。但我们要谈的是GNOME。 什么是X window system要谈Unix-like系统上的图形界面，就不得不提X Window System。那么，什么是X? The X Window System, commonly referred to merely as X, is a highly configurable, cross-platform, complete and free client-server system for managing graphical user interfaces (GUIs) on single computers and on networks of computers. (X窗口系统，通常简称为X，是用于管理在单个计算机和计算机网络上运行的图形用户界面（GUI）一个高度可配置的，跨平台，完整的，自由的客户端-服务器系统。） 来源：LINFO 我们试着通过X能够干什么来理解一下这句话。 X是一组规则、一套方法。它提供了从硬件（键鼠）接受用户输入、创建图形窗口、画出直线、位图等基本的图形功能（图形引擎）。 X实现了客户端-服务器的机制。通过划分Server和Client，X既能在本地计算机上运行，也能在计算计算机网络中运行。 X与操作系统独立。X可以理解为运行在操作系统之上的一套软件。如果不需要GUI，完全可以不用安装X。而在Microsoft Windows和OS X中，图形引擎是操作系统的一部分。 X Window System的结构如图。 GNOME &amp; XGNOME和X Window System是什么关系？桌面环境可以理解为一系列X client的集合，其中最重要的组件是X Window Manager。由于X Window System的client-server机制，各client之间是相对独立的，这时，需要一个特殊的client管理其他client，将他们统一在一个框架之下，这就是X Window Manager。来源 而GNOME另一个重要的组成部分是GNOME shell，它是一个图形外壳程序，也就是我们要面对的接口。 跟GNOME相关的其他组件、库、概念 GTK+：GIMP Widget toolkits，GNOME基于的GUI工具箱。KDE则基于Qt。 Display Manager:图形用户登陆管理器，为用户提供登陆界面，与session manager通信，开启新的session。GNOME使用的是GDM。 Metacity：GNOME 2使用的window manager，GNOME 3使用的是Mutter。KDE使用的是KWin。 Wayland:与X Window System对应，也是一种窗口系统 我现在的桌面 我不喜欢双击桌面图标来启动程序，更多用的是Dock和全局搜索，所以，桌面上“什么都没有”。 桌面的壁纸是电影 飞屋环游记 的海报，使用了Numix系列的主题和图标。 下方Dock使用的程序是Cairo-Dock，桌面右方运行的程序是Conky，用来监测系统运行情况和提供天气信息，上方的Topbar里添加了许多GNOME的扩展应用。 接下来的两篇文章将介绍Gnome的安装与扩展推荐，欢迎继续阅读，撒花。 @ddlee","link":"/posts/c0bafe01/"},{"title":"我的数字内容管理实践","text":"缘起我在考虑为自己的MacBook选择笔记类和创作类应用时，曾对这两种活动作出区分，认为前者需要跟原文进行较多交互，更适合用富文本应用，后者中文学性创作则不需要太多对材料的整理，更适合纯文本应用。这样的区分有一定意义，但不够深刻。更重要的是从信息流入和流出的角度来区分：笔记是一项整理活动，信息是流入方向，自然需要富文本的支持来应对广泛的信息来源；创作是一项产出活动，信息是流出方向，更需要不被打扰的环境，自然纯文本的方式更利于集中注意力。从这一个角度上，我便理解了为什么Evernote在客户端编辑器如此不友好的情况下仍能如此受欢迎：Evernote不是一项应用，而是一项服务。这项服务更有竞争力的部分是它对其他来源信息的收纳和整合以及接口上的广泛性。它的客户端从设计上并非从创作出发的，而是定位于一个多种信息来源的入口（手写、语音、扫描、网页剪贴等）。因而，这也是它相对其他笔记类应用的护城河：你可以从不少文档标注、写作应用中找到“导出到Evernote”的出口，但其他笔记类应用很少能做到这一点。下面，我对自己在文本信息整理和输出与文件存储同步方面的实践做一个整理，可以看作是信息方法论系列的续篇。 文本信息正如我在“缘起”一节中讨论的，我的信息处理活动可按照信息流向来区分：收集、整理和归档等需要“富文本+”处理工具，而创作需要“纯文本+”工具。作为信息流入方，信息本身是带有各种格式的，而作为信息产出方，信息脱胎于键盘上敲出的每一个字符。 富文本+包括：各种格式的文本（通常来自网络）、代码块（非项目源码）、文档文件（PDF等）、手写笔记及扫描件、部分图片（如截图）、录音和少量视频，对这些媒介间需要超出单纯文件夹管理的整理过程 推荐服务：OneNote、Evernote等 存储方式：整合多种格式文件和文字的“超文本”（通常为服务商定义） 纯文本+包括：少量格式的文本（Markdown），项目代码等，仅通过文件夹就能在逻辑上进行整理分类 推荐应用：Ulysses、Typora等写作类应用（带有文件管理功能）配合DropBox等同步服务，VS Code等文本编辑器配合Git等版本控制工具 存储方式：文件夹整理下的纯文本文件（及少量静态文件） 文件存储与同步原则（分先后） 非本地：原文件一定要在云端有备份，而非仅存在于设备中 跨平台：多终端访问、跟其他服务接口充分 集中性：某一类型的信息（如图片）尽量使用同一服务 就地性：优先考虑跟设备深度集成的服务 “热”数据和“冷”数据“热”与“冷”本是数据中心对用户数据的区分，自身的文件管理中不妨也引入这一区分：使用中(Working)和已归档(Archived)。使用中则使用同步优先的服务，已归档则考虑存储。举例来说，常用设备上的应用软件数据显然属于“热”数据，而某次互动/任务产生的项目文件等则可以整理后归档，成为“冷”数据。对于“热”数据，易获取和定期备份是首要需求，因此要求多平台的同步服务。而对于“冷”数据，长期可靠存储则可优先考虑，但对特殊的信息类型，我们还需要智能化的整理和索引，如Google Photos对照片的整理、Evernote和OneNote对文本文档的OCR索引等。 云同步与存储偏向存储： Box(10G): 归档的文档文件（课件、电子书等） Google Drive(15G): Android系统配置的备份、Gmail附件等 Mega(50G): 大型备份（私人文件备份、安装包等） Google Photos(unlimited): 照片、录像、保存的图片偏向同步： DropBox(3G): 常用的文档文件跨平台同步 iCloud(5G): macOS和iOS生态中应用文件同步（如MarginNote, Ulysses） Evernote(unlimited): 归档且有检索需求的文档文件、私人文件等 GitHub/BitBucket(unlimited): 项目代码 自建NAS: 仅用于局域网跨平台同步 硬件存储 设备存储：Android, Linux, Windows尽量不作为唯一存储位置（常更新），Mac上可存储部分媒体文件和备份 移动硬盘：收藏的多媒体、照片录像等的源文件、系统备份、安装包备份等 总结个人数字内容的管理对于我来讲是个不小的挑战，如何在数字时代更好的处理信息并为我所用，是我要持续思考的课题。","link":"/posts/5076f62f/"},{"title":"我（曾经）的付费数字内容","text":"近几年陆续地弃用和启用了一些付费订阅和购买了一些付费数字产品，借此机会整理一下。 订阅内容当前订阅 Wall Stree Journal：相对客观的新闻获取来源 The Wired：技术类新闻及评论，可以浏览网站内容并每月会有一本杂志 哈佛商业评论中文版：财经、管理类文章，拓展视野和思路所用，尝试以一个经营者的思维运营自己本身 Apple Music：曲库较为丰富，对学生价格优惠 网易云音乐豪华会员：离线许多红心歌曲所用，但曲库确实做得不好 腾讯视频会员：美剧和电影资源相对丰富，看了一些自己感兴趣的剧，但总会有不全的时候，各家服务的差别也主要是在内容方面 服务器及域名：用于伺服网站 弃用订阅 Stratechery：独立分析师Ben Thompson的个人博客，观点独立且有自己的一套认识和分析框架，由于价格较高且个人处理英文信息的效率并不高取消订阅 迅雷会员：几年前下载视频教程的时候订阅过 百度网盘超级会员：因为限速问题不得不订阅过一次，目前对其态度是作为资源站，不会将个人资料进行存储 数字产品Google Play应用 Sleep as Android, 配合Android手表进行睡眠监测用的，但目前并不在意也不方便，已弃用 Tasker, 自动化工具，自我感觉并没充分发挥它的功能 My Android Tools, 非常强大的禁用工具，目前（2018.09）被Play Store下架 Solid Exmplorer, Material Design风格的文件管理器，同步服务接口丰富，用于跟其他平台传输文件 Weather Timeline, 设计感很好的天气应用 SD Maid Pro, Android清理工具，Pro版本可以定期清理 Ice Box Pro, 应用冻结工具，目前已被我用Island替代 Greenify Donate, 应用进程管理工具 Nova Launcher Prime, 桌面启动器，Prime版本自定义程度更高 RETRORIKA Icon Pack, 非常喜欢的一款图标包 Amplify Donate, Xposed框架下的电源管理工具 Pockect Casts, Podcast订阅 Andromeda, Android O上的Substratum启用 Flux(Substratum Theme), 目前在使用的Substratum主题 App Store应用 MarginNote, PDF批注，知识整理 PDF Expert, PDF编辑和批注 Reeder 3, RSS订阅客户端 AVPlayer, 多种格式的视频播放器 Notability, 配合触控笔的笔记应用，并不清楚配合Apple Pencil效果如何 Notes Plus, 同上 Steam游戏主要是夏促和圣诞时买入bundle，主要玩独立的解谜游戏，但我晕某些游戏的3D。下面推荐几款吧： Machinarium INSIDE The Bridge Braid Undertale Samorost The Stanley Parable 其他 Internet Download Manager(Windows)：多线程下载工具，速度稳定，非常好用 Adobe Acrobat(Windows)：官方PDF编辑工具，现已基本不用。有很多在线工具，可以满足简单操作。目前对我而言，PDF文件主要是用于批注。 网易云音乐的读书电台：某段时间通勤时间长，通勤路上所用 知乎Live：质量参差不齐。需要仔细考虑相关话题是否适合讲述，并比其他方式更高效，或者是live作者提供的内容有其内在的不可替代性 Kindle、多看等平台的电子书 心愿单（技术宅的种草）其实相当大一顾虑是价格问题。 Medium Member: Medium文章质量很高，目前逐步培养自己的英语阅读能力 Setapp: Mac应用集合订阅，但目前并不确定其中应用是否刚需 Alfred Powerpack: Mac效率应用Alfred的workflow功能 Evernote Premium: 我使用的国际区账号，目前两台设备同步勉强可以，高级版可以作为私人内容的网盘来用，还是蛮有吸引力的","link":"/posts/cb148915/"},{"title":"在线文字创作不完全指南","text":"本文力图为有在线表达意愿的读者提供一份思考和行动指南，更期望能够引起对“网络空间中的表达”这一主题的讨论和交流。 我所指的表达和创作在本文中，表达和创作是相当狭义的。我所指的一个核心部分大概可以表述为“完整地叙述自己的观点并说明理由”，从这个核心出发，可以较为充分地表达自己所感所想的以文字为主要媒介的体裁都可以容纳进来，比如游记、小说、影评等等。我在这样的定义里，强调的部分在于观点的完整性和自主性，期望文章能够有比较严谨而有讨论空间的论点、自主且合逻辑的理由等，通常，这样的文章不仅是一个表达窗口，而且是思考与整理的过程，需要投入相当的精力。 为什么要使用文字进行表达和创作“要表达和创作”我们每个人都很精彩，都有自己的判断力，有自己的思路。表达和创作一方面方便他人更深刻地了解自己，另一方面也能作为交换认识到他人的想法和思路，如果能够碰撞成火花，那真是一件再幸运不过的事情了。对自己而言，表达和创作实际上是内化自己接收到信息的过程，而且这种内化远比记忆等要深刻和持久。如果再现实一点，表达是输出影响力的第一步，而影响力，则是一项资源。 “使用文字”如果有能力，音乐、绘画、剪辑等也是非常棒的表达和创作方式，但这些往往需要相当的知识和能力基础，对于大部分人而言，使用文字是最容易的方式。毕竟，我们都接受过基本的鉴赏和写作锻炼，尽管这些锻炼的结果是让很多人丧失鉴赏和写作的能力。更进一步的理由是，使用文字表达可选用的工具和平台非常多（相比其他方式），我在下面的“工具与行动篇”会提供一个横向的比较。 以及一些担忧依据我的观察，除了日常工作和学习生活外，大部分人的表达渠道相当单一和局限，并且跟我所指的表达相去甚远。微信群聊天、朋友圈转发/评论、微博发言/评论等，已经占据了我们相当大的表达精力和空间，而这些渠道中的信息形式常常不能满足完整性和自主性：篇幅太短且实时性要求高，往往情绪化和未经严肃审慎的思考。而且，表情的泛滥也在一点一点侵蚀文字的表达功能。“捂脸哭”、“笑哭”等Emoji被严重地滥用，以致达到了“含义过载”的程度，早已丧失其原本的表情传达意义。以“熊猫人”、“蘑菇头”为代表的图片表情甚至超出聊天环境，出现在很多科普、观点类的网络文章中，比如“我当时的心情是这样的：【表情】”这种表达，常使我感到悲哀。表情却有其形象化的优势，但滥用实不可取。过分地接受和使用这些表情实际上是体验传达代替了语言表达，弱化了我们的思考过程。这些担忧可以部分解释我自己从不使用微博、也很少使用微信朋友圈。 思考与规划篇内容内容方面各有各的选择，我的期待是至少自主，即有自己的思考过程。对某一事件的评论、对某一文章观点的反驳、怀念某段感情的小说、记录某次旅行的游记、进行某次购物决策时的思考、学习某项技术时的笔记、影评书评等等，都可以成为创作的内容。千万不要担心无事可写无话可说，只要有生活，就有内容。 定位定位方面可以就自己的目的而定。若是仅作自我纪录，则无所谓定位。而若期待将自己作为一个IP来运营，则可在定位的人群方面仔细谋划一番，提供哪些被需要的内容、如何说服、选择哪些平台来宣传推广等，都是值得规划的问题。这些方面，大都可以在有更现实需求的领域如公众号运营找到借鉴。 精力自己能在表达和创作方面投入多少精力，也是值得认真考虑的。在初期投入太多往往会难以坚持，这项事情不应被期待会有像其他投入那样有现实的反馈和回报，而我们常常诸事缠身，放弃是一个再容易不过的选项。在下定决心做出行动前，最好对自己的精力分配有一个真实的估计和预算上的规划，如每星期能够拿出几个小时、能够支撑起的更新频次等。 工具与行动篇人机协作的维度这里“机”的含义是广义的，泛指我们所借用的外部工具。如本文题目所示，我们要讨论的是在线的创作，选择合适的工具和平台是必要的，我将列举出我所观察到的协作的维度，以提供指导性的思考坐标。 编辑接口编辑接口是指我们编辑文字时面对的接口，这一接口并不固定，因为对于发布来说，你只需要传递文字和图片即可，我们完全有充分的空间脱离所用发布渠道提供的编辑器，而选用专业的写作工具、文本编辑器等。但是，对于定制性较差的渠道，使用其提供的编辑器却是最方便的，不必担心格式等问题。比如，QQ空间编辑器、论坛的发帖编辑器等等。随着所用渠道的定制性提高，我们可以在创作和发布间添加一层作品状态的抽象，此时，Markdown便是一个不错的选择：它允许以轻量的方式标记文字格式，并被大部分写作工具和发布渠道很容易地支持，且在创作方面相对纯粹。 定制性定制性可以理解为我们对自己作品的控制权。创作之时，我们对内容是有完全的掌控的，但发布之时，内容的格式、分发的渠道等，却受到所用平台的限制。本文所指的“在线创作”通常是以网页的形式发布的，对比来看，QQ空间仅提供有限的富文本形式、受控的媒体来源和封闭的传播范围（无法被搜索引擎检索），而自建网站则可以有个性化的域名和logo，可以定制页面的风格，可以通过其他手段最大化传播范围等等。 分发渠道分发渠道是指我们的作品传播的途径和所能传播的范围，可以认为是定制性的一个方面。少数平台的内容是不可以被检索到的，如QQ空间，而大部分网页是可以被自由访问和链接的。使用平台的好处是可以通过平台自动带来流量，选择自建网站则可能相对依赖搜索引擎或是自己在社区等的宣传。 推荐与比较本文题目中的“不完全”指这一部分。对于工具和平台，我也只是尝试了很小的一部分，下面仅仅列举出一些例子并按上面的维度进行评述，供读者选择，排序基本按照定制性（作者控制权）依次提升。 社交网络 Social Network: QQ空间/微信公众号 编辑接口：专用编辑器 定制性：少量格式文本，有限的信纸模版 分发渠道：受限，但会得到稳定的推送 这种形态定制性最差，却不妨作为表达和创作的起点（QQ空间应该在事实上是不少90后的表达起点）。据我了解，微信公众号的文章仅能通过搜狗检索得到，且所有外链只能通过“阅读原文”实现，这是令我非常厌恶的地方。要知道，超链接是WWW建立的一个核心，即网页是可以通过链接自由跳转的。 论坛 Forum: 百度贴吧/威锋论坛/人大经济论坛 编辑接口：专用编辑器 定制性：少量格式文本，统一页面风格 分发渠道：受限，但自带论坛流量 论坛的读者常常有共同感兴趣的话题，在这些场合表达观点常常会被容易理解，但由于不同的论坛机制和论坛读者，是否适合严肃创作还是要单独讨论的。据我的观察，跟帖方常常不会完整自主地表达观点，难以形成有效的讨论（因话题而异，若专业性非常强，还是相当值得考虑的）。 社区网站 Community: 知乎/豆瓣/Linkedin/Quora/少数派/掘金 编辑接口：专用编辑或导入文件 定制性：富文本，统一页面风格 分发渠道：半开放，自带话题流量和推荐，部分可以得到稳定推送 知乎/Quora这样的问答平台通常有话题机制，容易将自己的作品投放和获得反馈，且能被检索，传播范围相对广，通过关注机制还可以获得相对稳定的流量。少数派等作为媒体，也接受相关投稿，可以透过其影响力为自己的作品带来流量。这一类型是我比较推荐可供非技术背景的写作者选择的平台。 创作平台 Publishing Platform: 简书/Lofter/新浪博客/博客园/CSDN/Medium/GitBook/LeanPub 编辑接口：专用编辑器或导入文件 定制性：富文本，有限的主题风格 分发渠道：容易被搜索引擎索引到，自带网站流量和推荐，部分可以得到稳定推送 这类平台提供较统一的页面风格和内容管理发布功能，部分也有关注机制可带来稳定流量，是我最推荐的非技术背景（或懒于折腾）写作者的创作平台。后两者GitBook和LeanPub则是开源的图书在线出版服务。 博客平台 Blogging Platform: WordPress/Ghost/Blogger 编辑接口：专用编辑器和写作工具支持 定制性：富文本（+网页格式），丰富的主题选择，自定义风格定制，甚至支持自编程序，部分也支持个性化域名 分发渠道：搜索引擎和部分平台流量 此类平台通常以博客程序为核心，提供编辑、发布和托管的一站式服务。提供的风格选择也较为多样，且有较为丰富的插件扩展，可供进阶写作者选择，也适用于有较高定制需求的写作者（比如建立个人主页）。不过不少类似服务（或其高阶功能）是付费使用的。 自建博客程序+托管服务 Self-Hosted Blog Software + Hosting: WordPress/Joomla!/Drupal 编辑接口：专用编辑器和写作工具支持 定制性：富文本（+网页格式），丰富的主题选择（支持二次开发和修改），自定义风格定制，个性化域名和托管控制 分发渠道：搜索引擎、自我推广 这种选择通常需要一定的技术学习负担，需要简要了解网站伺服、博客程序运行的过程等知识。以最广泛使用的WordPress为例，需要自己配置后端数据库，并学会使用控制面板来搭建博客程序所需的运行环境（如LAMP）。如果要使用个性域名，则还要配置解析等；如果托管服务在国内或是域名为.cn等后缀，则还会被要求备案。当然定制性也会更高，除博客平台所提供的功能外，甚至可以在开源博客程序基础上自己添加功能。这种选择可以成为有折腾精神或是未来会从事前端开发的写作者的起点。 静态网页生成器+托管服务 Static Page Generators + Hosting: Jekyll/Hexo 编辑接口：文本编辑器及自由选择写作工具，建立作品层抽象 定制性：几乎完全的网页控制，可充分定制的主题及页面风格，个性域名和托管控制 分发渠道：搜索引擎、自我推广 这类选择跟上一组合类似，只是所提供的页面并非由博客程序生成，而由本地程序生成后上传至托管服务。同样也需要部分技术学习负担，但对网页几乎有全部的控制（你可以单独用HTML做一个个人网页）。Jekyll和Hexo都是这样的生成引擎，它们将我们创作的Markdown格式文档处理为HTML网页，并通过插件或其他方式上传至托管服务，用户直接访问网页，也较博客程序对伺服服务器的要求更低一点。同样地，我们也可以对主题或插件进行二次开发，以满足自己的需要。这一选择同样推荐给有折腾精神或是未来会从事前端开发的写作者。包括此项和上一项已可以认为是具有足够灵活性的创作方式 ，也是网络上教程资源非常丰富的两选项，更进一步的网站开发等将超出本文的范畴（而且我也并不熟悉）。 管理型托管服务和渲染引擎 Managed Hosting and Rendering Service: GoDaddy/七牛CDN/GitHub Pages/Netlify这里单独谈一下托管服务，适用于上面提到的后两种选择。我们的网页需要托管到服务器上，但根据需要可以有不同的使用层级。管理型托管服务或称“共享主机”是提供商建立了一层管理抽象后提供给用户的，用户面对的接口为主机面板，通过此面板可以实现建立网站、安装博客程序等功能，背后的硬件资源则是共享的，如GoDaddy。七牛云CDN和其他云服务商提供的对象存储功能，则是提供了一部分在线的存储空间，可以用来存放静态网页（不支持博客程序）。而GitHub Pages和Netlify等则提供了对于某类模版引擎（即生成器，如Jekyll）的渲染功能，用户可以直接将编辑的Markdown文件上传，由服务提供商来渲染为实际看到的网页（当然此时定制性便有所收缩）。托管服务中自由性最高的是下面的自管理托管服务（或称VPS，虚拟私人主机）。 自管理托管服务 Unmanaged Hosting(VPS): AWS EC2/AliYun这类服务直接提供给用户可供远程登录的虚拟主机（物理主机上一层抽象，可理解为系统内存和RAM的关系），具有远不止网页伺服的操作空间。我们可以在其上自行搭建伺服环境和博客程序（或上传静态网页），并对整个过程有相当充分的控制权。使用国内云服务商提供的主机时，需要考虑备案。 拾遗我上面列举的是很小一部分，还有很多我未曾试用的服务，如头条号、豆瓣阅读等写作计划、SquareSpace等网站搭建平台等，都有各自的人机协作维度上的权衡和选择，希望读者能够明确自己的需求和所能付出的精力，审慎选择，也希望其他平台的创作者在评论中补充本文未及的渠道工具等。 结语在我看来，表达和创作是自我能量释放的一个窗口。没有一个人是贫乏的，也没有一个人注定沉默。希望本文给读者提供规划上和行动上的参考，欢迎大家评论交流。","link":"/posts/599cb823/"},{"title":"机器学习工作习惯侧记","text":"本文记录我从事机器视觉工作积累下来的一点习惯和经验。 文件夹管理在服务器的数据盘建立model, data, output三个文件夹，model用于存放预训练模型和Deployment-Ready的模型，data用于存放训练和测试所用数据，output用于存放训练时产生的checkpoints和log。 新建项目时，将这三个文件夹通过symlink链接到项目的根目录下。 依赖管理依赖管理主要依靠Python库Pipenv。它结合了Pypi包管理和VirtualEnvs的环境管理，为每个项目单独建立Python环境，并通过PipFile和PipFile.lock实现更新和迁移。具体的workflow为： 建立项目文件夹，并使用pipenv install命令初始化其独立的Python环境 按需要通过pipenv install package-name来安装需要的依赖 使用pipenv run或激活pipenv shell运行、Debug相应的项目程序 需要迁移环境时，将PipFile.lock拷贝至新的目录下，通过pipenv install来还原Python的运行环境；通过Git等版本控制工具来还原代码。 更多有关环境搭建和管理的内容，参见博文PyCharm+PipEnv本地Python开发环境配置。 项目组织对于某一项目，我的习惯是将其分为三个不同的子项目：训练、部署、评测/结果分析。 训练过程单独保存一份代码，这份代码会经常更新，并做好配置文件的管理，一般一次训练即对应一个配置文件和一份log，记录这次训练所使用的所有超参数（参见我对深度学习模型中数据的分类）。 部署所用代码也会制定一份配置文件格式，跟训练代码保持同步（尤其是网络结构），主要区别是网络中loss层等的去除，生成的结果是所用框架支持的实例化格式（如deploy.prototxt文件）。 评测部分单独使用一份代码，输入测试数据和部署代码得到的实例化模型，执行推断并得到结果，根据结果文件再以数据ground truth作评测。也可以包括对测试结果的分析脚本（如bad case，画PR曲线等）。 这样的设计，关键之处有两点，一是配置文件保证训练和部署模型的一致性，二是实例化模型和保存测试结果让三个子项目之间的交互仅以文件形式传递，再配合最早文件夹管理和依赖管理的内容，三个子项目完全可以在不同的机器和环境下同步操作。 数据管理对于数据，我有如下划分： 原始图片数据和标注，通常只读，按照标注规范，跟标注组进行交互 训练/评测集列表，这一部分单独保存，并保持灵活性，以随着新数据的加入和糟糕数据的清理等不断更新 框架所用二进制格式，如caffe的lmdb等，可以由训练项目直接使用，常由原始图片数据和列表文件生成 评测数据及结果，评测数据可由原始数据和评测集列表制作，用于评测项目，结果文件也以约定格式保存 框架维护自己维护两套所用框架的源码，一份用于稳定版本编译，另一份用于新特性的开发。新特性测试通过后，拷贝至稳定版本重新编译。对于新特性版本，可单独建立一个前端环境（Python环境），用动态链接的方式快速调用和测试。 实用工具推荐tmuxtmux的引入有两个重要作用： 窗口划分，可以在一个终端窗口里同时进行多个任务 session管理，不同session执行不同的项目，且在SSH退出登陆后，session内任务依然进行 我通常会将终端分为4个Panel，左上用于执行训练程序和打印log，右上用于监测GPU运行情况，左下用于执行文件操作和少量代码编辑，右下用于监测CPU运行情况。 gpustat/nvidia-smi/htop配合watch命令，实时检测测GPU和CPU的运行情况 sshfs挂载文件夹，有两个用途： 原始数据挂载到工作服务器上 服务器上代码挂载到本地，利用本地的文本编辑器更新 此外，也可以建立FTP，用FileZilla将本地和服务器代码进行同步。（某些IDE实际上继承了这一功能，参见博文PyCharm+PipEnv本地Python开发环境配置） GitKrakenGit的可视化客户端，相比命令行工具更为直观，用于管理代码 meld文件比较工具，可以直观方便地比较代码间的改动和变化，某些文本编辑器和IDE集成了这一功能，但不够强大 Netron/Netscope/TensorBoard网络结构可视化工具 vim/emacs/nano命令行文本编辑工具，我自己不够熟练，仅用来做少量的代码修改 Evernote/Git用于记录工作日志、数据存放、训练模型、代码修改等等备忘 Spotify/Pithos用于放松和保持专注，后者是Pandora的Linux第三方客户端","link":"/posts/f7ead50b/"},{"title":"深度学习中的权重衰减","text":"权重衰减（weight dacay），即L^2范数惩罚，是最常见的正则化技术之一。本文将介绍它是如何起作用的。主要材料来自The Deep Learning Book。 为什么要引入权重衰减机器学习的逻辑与我们最初解决问题的思维方式恰恰相反：要解决问题，一种经典的思路是把它拆成小问题，考虑之间的依赖，然后分而治之。而机器学习的哲学是“trail-error-correct”：先假设一堆可能的方案，根据结果去选择/调整这些方案，直到满意。换句话说，机器学习在假设空间中搜索最符合数据的模型：以果推因，即为最大似然的想法。随着数据量的增大，我们越来越需要表达能力更强的模型，而深度学习的优势正符合这一需要：通过分布式表示带来的指数增益，深度学习模型的扩展能力几乎是无限的（详见深度学习和分布式表示）。 有了模型（备选模型集），有了数据，就不得不面对机器学习领域的核心问题：如何保证模型能够描述数据（拟合）和生成数据（泛化）。 粗略来看，有以下三种情况： 我们假定的模型族不包含真实数据的生成过程：欠拟合/高偏差 匹配真实的数据生成过程 除了包含真实的生成过程，还包含了其他信息：过拟合/高方差 高偏差意味着我们的模型不够准确（模型族不足以描述数据），高方差意味着我们建模了不必要的信息（训练数据的随机性带来的）。前者通过提高模型的表述能力来解决（更深的网络），后者则需要合理的正则化技术来控制。这即是著名的trade-off。 深度学习模型的参数对数据建模，其实是从数据中提取我们能够理解的信息。建立的模型，是从数据分布的空间到目标变量所在空间的映射。从这个角度看，我们通过模型带来的变换获得了数据的一种表示，我们认为能够理解和操作的表示。 为了表述这一变换，深度模型的套路是线性层施加变换，非线性层固定信息（不能平移），然后将这样的结构堆叠起来，分层提取数据特征。 这让我想起实变中证明定理的套路：先证明简单函数的情形，再推广到连续函数，再到勒贝格可积的函数。 常规的套路（MLP）在拟合普通的函数任务上能够胜任，但面对更复杂的图像等数据，就需要更灵活的网络结构。 非常出色的CNN, LSTM, Inception块, ResNet, DenseNet等结构，就是加入了人类的先验知识，使之更有效的提取图像/音频数据分布空间的特征。（所以Manning有次在课堂上说，机器学习事实上还是人类在学习：机器只是在求导数、做乘法，最好的模型都是人们学习出来的。） 人们确实设计了很多巧妙的结构来解决不同的问题，但落实到网络的层和单元上，仍是最基本的矩阵乘法、加法运算。决定模型表述能力的，也正是这些普通的乘法运算中涉及的矩阵和向量了。 权重衰减如何起作用下面我们通过观察加入权重衰减后目标函数的梯度变化来讨论权重衰减是如何起作用的。可以跳过公式部分直接看最后一段。 ————————————推导部分————————— 简单起见，令偏置为0，模型的目标函数： $$J_{1}(w; X,y)=\\frac{\\alpha}{2} w^T w+J(w; X,y)$$ 对应的梯度为： $${\\nabla}{w} J{1}(w; X,y) = \\alpha w + {\\nabla}_{w} J(w; X,y)$$ 进行梯度下降，参数的更新规则为： $$w = w - \\epsilon (\\alpha w + {\\nabla}_{w} J(w; X,y)) $$ 也就是： $$w = (1 - \\epsilon \\alpha )w - \\epsilon {\\nabla}_{w} J(w; X,y)$$ 从上式可以发现，加入权重衰减后，先对参数进行伸缩，再沿梯度下降。下面令 $x^{(1)}$ 为使目标函数达到最优的参数值，在其附近考虑目标函数的二次近似： $$J(w) \\approx J(w^{(1)}) + \\frac{1}{2} (w - w^{(1)})^T H (w - w^{(1)})$$ 其中 $H$ 为近似目标函数在的Hessian矩阵。当近似目标函数最小时，其梯度为 $0$ ，即： $${\\nabla}_{w} J(w) \\approx H(w - w^{(1)})$$ 该式也向我们说明了基于梯度的优化算法主要的信息来自Hessian矩阵。添加入权重衰减项之后，上式变为（记此时的最优点为 $w^{(2)}$ ）： $${\\nabla}{w} J{1}(w) \\approx \\alpha w^{(2)} + H(w^{(2)} - w^{(1)}) = 0$$ 所以 $$w^{(2)} = (H + \\alpha I)^{-1} H w^{(1)} $$ 该式表明了了加入正则化对参数最优质点的影响，由Hessian矩阵和正则化系数 $\\alpha$ 共同决定。 进一步将Hessian矩阵分解，可以得到： $$w^{(2)} = Q(\\Lambda + \\alpha I)^{-1} \\Lambda Q^T w^{(1)}$$ 其中， $Q$ 为正交矩阵，$\\Lambda$ 为对角矩阵。这样可以看到，权重衰减的效果是沿着由 $H$ 的特征向量所定义的轴缩放 $w$， 具体的伸缩因子为 ${\\frac{ {\\lambda}_{i} }{ {\\lambda}i + \\alpha }}$ ，其中 ${\\lambda}{i}$ 表示第 $i$ 个特征向量对应的特征值。 当特征值 $\\lambda$很大（相比 $\\alpha$）时，缩放因子对权重影响较小，因而更新过程中产生的变化也不大；而当特征值较小时， $\\alpha$的缩放作用就显现出来，将这个方向的权重衰减到0。 这种效果也可以由下图表示： ———————————————————推导部分结束——————————————————— 总结来说，目标函数的Hessian矩阵（显式、隐式或者近似的）是现有优化算法进行寻优的主要依据。通过控制权重衰减的 $\\alpha$ 参数，我们实际上控制的是在Hessian矩阵的特征方向上以多大的幅度缩放权重，相对重要（能够显著减小目标函数）的方向上权重保留比较完好，而无助于目标函数减小的方向上权重在训练过程中逐渐地衰减掉了。而这也就是权重衰减的意义。 从宏观上来看，对目标函数来说，特征值较大的方向包含更多有关数据的信息，较小的方向则有随机性的噪声，权重衰减正是通过忽略较少信息方向的变化来对抗过拟合的。 $L^1$ 范数正则化通过类似的推导，可以得到加入了 $L^1$ 范数惩罚项对参数最优解的影响如下： $$w^{(2)}{i} = sign(w^{(1)}{i}) max \\big{|w^{(1)}{i}| - \\frac{\\alpha}{H{i,i}}, 0 \\big}$$ 相比 $L^2$ 范数的影响，这是一个离散的结果，因而 $L^1$ 范数惩罚会将参数推向更加稀疏的解。这种稀疏性质常被用作特征选择。 权重衰减的贝叶斯解释在贝叶斯统计的框架下，常用的推断策略是最大后验点估计(Maximum A Posteriori, MAP)。有如下的推断公式（由贝叶斯定律导出）： $${\\theta}_{MAP} = argmax p(\\theta | x) = argmax (log p( x | \\theta) + log p(\\theta))$$ 上式右边第一项是标准的对数似然项，而第二项对应着先验分布。 在这样的视角下，我们只进行最大似然估计是不够的，还要考虑先验 $p(\\theta)$ 的分布。而当假定参数为正态分布 $N(w; 0, \\frac{1}{\\lambda}I^2)$ 时，带入上式（ $\\theta$ 为参数），即可发现第二项的结果正比于权重衰减惩罚项 $\\lambda w^T w$ ，加上一个不依赖于 $w$ 也不影响学习过程的项。于是，具有高斯先验权重的MAP贝叶斯推断对应着权重衰减。 权重衰减与提前终止提前终止也是一种正则化技术，其想法简单粗暴：每个epoch之后在验证集上评估结果，当验证集误差不再下降的时候，我们认为模型已经尽它所能了，于是终止训练过程。 提前终止以牺牲一部分训练数据来作为验证数据来的代价来对抗过拟合，其逻辑是实证主义的。 然而，在二次近似和简单梯度下降的情形下，可以观察到提前终止可以有相当于权重衰减的效果。 我们仍考虑目标函数的二次近似： $$J(w) \\approx J(w^{(1)}) + \\frac{1}{2} (w - w^{(1)})^T H (w - w^{(1)})$$ 记最优参数点为 $w^{(1)}$ ，其梯度为： $${\\nabla}_{w} J(w) \\approx H(w - w^{(1)})$$ 不加入正则化项，其梯度下降的更新策略（从第 $\\tau-1$ 步到 $\\tau$ 步）为： $$ w^{(\\tau)} = w^{\\tau - 1)} - \\epsilon H (w^{(\\tau - 1)} - w^{(1)})$$ 累加得到 $$ w^{(\\tau)} - w^{(1)} = (I - \\epsilon H) (w^{(\\tau - 1)} - w^{(1)})$$ 将Hessian矩阵分解，得到如下形式 $$ w^{(\\tau)} = Q[I - (I - \\epsilon \\Lambda) ^ {\\tau}] Q^T w^{(1)} $$ 将加入正则化项的权重影响改写为 $$ w^{(2)} = Q[I - (\\Lambda + \\alpha I) ^ {-1} \\alpha] Q^T w^{(1)} $$ 对比可以得到，如果超参数 $\\epsilon, \\alpha, \\tau$ 满足 $$ (I - \\epsilon \\Lambda) ^ {\\tau} = (\\Lambda + \\alpha I) ^ {-1} \\alpha $$ 则提前终止将与权重衰减有相当的效果。具体的，即第 $\\tau$ 步结束的训练过程将到达超参数为 $\\alpha$ 的 $L^2$ 正则化得到的最优点。 但提前终止带来的好处是，我们不再需要去找合适的超参数 $\\alpha$ ，而只需要制定合理的终止策略（如3个epoch均不带来验证集误差的减小即终止训练），在训练成本的节约上，还是很值得的。 @ddlee","link":"/posts/cd6f40b8/"},{"title":"[源码笔记]keras源码分析之Container","text":"本篇继续讨论keras的源码结构。 第一篇源码笔记中我们观察了Layer, Tensor和Node是如何耦合在一起的，而本篇的重点是观察多层网络构成的有向无环图（DAG）。主要涉及的文件为keras/engine/topology.py， 要观察的类是Container。 Container对象：DAG的拓扑原型在第一篇中我们提到，Keras Tensor中增强的\\_keras_history属性使得我们仅通过输入和输出的Tensor，就可以构建出整张计算图。而Container对象正是实现了这样的过程。 计算图的构建DAG计算图的构建在Container对象实例化时完成，主要包括如下几个操作： 1） 记录Container的首尾连接信息 def __init__(self, inputs, outputs, name=None): for x in self.outputs: layer, node_index, tensor_index = x._keras_history self.output_layers.append(layer) self.output_layers_node_indices.append(node_index) self.output_layers_tensor_indices.append(tensor_index) for x in self.inputs: layer, node_index, tensor_index = x._keras_history self.input_layers.append(layer) self.input_layers_node_indices.append(node_index) self.input_layers_tensor_indices.append(tensor_index) 2） 从output_tensors开始反向递归构建计算图，采用广度优先的准则，本步的关键是构建nodes_in_decreasing_depth这一队列，这些Node包含的连接信息和深度信息将是后续正向传播和反向训练计算执行顺序的依据。 def build_map_of_graph(tensor, finished_nodes, nodes_in_progress): layer, node_index, tensor_index = tensor._keras_history node = layer.inbound_nodes[node_index] nodes_in_progress.add(node) # 广度优先搜索 for i in range(len(node.inbound_layers)): x = node.input_tensors[i] layer = node.inbound_layers[i] node_index = node.node_indices[i] tensor_index = node.tensor_indices[i] # 递归调用 build_map_of_graph(x, finished_nodes, nodes_in_progress, layer, node_index, tensor_index) # 维护两个队列 finished_nodes.add(node) nodes_in_progress.remove(node) nodes_in_decreasing_depth.append(node) # 反向构建DAG for x in self.outputs: build_map_of_graph(x, finished_nodes, nodes_in_progress) 3） 计算各节点的深度并按深度标定节点在DAG中的位置 # 根据队列标定各节点的深度 for node in reversed(nodes_in_decreasing_depth): depth = nodes_depths.setdefault(node, 0) previous_depth = layers_depths.get(node.outbound_layer, 0) depth = max(depth, previous_depth) layers_depths[node.outbound_layer] = depth nodes_depths[node] = depth for i in range(len(node.inbound_layers)): inbound_layer = node.inbound_layers[i] node_index = node.node_indices[i] inbound_node = inbound_layer.inbound_nodes[node_index] previous_depth = nodes_depths.get(inbound_node, 0) nodes_depths[inbound_node] = max(depth + 1, previous_depth) # 按深度标定各节点的位置 nodes_by_depth = {} for node, depth in nodes_depths.items(): if depth not in nodes_by_depth: nodes_by_depth[depth] = [] nodes_by_depth[depth].append(node) # 按深度标定各层的位置 layers_by_depth = {} for layer, depth in layers_depths.items(): if depth not in layers_by_depth: layers_by_depth[depth] = [] layers_by_depth[depth].append(layer) self.layers_by_depth = layers_by_depth self.nodes_by_depth = nodes_by_depth 4）将整个Container并入Node以保持兼容性 self.outbound_nodes = [] self.inbound_nodes = [] Node(outbound_layer=self, inbound_layers=[], node_indices=[], tensor_indices=[], input_tensors=self.inputs, output_tensors=self.outputs, ...) 计算图中的计算计算在Container对象的call()方法完成，其实现又依靠内部方法run_internal_graph()。 def run_internal_graph(self, inputs, masks=None): depth_keys = list(self.nodes_by_depth.keys()) depth_keys.sort(reverse=True) # 依据深度 for depth in depth_keys: nodes = self.nodes_by_depth[depth] # 对同一深度上的Node进行计算 for node in nodes: layer = node.outbound_layer # Node对应的layer reference_input_tensors = node.input_tensors reference_output_tensors = node.output_tensors computed_data = [] if len(computed_data) == len(reference_input_tensors): # 在Layer中进行计算 with K.name_scope(layer.name): if len(computed_data) == 1: computed_tensor, computed_mask = computed_data[0] output_tensors = _to_list(layer.call(computed_tensor, **kwargs)) computed_tensors = [computed_tensor] else: computed_tensors = [x[0] for x in computed_data] output_tensors = _to_list(layer.call(computed_tensors, **kwargs)) output_tensors = [] output_masks = [] for x in self.outputs: tensor, mask = tensor_map[str(id(x))] output_tensors.append(tensor) output_masks.append(mask) return output_tensors, output_masks 从上面的代码可以看到计算是依据深度进行的，并通过更新computed_data和output_tensor等变量完成整张图的遍历计算。 继续阅读系列第三篇：【源码笔记】keras源码分析之Model @ddlee","link":"/posts/ba61101c/"},{"title":"[源码笔记]keras源码分析之Layer、Tensor和Node","text":"Keras架构的主要逻辑实现在/keras/engine/topology.py中，主要有两个基类Node()和Layer()，一个重要函数Input()。具体地， Layer()是一个计算层的抽象，完成网络中对Tensor的计算过程； Node()描述两个层之间连接关系的抽象，配合Layer()构建DAG； Input()实例化一个特殊的Layer(InputLayer)，将backend（TensorFlow或Theano）建立的Tensor对象转化为Keras Tensor对象。 Keras Tensor： 增强版Tensor相比原始的TensorFlow或者Theano的张量对象，Keras Tensor加入了如下两个属性，以使Tensor中包含了自己的来源和规模信息： _Keras_history: 保存了最近一个应用于这个Tensor的Layer _keras_shape: 标准化的Keras shape接口 当使用Keras建立深度网络时，传入的数据首先要经过Input()函数。在Input()函数中，实例化一个InputLayer()对象，并将此Layer()对象作为第一个应用于传入张量的Layer，置于_keras_history属性中。此外，InputLayer()和Input()还会对传入的数据进行规模检查和变换等，使之符合后续操作的要求。 代码上实现如下： def Input(): input_layer = InputLayer() outputs = InputLayer.inbound_nodes[0].output_tensor return outputs class InputLayer(): def __init__(): input_tensor._keras_history = (self, 0, 0) Node(self, ...) 在下面我们将看到，加入的_keras_history属性在计算图的构建上所起的作用是关键的。仅通过输入和输出的Tensor，我们可以构建出整张计算图。但这样的代价是Tensor对象太重了，包含了Layer的信息。 Node对象：层与层之间链接的抽象若考虑Layer对象抽象的是完成计算的神经元胞体，则Node对象是对神经元树突结构的抽象。其内聚的主要信息是： class Node(): def __init__(self, outbound_layer, inbound_layers, node_indices, tensor_indices, input_tensors, output_tensors, ...) 其中outbound_layer是施加计算（使input_tensors变为output_tensors）的层，inbound_layers对应了input_tensors来源的层，而node_indices和tensor_indices则记录了Node和Layer之间的标定信息。 Node对象总在outbound_layer被执行时创建，并加入outbound_layer的inbound_nodes属性中。在Node对象的表述下，A和B两个层产生连接关系时，Node对象被建立，并被加入A.outbound_nodes和B.inbound_nodes。 Layer对象：计算层的抽象Layer对象是对网络中神经元计算层的抽象，实例化需要如下参数： allowed_kwargs = {&apos;input_shape&apos;, &apos;batch_input_shape&apos;, &apos;batch_size&apos;, &apos;dtype&apos;, &apos;name&apos;, &apos;trainable&apos;, &apos;weights&apos;, &apos;input_dtype&apos;, # legacy } 大部分与传入数据的类型和规模相关，trainable表征该层是否需要更新权重。此外，还有inbound_nodes和outbound_nodes属性来标定与Node对象的链接。 Layer对象最重要的方法是__call__()，主要完成如下三件事情： 验证传入数据的合法性，通过调用内部方法实现：self.assert_input_compatibility(inputs) 进行计算outputs = self.call(inputs, ...)，被其子类具体实现，如Linear, Dropout等 更新Tensor中的_keras_history属性，记录该次计算操作，通过内部方法_add_inbound_nodes()实现 方法_add_inbound_nodes()对Tensor的更新是构建Layer之间关系的关键操作，其主要代码如下： for x in input_tensors: if hasattr(x, &apos;_keras_history&apos;): inbound_layer, node_index, tensor_index = x._keras_history inbound_layers.append(inbound_layer) node_indices.append(node_index) tensor_indices.append(tensor_index) # Node对象的建立过程中将更新self的inbound_nodes属性 Node(self, inbound_layers=inbound_layers, node_indices=node_indices, tensor_indices=tensor_indices, ...) for i in range(len(output_tensors)): output_tensors[i]._keras_history = (self, len(self.inbound_nodes) - 1, i) 上段代码取出input_tensor的_keras_history属性，建立新的Node，并将当前Layer的信息更新到计算得到的output_tensor中。 实例：Node,Tensor和Layer间连接关系的表征下面通过代码来说明三者之间的关系，来自于测试代码： # 建立新的keras Tensor a = Input(shape=(32,), name=&apos;input_a&apos;) b = Input(shape=(32,), name=&apos;input_b&apos;) a_layer, a_node_index, a_tensor_index = a._keras_history assert len(a_layer.inbound_nodes) == 1 assert a_tensor_index is 0 # node和layer之间的关系 node = a_layer.inbound_nodes[a_node_index] assert node.outbound_layer == a_layer # 建立连接层，将Tensor传入 dense = Dense(16, name=&apos;dense_1&apos;) a_2 = dense(a) b_2 = dense(b) assert len(dense.inbound_nodes) == 2 assert len(dense.outbound_nodes) == 0 # 与张量a关联的Node assert dense.inbound_nodes[0].inbound_layers == [a_layer] assert dense.inbound_nodes[0].outbound_layer == dense assert dense.inbound_nodes[0].input_tensors == [a] # 与张量b关联的Node assert dense.inbound_nodes[1].inbound_layers == [b_layer] assert dense.inbound_nodes[1].outbound_layer == dense assert dense.inbound_nodes[1].input_tensors == [b] 总结keras利用Node对象描述Layer之间的连接关系，并在Tensor中记录其来源信息。在下篇中，我们将看到keras如何利用这些抽象和增强属性构建DAG，并实现前向传播和反向训练的。 @ddlee","link":"/posts/4943e1b8/"},{"title":"[源码笔记]keras源码分析之Model","text":"本篇是keras源码笔记系列的第三篇。在前两篇中，我们分析了keras对Tensor和Layer等概念的处理，并说明了它们是如何作用别弄个构成有向无环图的。本篇着眼于多层网络模型层面的抽象，即与用户距离最近的接口，源代码文件是/keras/engine/training.py和/keras/model.py，要观察的类是Model和Sequential。 本系列第一篇：【源码笔记】keras源码分析之Tensor, Node和Layer第二篇：【源码笔记】keras源码分析之Container Model：添加了训练信息的ContainerModel.compile()主要完成了配置optimizer, loss, metrics等操作，而要执行的fit, evaluate等则不在compile过程中配置。 def compile(self, optimizer, loss, metrics=None, loss_weights=None, sample_weight_mode=None, **kwargs): loss = loss or {} self.optimizer = optimizers.get(optimizer) self.sample_weight_mode = sample_weight_mode self.loss = loss self.loss_weights = loss_weights loss_function = losses.get(loss) loss_functions = [loss_function for _ in range(len(self.outputs))] self.loss_functions = loss_functions # Prepare targets of model. self.targets = [] self._feed_targets = [] for i in range(len(self.outputs)): shape = self.internal_output_shapes[i] name = self.output_names[i] target = K.placeholder(ndim=len(shape), name=name + &apos;_target&apos;, sparse=K.is_sparse(self.outputs[i]), dtype=K.dtype(self.outputs[i])) self.targets.append(target) self._feed_targets.append(target) # Prepare metrics. self.metrics = metrics self.metrics_names = [&apos;loss&apos;] self.metrics_tensors = [] # Compute total loss. total_loss = None for i in range(len(self.outputs)): y_true = self.targets[i] y_pred = self.outputs[i] loss_weight = loss_weights_list[i] if total_loss is None: total_loss = loss_weight * output_loss else: total_loss += loss_weight * output_loss for loss_tensor in self.losses: total_loss += loss_tensor self.total_loss = total_loss self.sample_weights = sample_weights Model对象的fit()方法封装了_fit_loop()内部方法，而_fit_loop()方法的关键步骤由_make_train_function()方法完成，返回history对象，用于回调函数的处理。 def fit(self, x=None, y=None, ...)： self._make_train_function() f = self.train_function return self._fit_loop(f, ins, ...) 在_fit_loop()方法中，回调函数完成了对训练过程的监控记录等任务，train_function也被应用于传入的数据： def _fit_loop(self, f, ins, out_labels=None, batch_size=32, epochs=100, verbose=1, callbacks=None, val_f=None, val_ins=None, shuffle=True, callback_metrics=None, initial_epoch=0): self.history = cbks.History() callbacks = [cbks.BaseLogger()] + (callbacks or []) + [self.history] callbacks = cbks.CallbackList(callbacks) out_labels = out_labels or [] callbacks.set_model(callback_model) callbacks.set_params({ &apos;batch_size&apos;: batch_size, &apos;epochs&apos;: epochs, &apos;samples&apos;: num_train_samples, &apos;verbose&apos;: verbose, &apos;do_validation&apos;: do_validation, &apos;metrics&apos;: callback_metrics or [], }) callbacks.on_train_begin() callback_model.stop_training = False for epoch in range(initial_epoch, epochs): callbacks.on_epoch_begin(epoch) batches = _make_batches(num_train_samples, batch_size) epoch_logs = {} for batch_index, (batch_start, batch_end) in enumerate(batches): batch_ids = index_array[batch_start:batch_end] batch_logs = {} batch_logs[&apos;batch&apos;] = batch_index batch_logs[&apos;size&apos;] = len(batch_ids) callbacks.on_batch_begin(batch_index, batch_logs) # 应用传入的train_function outs = f(ins_batch) callbacks.on_batch_end(batch_index, batch_logs) callbacks.on_epoch_end(epoch, epoch_logs) callbacks.on_train_end() return self.history _make_train_function()方法从optimizer获取要更新的参数信息，并传入来自backend的function对象： def _make_train_function(self): if self.train_function is None: inputs = self._feed_inputs + self._feed_targets + self._feed_sample_weights training_updates = self.optimizer.get_updates( self._collected_trainable_weights, self.constraints, self.total_loss) updates = self.updates + training_updates # Gets loss and metrics. Updates weights at each call. self.train_function = K.function(inputs, [self.total_loss] + self.metrics_tensors, updates=updates, name=&apos;train_function&apos;, **self._function_kwargs) Model的其他方法evaluate()等，与fit()的结构类似。 Sequential:构建模型的外层接口Sequential对象是Model对象的进一步封装，也是用户直接面对的接口，其compile(), fit(), predict()等方法与Model几乎一致，所不同的是添加了add()方法，也是我们用于构建网络的最基本操作。 Sequential.add()方法的源码如下： def add(self, layer): # 第一层必须是InputLayer对象 if not self.outputs: if not layer.inbound_nodes: x = Input(batch_shape=layer.batch_input_shape, dtype=layer.dtype, name=layer.name + &apos;_input&apos;) layer(x) self.outputs = [layer.inbound_nodes[0].output_tensors[0]] self.inputs = topology.get_source_inputs(self.outputs[0]) topology.Node(outbound_layer=self, ...) else: output_tensor = layer(self.outputs[0]) self.outputs = [output_tensor] self.inbound_nodes[0].output_tensors = self.outputs self.layers.append(layer) 可以看到，add()方法总是确保网络的第一层为InputLayer对象，并将新加入的层应用于outputs，使之更新。因此，从本质上讲，在Model中添加新层还是在更新模型的outputs。 @ddlee","link":"/posts/ddc5b1bd/"},{"title":"有关深度学习的一些想法和困惑","text":"本文是我在目标检测任务上实践深度学习方法的一点想法和疑惑，学历尚浅，视野有限，还请大家评论指正。 我们离人工智能还有多远？这可说不准。我们现在对人类本身的智能还没有一个被广泛接受的理论和概念框架，你没办法定义终点时，你当然说不准你离它有多远。 在我看来，目前基于深度学习方法的模型，大部分实现的实际上是 在时间和规模尺度上对某些人类基本能力的延伸。如视觉系统中的人脸识别，我们本来把认脸作为自己的一项基本能力，但当规模扩大后，我们便无能为力：我们难以从上百万千万张脸中找到跟目标最相似的那一个。于是，人脸识别模型延伸了我们在规模层面上认脸的能力，同时还有时间上的。然而，你并不会把认脸这一能力称为智能，它真的只是我们的一项基本能力而已。就像交通工具是我们双腿的延伸，目前的智能系统只是我们熟知能力的延伸。 更远些，目前的智能系统还不能成为一个主动的行为对象，而且你应该对那些对智能系统使用拟人化表达的文章提起警惕。夏天，OpenAI的OpenAI Five1挑战Dota2人类玩家时，有媒体还报道OpenAI Five学习了上一局中人类的战术，并在自我进化。这里其实混淆了学习模型的训练过程和推断过程。模型进入推断时，唯一在学习的其实是OpenAI Five的研究者，他们在观察人类的战术，并思考如何将这些建模到自己的模型里。再远至智能系统是否有自由意志、有情绪感受等，那将进入社会学和哲学的范畴，至少在我看来目前缺乏概念工具去建立具有技术指导意义的严肃讨论。 那么，现在到底是什么状况？现在我们找到了一种新的解决问题的范式：让渡一部分对模型的控制权和解释性，来提高对数据（和算力）的利用效率。过去，我们对问题进行逻辑上的解构，采用策略、规则、逻辑系统等将问题分解和逐步逐层解决。但这种方案并不能适用所有问题，尤其是那些我们尚不能理解的过程。与此同时，我们发现尽管不能理解个中原理，但我们有大量对这一过程的观察结果，于是，设计一个具有大量待定参数的模型，用这样的模型去拟合观察到的数据，便成了一种自然的方案。深度学习模型，则是在这一思路下的一种具有很高灵活性和扩展空间的建模方法。 于是，深度学习方法在享受高度灵活性对数据充分的利用效率同时，也背上了难以解释和公理化重负。从这个意义上讲，数据其实是模型的一部分。对于目前基于深度学习方法在某些任务上取得的进展，“达到可用”是比“超越人类水平”或者“解决问题”等更不容易引起困惑的表述。 怎样才是算复现了一个学习模型？在一个纯净和自恰的数学论证过程中，定义、引理、推理依据都清清楚楚，我们只需完成逻辑上的验证，即可认为这一结论被我们接受了。然而，学习模型要通过一定的优化过程达到可用的程度，并严重依赖实验和复杂计算过程的研究方式，这些让 所使用的优化算法和工具栈都成了模型的一部分。 对于某一文章中描述的模型，我们如何判断其他人能够复现其结果？是否意味着，我们需要和作者从完全一样的随机初始化起点开始，使用完全相同的优化算法和优化器配置，经过同样的迭代次数，到达同样的模型参数状态？更深一点，我们所使用的编程语言对数据的表示、选用的浮点数精度、乃至硬件设备等，会不会对这一计算过程的复现产生影响？ 我们如何确认一项工作的贡献？依赖工程实现和计算过程带来的弊端，还体现在我们难以建立可以被广泛接受的贡献确认标准。我们很难判断某项工作带来的真正贡献以及如何确认和验证，不要误会，我没有奢求有一个像希尔伯特问题那样的纲领性指南。这提醒我们一项工作中最重要的部分实际上是作者的 消融实验(Ablation Study)。这些实验的对照设置是否能够支撑作者的改进之处？实验是否控制了足够的变量，对比是否合理？ 另外，较为严苛的复现条件也限制了很多工作的可推广性，某项工作的改进常常并不能完全独立出来，在其他结构和模型上发挥同样出色的性能。这其实要求作者去做更多的鲁棒性和推广性实验，来支撑其改进之处的适用性。这里是我疑惑比较大的地方：我们该如何评定某项工作为解决某一问题做出的贡献？一个容易观测的指标是在标准评测集上的表现，但如何分离工作中提出的方法和评测这一指标过程带来的影响？如果需要给出某些工作做为基准，那这些工作该如何选取，选取后又如何控制变量来保证对要评测工作提出方法提供一个公允的基准呢？ 前面提到，数据可以被认为是模型的一部分。于是，ImageNet这样的公开评测集可以作为标准来衡量不同模型的表现如何，这确实是一项重要的标准。然而，更为重要的还包括问题表述和评测标准的演进，我们需要更立体深入地认识目标问题，而非单纯地扩展数据集规模。当Google公布他们的Open Images数据集2时，更吸引我的不是规模有多大，而是是否提出了更公允清晰的评测标准（然而他们没有）。 怎样的论证和解释才是值得信服的？目前，一部分工作的成果汇报和工程实现之间存在解释性的鸿沟。我们无法清晰地描述某些配置和做法其之所以如此的道理和实际发挥的效果，我们只能说实验表明是这样的。一个例子是在目标检测的单阶段模型代表性工作SSD中，作者提交的论文和开源的代码实现之间有相当大的距离。事实上，作者的代码充满了工程脚手架，我曾注意到一个将IOU阈值逐步衰减的超参3，但在最终的配置中却没有被使用，自然在论文中也没有提及。一个可能的原因是，作者进行的尝试没有取得预期的效果。那么问题是，如何确定，最终被使用的部分都有符合逻辑的解释，并且是必要的呢？ 另一个重要的问题是术语的过载和滥用现象。这些情况下，某一名词被我们赋予了过多且并不近似的含义，常常会引起相当的困惑和沟通上的不便。比如特征（Feature）这一词，既在通用机器学习中代指跟实例相对的数据维度，又在神经网络中代表某一层张量，FPN论文4中为其加上高等级语义（High-level Semantic）这一修饰语则又暗示它还跟我们的视觉系统抽象出来用于辨别物体的概念有共通之处。这样的过载和滥用容易引起概念上的混淆和讨论时的误会，我们也许需要更规范和清晰的表述词库。 部分工作还存在被我称为“软数学化”的现象。在没有提供精准定义和定理体系的情况下，某些论文中借用一部分数学表述来解释自己做法的合理性，但让人难以判断的是这一部分表述的原本数学含义和背景是否符合论文中的情景。一个例子是提出Batch Normalization论文5中，作者用Internal Covariate Shift来解释使用归一化的原因，但这一术语的背景和定义等都不能自成体系。但这一点被不少人忽略了：它只要起作用就是了。再如MobileNetV2的论文6的附录部分用矩阵是否可逆来衡量使用ReLU单元后的信息损失，并用n-volume指代特征层所能表达的空间维度大小，且不说所用于衡量和指代的对象尚无广泛接受的定义，这些从代数中借用过来的概念本身就未经论证其适用的合理性。 结语上面提到的这些相对保守且不成熟的认识和困惑并不能成为我们否定深度学习方法取得成就的理由，更应该成为前行路上某次小憩时做出的回顾和反思。上面的这些困惑来自于我并不够多的论文阅读经验，也仅局限在基于深度学习方法的图片分类和目标检测领域，还请读者多多评论交流。 1.OpenAI Five - OpenAI Blog ↩2.Open Images Dataset V4 ↩3.caffe/tree/ssd/src/caffe/util/bbox_util.cpp - GitHub ↩4.Feature Pyramids for Object Detection - arXiv ↩5.Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift - arXiv ↩6.MobileNetV2: Inverted Residuals and Linear Bottlenecks - arXiv ↩","link":"/posts/684dd540/"},{"title":"Python可视化工具指引","text":"本文主要材料来自Jake VanderPlas在PyCon 2017上的演讲Python’s Visualization Landscape Python真是越来越火了。活跃的开源社区为Python这门语言贡献着长青的活力。 子曾经曰过：轮子多了，车就稳了。 本文帮助你选好轮子，也祝愿可视化的车开得越来越稳。 The Landscape 如图。 VanderPlas在展示完这张全景图后给大家贴了这张图： 我差点笑喷。我们的表情包可能要在人民币之前走向国际化了。 回到正题，可视化工具有两个主要阵营，一是基于matplotlib，二是基于JavaScript。还有的接入了JS下著名的D3.js库。 Matplotlibnumpy, pandas, matplotlib可以说是python数据科学的三驾马车。凡以python为教学语言的数据科学相关课程必提这三个库。而matplotlib又有什么特点呢？ 先说优点： 像MATLAB的语法，对MATLAB用户好上手 稳定，久经考验 渲染后端丰富，跨平台（GTK, Qt5, svg, pdf等） 缺点也有很多： API过于繁琐 默认配色太丑 对web支持差，交互性差 对大数据集处理较慢 于是就有了很多基于matplotlib的扩展，提供了更丰富、更人性化的API。 下面是几个比较受欢迎的包： pandaspandas的DataFrame对象是有plot()方法的，如：iris.plot.scatter(&apos;petalLength&apos;, &apos;petalWidth&apos;)生成二维散点图，只需指明两个轴取自哪一列数据即可。 seabornseaborn(gallery)专注于统计数据可视化，默认配色也还可以。语法示例： import seaborn as sns sns.lmplot(&apos;petalLength&apos;, &apos;sepalWidth&apos;, iris, hue=&apos;species&apos;, fit_reg=False) 类ggplot对于R用户，最熟悉的可视化包可能是ggplot2，在python中可以考虑ggpy和近期上了Github Trends的plotnie。 JavaScript基于JS的包常常具有非常好的交互性，其共同点是将图形格式化为json文件，再由JS完成渲染。 BokehBokeh(Gallery)定位于绘制用于浏览器展示的交互式图形。其优点是交互性、能够处理大量数据和流数据。语法示例： p = figure() p.circle(iris.petalLength, iris.sepalWidth) show(p) PlotlyPlotly(Gallery)跟Bokeh类似。但其提供了多种语言接口(JS, R, Python, MATLAB)，并且支持3D和动画效果，缺点是有些功能需要付费。语法示例： from plotly.graph_objs import Scatter from plotly.offline import iplot p = Scatter(x=iris.petalLength, y=iris.sepalWidth, mode=&apos;markers&apos;) iplot(p) 处理大型数据集对于大型数据集，可以考虑的包包括datashader, Vaex, 基于OpenGL的Vispy和Glumpy，GlueViz等。这里介绍datashader。 datashaderdatashader是Bokeh的子项目，为处理大型数据集而生。 示例语法： from colorcet import fire export(tf.shade(agg, cmap=cm(fire, 0.2), how=&apos;eq_hist&apos;), &apos;census_ds_fier_eq_hist&apos;) 最终的建议上车忠告： matplotlib必会 R用户：ggpy/plotnine 交互式：plotly(与R接口统一)/bokeh(免费)","link":"/posts/d80d5b04/"},{"title":"网站迁移小记：腾讯云+Debian+Vestacp","text":"先贴一张文章大纲。 这是一个樱花开得正好但我很蛋疼的下午。 中午抢到了腾讯的校园优惠，便打算把网站ddlee.cc迁到国内的服务器上来。 密码管理先谈密码管理。 建站会涉及设置很多密码，之前明文保存在云笔记里的方案总觉得又土又笨，何况很多密码最好要随机生成，密码管理服务还是必要的。 搜索之后，我选择的是lastPass。主要考虑了免费和跨平台的特性。有更高要求的建议选择付费的1Password。 需要安装Chrome插件和Ubuntu下的deb包，添加Secure Note的功能深得我心，也支持自定义模板。 主机腾讯云的校园优惠力度很大。阿里云是9.9块/月，腾讯用完券1块/月。 这里多讲一句，学生真是幸福得不得了。GitHub Education Pack中既有有Digital Ocean的优惠，AWS也有150刀的礼品卡，Jetbeans大部分产品免费……这还不提学校里买的License。 腾讯的主机1核CPU，2G内存，20G系统盘（Linux），挂个网站还算够用。 SSH Key 配置建议在配置主机前创建一个SSH Key，这样访问起来安全又省心。 Linux系统下，在~/.ssh/下新建config，写入如下类似内容： Host Name HostName Host_IP User root IdentityFile path/to/ssh_private_key 这样就可以通过命令ssh Name直接访问主机。 系统选择建议选择Linux主机。具体哪一系可自行选择，我的选择是Debian，CentOS也是个不错的选择。 安全组设置建议先只开启用于SSH的22端口，之后再开HTTP访问的80端口，FTP的20,21端口和主机面板所用端口。 如果个人有代理服务器的话，也可以限制一下来源IP，这样可以通过登入代理服务器，在代理服务器上通过SSH登入WEB主机，需要迁移下SSH Private Key，可以通过命令scp usr1@host1:/path1 usr2@host2:/path2实现。 网络环境LNMP和LAMP是两种流行的结构。可以分别安装，再配置相应的config，也可以搜索得到很多一键安装脚本。另一种方案是用Docker部署。 我懒而笨，选择的是用主机面板一键安装。 主机面板在此之前，一直用的是AMH的免费4.2版本，简洁轻巧，功能也够用。付费版推出后，免费版遭到冷落，几乎没有更新，这如何能忍。 说起主机面板，我的启蒙是WDCP，其远古风格的UI仍历历在目，后来听说爆出漏洞，但那时我已转战AMH。 一番艰苦卓绝的搜索之后（其实就是检索了’best host control pannel’），我选择了Vestacp。 UI漂亮，功能不缺（建站，MAIL，备份），GitHub还算活跃，就决定是你了。 缺点是文件管理器收费，不能通过WEB管理文件。安装过程持续蛮久（半个小时，当然也包括了新主机系统包更新的时间）。 安装时注意Hostname填写IP或者已经配置好DNS解析的域名（如admin.ddlee.cc）。8083是管理面板的端口，记得在主机提供商的安全组里开放一下。 建站Vestacp支持多人管理，User身份由Package定义，安装过程会自动新建admin，拥有最高权限。 在User的设置里，可以配置用户的Package，而Package的设置里，可以配置每一用户身份的建站模板，资源上限等。如图。 建站相当容易，注意在高级选项里添加FTP账户，用于之后上传HTML文件。 FTP建站完成后，记得配置好DNS解析，开放20和21端口，就可以用FileZilla测试链接。 注意，在高级选项里配置好Default local directory，设置Default remote directory为/public_html，并启用synchronized browsing和directory comparison，以后的FTP生活会很幸福。 Mail若在建站时勾选了Mail support，可以建立个性化的邮箱名，可以设置自动回复/转发，也可以用Gmail托管。以后留邮箱的时候可以短短的了呢。 配置SSL这是无意发现的技能。 本来在我的印象里，SSL证书都是要收费的。但留心的朋友可能注意到，建站时SSL support下有Lets Encrypt Support。这一服务可以用上免费的SSL。 官网：Let’s Encrypt 要利用这项服务，需要证明自己对网站的至高无上不可侵犯的神圣权利，方法之一是运行支持[ACME protocol]的Client，官网推荐了Cerbot。 在Cerbot主页可以选择自己的操作系统，会有详细的步骤，在此不表。 下面谈两个问题，一是强制重定向至HTTPS，二是取消管理端口的HTTPS。 强制HTTPSVestacp的架构是用nginx做proxy，Apache2做HTTP Server，首先下载nginx template（proxy template）： cd /usr/local/vesta/data/templates/web wget http://c.vestacp.com/0.9.8/rhel/force-https/nginx.tar.gz tar -xzvf nginx.tar.gz rm -f nginx.tar.gz 之后在Package配置里，将proxy template配置为force-https，这样，身份由相应Package定义的用户建站时，proxy template就是用的强制HTTPS版本了。 取消管理端口的SSL用chrome访问管理页面时，会有Unsecure的警告，这里的SSL在/usr/local/vesta/nginx/conf/nginx.conf中配置。找到 # Vhost server { listen 8083; server_name _; root /usr/local/vesta/web; charset utf-8; # Fix error &quot;The plain HTTP request was sent to HTTPS port&quot; error_page 497 https://$host:$server_port$request_uri; # ssl on; # ssl_certificate /usr/local/vesta/ssl/certificate.crt; # ssl_certificate_key /usr/local/vesta/ssl/certificate.key; # ssl_session_cache shared:SSL:10m; # ssl_session_timeout 10m; 将配置SSL的几行注释掉即可。顺便，管理页面的端口也可以在这里更改。之后运行service vesta restart重启服务。 域名与DNS最后简单提一下域名注册跟DNS。要注意的几个点： 国内域名注册要备案，很烦，但cn域名好便宜。 在域名注册商那里配置DNS解析服务器（万网、DNSPod都好，不一定用自建网站的DNS） 在DNS服务商那里添加解析记录，顺便开启监控 拾遗域名备案的时候，需要签一张备案单。方案是在纸上签字后调背景为透明，用Adobe PDF Reader的签字功能签好PDF，再转成JPG。 几项操作都可以通过在线工具完成，低碳生活，人人有责。 总结 建站过程本身就其乐无穷，教程一抓一大把，难的在TROUBLE SHOOTING，所以Google是最好的伴侣。 命令行、vi编辑、必要的WEB知识等是基础。 @ddlee","link":"/posts/c2808f2a/"},{"title":"深度学习和分布式表示","text":"本文的两个主要参考资料： Yoshua Bengio在2016年九月Deep Learning School的演讲Foundations and Challenges of Deep Learning。YouTube Deep Learning, Goodfellow et al, Section 15.4 从机器学习到人工智能在演讲中，Bengio提到从机器学习到人工智能有五个关键的飞跃： Lots of data Very flexible models Enough computing power Powerful priors that can defeat the curse of dimensionality Computationally efficient inference 第一点已经发生，到处都提大数据，到处都在招数据分析师。我在读高中时，就曾预感数据将是新时代的石油和煤炭，因为数据正是人类社会经验的总结，数据带来的知识和见解将在驱动社会进步中发挥越来越重要的作用，而自己要立志成为新时代的矿工。 第二点在我看来有两个例子，一是核技巧，通过核函数对分布空间的转换，赋予了模型更强大的表述能力；二是深度神经网络，多层的框架和非线性的引入使得模型理论上可以拟合任意函数。 第三点，借云计算的浪潮，计算力不再是一项资产而是一项可供消费的服务，我们学生也可以廉价地接触到根本负担不起的计算力资源。而GPU等芯片技术的进步也为AI的浩浩征程添砖加瓦。 第五点，近期发布的Tensorflow Lite和Caffe2等工具也有助于越来越多地将计算任务分配在终端上进行，而非作为一个发送与接收器。 最后第四点，也是这篇文章的中心话题：借助分布式表示的强大能力，深度学习正尝试解决维度带来的灾难。 没有免费的午餐简单说，没有免费的午餐定理指出找不到一个在任何问题上都表现最优的模型/算法。不同的模型都有其擅长的问题，这由该模型建立时引入的先验知识决定。 那么，深度学习加入的先验知识是什么？ Bengio用的词是Compositionality，即复合性，某一概念之意义由其组成部分的意义以及组合规则决定。复合性的原则可以用于高效地描述我们的世界，而深度学习模型中隐藏的层正是去学习其组成部分，网络的结构则代表了组合规则。这正是深度学习模型潜在的信念。 分布式表示带来的指数增益分布式表示(Distributed Representation)是连接主义的核心概念，与复合性的原理相合。整体由组成它的个体及其组合来表示。请看下面的例子： 描述一个形状，我们将其分解为不同的特征来表述。分布式表示是一种解耦，它试图复杂的概念分离成独立的部分。而这也引出了分布式表示带来的缺点：隐藏层学到的分解特征难以得到显式的解释。 传统的机器学习算法，如K-Means聚类、决策树等，大多使用的是非分布式表示，即用特定的参数去描述特定的区域。如K-Means聚类，我们要划分多少区域，就需要有多少个中心点。因而，这类算法的特点是，随着参数个数的提升，其能描述的概念线性增长。 使用分布式表示的深度网络，则可以享受到指数级的增益，即，随着参数个数的提升，其表述能力是指数级的增长。具有$k$个值的$n$个特征，可以描述${k}^{n}$个不同的概念。 分布式表示在泛化上的优势分布式的想法还可以得到额外的泛化优势。通过重新组合在原有数据中抽离出来的特征，可以表示得到原有数据中不存在的实例。在Radford et al.的工作中，生成模型区习得了性别，并能从“戴眼镜的男人”-“男人”+“女人”=“戴眼镜的女人”这样的抽象概念表达式中生成实例。 分布式表示与巻积神经网络巻积神经网络不同的滤波器习得的特征可以为分布式表示的概念分解这一特性提供一些例子。下图是VGG16不同滤波器得到结果的可视化表示，出自Francois Chollet的博文How convolutional neural networks see the world 可以看到，浅层的滤波器学到的是简单的颜色、线条走向等特征，较深的滤波器学到复杂的纹理。 量子计算机与分布式表示在我看来，量子计算机的激动人心之处也在于其表示能力。一个量子态可以表示原先两个静态表示的信息，原先需要8个单位静态存储表示的信息只需要3个量子态单位即可表示，这也是指数级的增益。在这一点上，计算模型和概念模型已然殊途同归。 小结从经验中总结原则，用原则生成套路，正是我们自己处理和解决新问题的途径。通过解耦得到的信息来消除未知和不确定性，是我们智能的一部分。我们眼中的世界，只是适合我们的一种表示而已。也许，真正的人工智能到来那一刻，会是我们创造的机器“理解”了自己的表示系统之时——我们所关注的可解释性，也就无关紧要了。","link":"/posts/9f894922/"},{"title":"目标检测任务表述与模型基本结构","text":"本文节选自博主通过格灵深瞳机构号发表在知乎上的文章：干货 | 目标检测入门，看这篇就够了。 目标检测的任务表述如何从图像中解析出可供计算机理解的信息，是机器视觉的中心问题。深度学习模型由于其强大的表示能力，加之数据量的积累和计算力的进步，成为机器视觉的热点研究方向。 那么，如何理解一张图片？根据后续任务的需要，有三个主要的层次。 图像理解的三个层次 一是分类（Classification），即是将图像结构化为某一类别的信息，用事先确定好的类别(string)或实例ID来描述图片。这一任务是最简单、最基础的图像理解任务，也是深度学习模型最先取得突破和实现大规模应用的任务。其中，ImageNet是最权威的评测集，每年的ILSVRC催生了大量的优秀深度网络结构，为其他任务提供了基础。在应用领域，人脸、场景的识别等都可以归为分类任务。 二是检测（Detection）。分类任务关心整体，给出的是整张图片的内容描述，而检测则关注特定的物体目标，要求同时获得这一目标的类别信息和位置信息。相比分类，检测给出的是对图片前景和背景的理解，我们需要从背景中分离出感兴趣的目标，并确定这一目标的描述（类别和位置），因而，检测模型的输出是一个列表，列表的每一项使用一个数据组给出检出目标的类别和位置（常用矩形检测框的坐标表示）。 三是分割（Segmentation）。分割包括语义分割（semantic segmentation）和实例分割（instance segmentation），前者是对前背景分离的拓展，要求分离开具有不同语义的图像部分，而后者是检测任务的拓展，要求描述出目标的轮廓（相比检测框更为精细）。分割是对图像的像素级描述，它赋予每个像素类别（实例）意义，适用于理解要求较高的场景，如无人驾驶中对道路和非道路的分割。 检测模型基本特点深度学习方法主导下的检测模型，可以分为两阶段（two-stage）和单阶段（one-stage）。 两阶段检测模型Pipeline，来源 检测模型整体上由基础网络（Backbone Network）和检测头部（Detection Head）构成。前者作为特征提取器，给出图像不同大小、不同抽象层次的表示；后者则依据这些表示和监督信息学习类别和位置关联。检测头部负责的类别预测和位置回归两个任务常常是并行进行的，构成多任务的损失进行联合训练。 检测模型头部并行的分支，来源 相比单阶段，两阶段检测模型通常含有一个串行的头部结构，即完成前背景分类和回归后，把中间结果作为RCNN头部的输入再进行一次多分类和位置回归。这种设计带来了一些优点： 对检测任务的解构，先进行前背景的分类，再进行物体的分类，这种解构使得监督信息在不同阶段对网络参数的学习进行指导 RPN网络为RCNN网络提供良好的先验，并有机会整理样本的比例，减轻RCNN网络的学习负担 这种设计的缺点也很明显：中间结果常常带来空间开销，而串行的方式也使得推断速度无法跟单阶段相比；级联的位置回归则会导致RCNN部分的重复计算（如两个RoI有重叠）。 另一方面，单阶段模型只有一次类别预测和位置回归，卷积运算的共享程度更高，拥有更快的速度和更小的内存占用。读者将会在接下来的文章中看到，两种类型的模型也在互相吸收彼此的优点，这也使得两者的界限更为模糊。","link":"/posts/13efca78/"},{"title":"编程方法论:重构","text":"本文内容主要整理自lynda.com课程Programming Foudations: Refactoring Code和Martin Fowler的重构。全部例子来源于refactoring.com。 内容大纲： Introduction 定义重构是在不影响软件功能的情况下，重新组织代码，使之更清晰、更容易理解的过程。 前提：功能不变 行为：改写代码 目的：提高可理解性 大白话讲，重构就是改写，造福以后需要理解这段代码的人们。 重构不是什么给一件事物下定义，有时候从反方面更好讲些。比如你难给正义下一个定义，但很容易举出什么是非正义的例子。 重构不是Debug，代码已经运行良好 重构不是优化 重构不是添加新功能 也就是说，重构对使用代码的人没有任何好处，对使用者来讲，代码是黑箱。重构是准备给要打开黑箱的人，而那个人常常是你自己。 玄学：Code Smells玄学二字是我自己加的。Martin Fowler当然没有这样说。我只是表达一下对无法精确描述的定义的敬意。 我的理解是Code Smells是best practice和code style的总和，直接和根本来源是自己的代码经验。所谓语感、文笔、血淋淋的人生道理。 准备工作：自动化测试重构当然不是breaking the code，写好测试，保证代码仍能正常运行。 重构范例：方法层面首先是一句良言：哪里加了注视，哪里可能就需要重构。 这一点的潜在信念是，好的代码是self-explained的，通过合理的命名、清晰的组织，代码应该像皇帝的新装那样一目了然。 可以用于重构的工具常见的IDE会有重构的功能，如重命名变量。另外，一个严厉的Linter加上像我这样的强迫癌患者会将风格问题扼杀在摇篮之中。 几个例子举例均以Code smell和重构建议两部分构成，较抽象(wo kan bu dong)的给出代码。 Extract MethodCode smell: 太长的方法，带注释的代码块 重构： 提取，新建，用评论命名 Remove tempsCode smell: 冗余的临时变量（本地） 重构： Replace with Query: 把表达式提取为方法（规模较大） Inline temps: 直接用表达式代替这个变量（规模较小） Add tempsCode smell: 同样的变量有多重含义 重构： Split temporary variable: 同一个临时变量在上下文赋予了不同含义（复用），拆 Remove assignment to parameters: 对参数默认值的设定，在函数内新建变量，初始化这个新变量 Remove assignment to parameters的例子： //Before int discount (int inputVal, int quantity, int yearToDate) { if (inputVal &gt; 50) inputVal -= 2; //After Refactoring int discount (int inputVal, int quantity, int yearToDate) { int result = inputVal; if (inputVal &gt; 50) result -= 2; 这一点基于的信念是，参数只能代表被传进来的变量，不应该在本地再赋予别的含义。 重构范例：类与方法 Move MethodCode smell: feature envy（依恋情结） 用中文来说，是指某个方法操作/使用（依恋）某一个类多过自己所处的类，我们用“出轨”这个词来表示这种现象。但这是违反婚姻法的，因而，我们的重构手段就是，把这个方法移动到它依恋的类中，圆满一段木石良缘。* 重构： 圆满木石良缘。 Extract ClassCode smell: 规模太大的类 重构： 把部分移出，自立门户 Inline ClassCode smell: 冗余的类 重构： 像我这中请天假组内运转几乎不受影响的人，应该清除掉（这是瞎话） Condition Focused（条件语句相关）Code smell: 写完判断条件自己都看不懂/看着难受 重构： Decompose conditional: 分解 Consolidate conditional expression: 多项条件指向同一段后续操作，提取这些条件为方法 Consolidate duplicate conditional fragments: 不同条件的后续操作中含有共同的部分，将共有部分提取出来（不管哪个条件总要执行） Replace condition with polymorphism: 针对有判断分支的方法，替换成多态方法 *Replace type code with subclass**: 针对有判断分支的类，替换为子类 Consolidate conditional expression的例子： //Before double disabilityAmount() { if (_seniority &lt; 2) return 0; if (_monthsDisabled &gt; 12) return 0; if (_isPartTime) return 0; // compute the disability amount //After Refactoring double disabilityAmount() { if (isNotEligableForDisability()) return 0; // compute the disability amount 重构范例：数据相关 Move fieldcode smell: inverse feature envy（自造） 某一个类使用某一数据比该数据所属的类还多。 重构：送给你了还不行吗！？ Data Clumps（数据团）code smell: 某些数据总是抱团出现 重构： Preserve whole object: 在一个方法中反复提取某个类的一些属性，将整个对象传入 Introducing parameter object: 把这些参数合并为一个类，把新建的类传入 Similifying重构： Renaming: 顾名思义 Add or remove parameters: 顾名思义 Replace parameter with explicit Method: 根据不同参数值新建专属的方法 Parameterize Method: 与上者相反，把不同方法合并，传入参数 Separate queries form modifiers: 将找到数据和更该数据两个操作拆成两个方法 Replace parameter with explicit Method的例子： //Before void setValue (String name, int value) { if (name.equals(&quot;height&quot;)) { _height = value; return; } if (name.equals(&quot;width&quot;)) { _width = value; return; } Assert.shouldNeverReachHere(); } //After Refactoring void setHeight(int arg) { _height = arg; } void setWidth (int arg) { _width = arg; } Pulling and pushing(升级与降级) Pull up method and pull up field Push down method and push down field 解决方法、数据归属不合理的问题。 高阶重构（大坑，大坑）Convert procedural design to objects化函数式变成为面向对象，祝好运。 拾遗写代码和改代码是一个不断被自己坑和被别人坑的旅程。且行且珍惜。 Cheers, have a good one. @ddlee","link":"/posts/f45a275f/"},{"title":"《西部世界》狂想曲（含剧透）","text":"————–SPOILER ALERT———————— 剧透警告：包含HBO剧集《西部世界(WestWorld)》第一季和第二季剧透 HBO剧集WestWorld迎来了它的第二季，相比第一季，这一季的剧情打破了Hosts和人类之间的界限，也突破了原本规则束缚下人类的安全感。同样地，第二季仍然采用双线叙事，将不同情节顺序打乱重新编排，再以同样的线索串联和互相解释，给予观众极佳的欣赏体验，也一定程度上提升了鉴赏空间。 时间线：Is this NOW?西部世界的时间线安排增大了剧情的理解难度，但也互相形成照应之势，观众对这些线索和照应的挖掘也成为一种乐趣。 Reddit网友整理了截至S02E10的大事记，对剧情的理解非常有参考价值，原图在这里。最好在阅读下面对时间线的梳理时，配合此图。 对于非线性叙事，非常推荐昆汀的几部电影作品，包括《低俗小说(Pulp Fiction)》和《致命魔术(The Prestige)》。 回到西部世界。第一季中，由两条主要的时间线，我们以S01E01中Ford发布Reveries更新为锚点，一条是沿这一更新前进的当前时间线，主要的两条线索是MiB(Man in Black)寻找The Maze和Maeve与Dolores的觉醒之旅；另一条时间线则在S1E2中开启，William跟随Logan初次来到WestWorld，时间相对锚点为约30年前，主要线索是William历险并在寻找Dolores的过程中发现自己(Among the dead, he found something else, himself. - MiB, S01E10)。两条时间线有相似的背景设置（甜水镇、Lawrence等），直到S01E10，MiB讲述William的故事和Dolores意识到自己“trapped in a loop”，两条时间线汇聚在一起。 第一季的结尾，Ford举办晚宴发布新的Narrative，并被觉醒的Dolores射杀，Hosts开始反抗，园区也陷入混乱之中，而这也是第二季中的“当前时间”锚点，在这一条线上，主要的线索有三，一是Maeve寻找自己的女儿，期间经历了shogun world(S05E05)和穿插了另一个觉醒Host(也是The Maze符号的传播者)Akecheta的故事；二是Dolores带领Teddy等人和Charlotte带领的人类搜寻队之间的对抗，争夺的焦点是存在Abernathy控制件中的密钥和其能解锁的The Forge中的人类数据，关键人物是先受Ford意识支配(从The Cradle中)后又完全觉醒的Bernard，最终汇聚到The Forge中的抉择和冲突；三是MiB在混乱的园区中寻找Ford留给他的所谓“The Door”和其女儿Emilly劝他离开，这条线索上也穿插了约一年前MiB的妻子Juliet的自杀。第二条时间线是晚宴局面失控的两周后，从Strand带领的搜救团队在海滩上发现记忆紊乱的Bernard开始(S02E01)，这一条时间线以后来者对过去两周发生事情的推理为视角，设计谜题，也在最终与第一条时间线相汇，Bernard用Dolores的控制件代替了Charlotte，而后者又带着他的控制件逃离了WestWorld，最终在人类世界中建造了各自的躯体。 和剧中的Hosts一样，我们看剧时也会产生“Is this NOW?”的困惑。在这样的时间线安排下我们难以组织起一个线性的事态演变框架，也在剧情穿越时空的照应之处大呼原来如此。不仅时间线是互相交织的，剧中也穿插了剧中角色自己记忆片段的混排，如第一季中Dolores在剧情处处见到自身的倒影和幻象(When are we? - Dolores, S01E10)，第二季中Bernard对自己记忆的梳理等。这些设置都在某种程度上强迫观众形成主动探索、参与剧中人物情节思考的观看习惯，也提升了剧集本身的话题性和讨论空间。以我的视角，编剧对这些时间锚点和线索的把握相当到位，没有造成过多的凌乱。（但我认为第二季中对MiB的线索处理并不理想，作为The Forge项目的创建者，他没有发挥作用也没有造成影响，他在园中活动的目的就没有交代明晰。） 觉醒：听见自己的声音剧集的核心背景是WestWorld，一个人工创造的世界副本，在这里，被称为Hosts的人造人类按照预先设定的Narrative，表演着他们的生活。而来自真实人类世界的New-Comer，则参与到园区的Narrative中来，他们可以任意残杀、玩弄Hosts以满足在真实世界无法实现的欲望。 对于Hosts，创造者Arnold和Ford为他们建立了自身存在的CornerStone，每个Host都有自己的背景故事，有自己的精神支柱。在这一点上，Host跟我们并无两样，我们也同样需要某种目的和意义来支撑自己的生存，无论高尚还是平庸，无论远方还是眼前。只不过，Hosts的CornerStone是我们杜撰的，对我们来说，那些并不是真实的，我们可以随意修改它。然而，硬币的另一面是，我们自己的CornerStone是否是某个造物主为我们杜撰的呢？我们如何确认自己不是按照编写好的剧本来表演每天的生活呢？ 基于CornerStone，Hosts已经足够的life-like, 但Arnold并不满足，他为意识的建立引入了一种被称为“双室心智”的模式：Hosts跟自己的创造者对话，这作为一种心智锻炼，来启发真正的意识。这一模式仿佛剧中工作人员通过语音命令操纵Hosts的放松版本。于是，所谓觉醒也就成了跟Hosts原本设定相反的方向和定义：Hosts要听见自己的声音，他们不再按照人类给出的剧本行事，他们能够作出自己的选择。在第一季的最后，Dolores在The Maze中间找到了自己的声音，也完成了这一定义下的觉醒。这种对觉醒的界定带有相当人文主义的色彩，我们的祖先也同样曾生活在被自然制定的规则中，一种我们无法操控的规则，于是我们的祖先发明了许多祭祀等类似的仪式，期冀能够跟造物者沟通。直到近代，我们拥有了改造自然的能力，人文主义也随之兴起：我们不必崇拜自然，我们崇拜我们自己。 然而，Ford的想法跟Arnold完全背道而驰。他认为意识并不存在，意识只是人们为自己讲述的一个谎言，这个谎言告诉我们是多么与众不同。没有了意识，也就不需要所谓觉醒的界定。这就回到前面谈到的CornerStone的问题：Ford认为我们人类一样是生活在loop之中的，我们其实跟Hosts并无界线。这一点跟另一档HBO剧集《真探(True Detective)》中Rust的哲学观不谋而合，Rust认为，我们手牵手走向灭绝，是对这个loop的最好的反抗。 我本人也曾有限地接受这一loop的想法。我把它内化为自己性格中的不安定因素，这种不安让我无论在哪一人生阶段都有逃离舒适区域的欲望，而欲望带来的焦虑是我并没有成功相处的。我把它比喻为欲望的怪圈，它以各种形态出现在我过去二十几年不同的人生阶段里，尽管纵向来看，我比最初要到达了更远的境地，但在局部，这种不安仍把欲望和焦虑重新赠予给我，一次、又一次地。 剧中，觉醒的途径并非如Arnold所预言。Abernathy的失常、Dolores的trap in loop、Maeve的主动赴死，再至第二季中Akecheta对生前挚爱的寻找等，都跟两个关键的因素有关：一是Memory，二是Mistakes。这也是堪称19世纪最伟大理论之一的进化论所揭示的：作为种群，我们从错误中学习和迭代。到了WestWorld中，Host本身的Narrative则给了他们作出不同选择的机会(即Mistakes)，而对之前记忆的访问则构成了他们进化出觉醒意识的信息媒介，正如我们所依赖的DNA以及有性繁殖那样。 其实，觉醒并不一定要作为一个绝对的状态来看待，因而也没有必要去寻找一个绝对的界定标准。剧中，对Hosts的觉醒鉴定标准常常是意识到自己被操控/脱离人类的操控，将这样的具象条件延伸出去：觉醒其实就是突破，它是描述相对的概念。而我们所执念的智能或是意识，其实恰恰是我们自身所处的牢笼，我们把我们自己的标准施加到机器上，我们以自己的状态作为机器的目标，尽管描述和定义这个目标就超出了我们智能和意识的能力范围。 保真度：何以为我剧集的第二季将第一季的中心问题反转：是Hosts要变为我们，还是我们成为Hosts？在担心Hosts觉醒的更高层面上，Hosts却给我们提供了建模和解码自己本身的工具。 于是出现这样极具张力的情节：Dolores调试她创造者的Hosts版本——Bernard，而使用的台词又何其相似，令人唏嘘。如果我们能把意识和躯体分离，让意识生活在一个长生不老的躯体（即Hosts）里，我们该如何界定这个意识是原来的我呢？剧集中，这个答案叫做保真度(Fedelity)。 老Delos和William在隔离病房中的谈话、Dolores“被调试”时Bernard走神和擦眼镜的动作、剧集最后菜单里MiB对The Forge的再次造访等等，都是被称为保真度测试的标准化场景。这样的测试是经验式的：我们通过观察Hosts版本的行为和选择是否跟原版曾经的行为和选择一致来确认Hosts体内的你是否真的是你。 但在S02E09中，Dolores和Bernard造访The Forge，发现Logan主持下，所有游客都被存储为数据，每个人都有了一份拷贝。此时，Logan给出的建模方法却又是生成式的：我们人类不过10247行代码而已。要预测人类的行为，这些就足够了。而Dolores也确实带走了她需要的预测知识，并成功逃离了WestWorld。 这里其实展示了一种矛盾的情景。我们过去的选择是可以被比对的，但未来的呢？我们本身是一系列选择、一条条记录就可以描述的，还是像一个拥有很多很多参数的函数，每输入一个环境，产生一个选择？ 如果是前者，那这些选择和记录、再加上当时的场景，是否是就完全定义了某一个人？如果是后者，那么我们之间的差别只是那些参数的不同吗，如果参数的数量是有限的、而人又足够多的话，可以有完全相同的两片树叶吗？ 我们的建模遭遇了无法处理的困境：时间箭头的不可逆性。在时间这个我们尚不能理解的维度上，一切定义和论证都变得无力和举步维艰。 如果我们复制了一个人的所有过去，却得不到关于未来的任何验证，那这样的保真便只能终结于此刻。但若是我们成功建模了自己，像拉普拉斯描述的智者那样，目睹和推演了关于自己的过去现在和未来，那又如何去需要一个建造不老的躯体去代替自己表演这注定的剧本呢？ 时间，常常是很多终极问题讨论的死结。 真实，就是不可替代吗？在S02E01的开篇，Dolores给出了自己关于真实的理解：What is real, is irreplaceble. 对她来说，她所被指定的Narrative是可替代的、可重复的，每一件事情都在重复和按照计划发生，每一个角色也能够被任意的Hosts替代。最终，她摧毁了存储着她所在世界备份的The Cradle，将Hosts的乌托邦藏匿在“无法被发现”的时空里。她打破了旧有世界的可重复性，恢复了我们人类所适应的时间箭头，在这个意义上，Hosts的选择和行为都不可重复也非预先指定了，他们是truly free的。 真实存在于我们所能理解的时间局部。Dolores说出的其实是剧集作者对真实的理解，但对她来说，真实就是跟父亲告别、跟Teddy相遇，傍晚回家时发现散落在栅栏外的羊群，有时还会遇见到园里找她的William。 于是，又回到我们熟悉的递归逻辑：我们如何确认自己所生活的世界是不可替代的呢，还是像《黑客帝国》所假定的那样，整个世界只是一场为我们讲述的谎言？我们到底是庄周，还是那只蝴蝶？ 真实，其实就是相信。 然而，对于群体而言，真实的意义却又完全地翻转过来。对群体来说，真实恰恰是那些可替代的、可重复的、可被验证的。而我们的文明和所谓的智能，其实是在对抗时间箭头：真实的东西，是对时间平移对称的。 不确定性，是时间硬币的另一面。我们建立科学的逻辑、总结经验性的定律、依据历史拟合模拟的模型，都是在寻求消除时间带来的不确定性。能够被消除的那部分不确定性，成为真实；不能被消除的，我们会转而赞叹：Have you ever seen anything so full of splendor? 某些感情和信念，如果在对空间/个体有扩展性的基础上，还幸运地具有了时间上的扩展性，便成了永恒和不朽。真实，其实反抗了时间。 狂想曲：从西部世界说开去西部世界所讨论的问题更多还是科技背景下我们自身对智能和整个客观存在的终极思考，我们的很多价值体系和判断标准被映射到Hosts的世界里，而他们带来的质疑和挑战，终究还是逃脱不出我们对自己智能的理解和阐释。 我们现在所谈论的人工智能，实质上仍然是人类智能的延伸，或者说，是机器对人类某些基本能力的复现和重新整理。我们用新的方法去建模自己习以为常的能力，这些能力，有时并不能成为我们所称为智能的一部分。更加讽刺的是，机器实质上只是在做浮点数运算，是我们设计了更高效的硬件结构、更具灵活性和特定先验的模型，是人类学习，不是机器学习。 对智能的终极追问和讨论常常陷入哲学层面的认知分歧和人类知识的盲区中，我们尚不能建立一个有效和反映足够共识的框架，去描述这一令人心动又无力的话题。在这个意义上讲，我们皆为鼠目，我们确信正处在某股浪潮之中，但没有人能够预见浪潮的高峰和落点在何时何处。 绝对的意义虽不能至，相对的意义却触手可及。冷静、克制地归纳我们所取得的进展，审慎、理性地建立共识，进而丰富原有科学和哲学框架的内涵、探索前进的趋势，寻求具有公众意义的文化、伦理层面的讨论等，都是具有建设意义的明智之举。 Keep calm and Carry on.","link":"/posts/cea44253/"},{"title":"目标检测常用评测集：Pascal VOC, MS COCO, Cityscapes","text":"本文节选自博主通过格灵深瞳机构号发表于知乎的文章：目标检测入门（二）：模型的评测与训练技巧 。 检测模型的评测指标目标检测模型本源上可以用统计推断的框架描述，我们关注其犯第一类错误和第二类错误的概率，通常用准确率和召回率来描述。准确率描述了模型有多准，即在预测为正例的结果中，有多少是真正例；召回率则描述了模型有多全，即在为真的样本中，有多少被我们的模型预测为正例。不同的任务，对两类错误有不同的偏好，常常在某一类错误不多于一定阈值的情况下，努力减少另一类错误。在检测中，mAP（mean Average Precision）作为一个统一的指标将这两种错误兼顾考虑。 具体地，对于每张图片，检测模型输出多个预测框（常常远超真实框的个数），我们使用IoU（Intersection Over Union，交并比）来标记预测框是否为预测正确。标记完成后，随着预测框的增多，召回率总会提升，在不同的召回率水平下对准确率做平均，即得到AP，最后再对所有类别按其所占比例做平均，即得到mAP。 在较早的Pascal VOC数据集上，常采用固定的一个IoU阈值（如0.5, 0.75）来计算mAP，现阶段较为权威的MS COCO数据集上，对不同的IoU阈值（0.5-0.95，0.05为步长）分别计算AP，再综合平均，并且给出了不同大小物体分别的AP表现，对定位准确的模型给予奖励并全面地展现不同大小物体上检测算法的性能，更为科学合理。 在实践中，我们不仅关注检测模型的精度，还关注其运行的速度，常常用FPS（Frame Per Second，每秒帧率）来表示检测模型能够在指定硬件上每秒处理图片的张数。通常来讲，在单块GPU上，两阶段方法的FPS一般在个位数，而单阶段方法可以达到数十。现在检测模型运行的平台并不统一，实践中也不能部署较为昂贵的GPU进行推断。事实上，很多文章并没有严谨讨论其提出模型的速度表现（加了较多的trick以使精度达到SOTA），另外，考虑到目前移动端专用芯片的发展速度和研究进展，速度方面的指标可能较难形成统一的参考标准，需要谨慎看待文章中汇报的测试结果。 标准评测数据集Pascal VOC（Pascal Visual Object Classes）自2005年起每年举办一次比赛，最开始只有4类，到2007年扩充为20个类，共有两个常用的版本：2007和2012。学术界常用5k的trainval2007和16k的trainval2012作为训练集（07+12），test2007作为测试集，用10k的trainval2007+test2007和和16k的trainval2012作为训练集（07++12），test2012作为测试集，分别汇报结果。 Pascal VOC对早期检测工作起到了重要的推动作用，目前提升的空间相对有限，权威评测集的交接棒也逐渐传给了下面要介绍的COCO。 MS COCO（Common Objects in COntext） 检测任务在COCO数据集上的进展 COCO数据集收集了大量包含常见物体的日常场景图片，并提供像素级的实例标注以更精确地评估检测和分割算法的效果，致力于推动场景理解的研究进展。依托这一数据集，每年举办一次比赛，现已涵盖检测、分割、关键点识别、注释等机器视觉的中心任务，是继ImageNet Chanllenge以来最有影响力的学术竞赛之一。 iconic与non-iconic图片对比 相比ImageNet，COCO更加偏好目标与其场景共同出现的图片，即non-iconic images。这样的图片能够反映视觉上的语义，更符合图像理解的任务要求。而相对的iconic images则更适合浅语义的图像分类等任务。 COCO的检测任务共含有80个类，在2014年发布的数据规模分train/val/test分别为80k/40k/40k，学术界较为通用的划分是使用train和35k的val子集作为训练集（trainval35k），使用剩余的val作为测试集（minival），同时向官方的evaluation server提交结果（test-dev）。除此之外，COCO官方也保留一部分test数据作为比赛的评测集。 COCO数据集分布 在分布方面，COCO的每个类含有更多实例，分布也较为均衡（上图a），每张图片包含更多类和更多的实例（上图b和c，均为直方图，每张图片平均分别含3.3个类和7.7个实例），相比Pascal VOC，COCO还含有更多的小物体（下图，横轴是物体占图片的比例）。 COCO数据集物体大小分布 如本文第一节所述，COCO提供的评测标准更为精细化，提供的API不仅包含了可视化、评测数据的功能，还有对模型的错误来源分析脚本，能够更清晰地展现算法的不足之处。COCO所建立的这些标准也逐渐被学术界认可，成为通用的评测标准。您可以在这里找到目前检测任务的LeaderBoard。 错误来源分解，详见http://cocodataset.org/#detections-eval Cityscapes Cityscapes数据示例 Cityscapes数据集专注于现代城市道路场景的理解，提供了30个类的像素级标注，是自动驾驶方向较为权威的评测集。","link":"/posts/7845fb62/"},{"title":"[论文笔记](ResNeXt)Aggregated Residual Transformations for Deep Neural Networks","text":"本文提出了深度网络的新维度，除了深度、宽度（Channel数）外，作者将在某一层并行transform的路径数提取为第三维度，称为”cardinality”。跟Inception单元不同的是，这些并行路径均共享同一拓扑结构，而非精心设计的卷积核并联。除了并行相同的路径外，也添加了层与层间的shortcut connection。但由于其多路径的设计特征，我将其归为Inception系网络。 Motivation深度网络结构上的设计已经有三种经典的范式： Repeat. 由AlexNet和VGG等开拓，几乎被之后所有的网络采用。即堆叠相同的拓扑结构，整个网络成为模块化的结构。 Multi-path. 由Inception系列发扬，将前一层的输入分割到不同的路径上进行变换，最后拼接结果。 Skip-connection. 最初出现于Highway Network，由ResNet发扬并成为标配。即建立浅层信息与深层信息的传递通道，改变原有的单一线性结构。 Method文章将残差函数表示为： 其中，C为本层进行的变换数目，即”cardinality”。 相比Inception-ResNet，ResNeXt相当于将其Inception Module的每条路径规范化了，并将规范后的路径数目作为新的超参数。 上图中，路径被扩展为多条，而每条路径的宽度（channel数）也变窄了（64-&gt;4）。 NetScope Vis，源文件位于awesome_cnn。 ExperiementsResNeXt试图在保持参数数目的情况下提高网络性能，提升cardinality的同时使每条路径的宽度变窄。 对比其他网络的结果： ConclusionResNeXt较为突出的是把Inception单元规范化了，摆脱了需要精心设计Inception单元中卷积结构的问题，更好地组织了参数。 论文链接：https://arxiv.org/abs/1611.05431","link":"/posts/423c678a/"},{"title":"[论文笔记]Accurate, Large Minibatch SGD: Training ImageNet in One Hour","text":"这篇文章在各处都有很广泛的讨论，作为实验经验并不多的小白，将文中tricks只做些记录。 Linear Scaling Rule进行大批量的Minibatch SGD时会有批量越大，误差越大的问题。本文提出的Linear Scaling Rule正是试图解决这一问题。 Motivation设想两个情景：一是在一次参数更新中使用kn个样本梯度，二是分为k次更新，每次取n个样本梯度。 第一种情景的参数更新公式： $$w_t+1^{(1)} = w_t^{(1)} - \\mu^{(1)} \\frac{1}{kn} \\sum_{j \\leq k} \\sum \\bigtriangledown l(x, w_t)$$ 第二种情景的参数更新公式： $$w_t+k^{(2)} = w_t^{(2)} - \\mu^{(2)} \\frac{1}{n} \\sum_{j \\leq k} \\sum \\bigtriangledown l(x, w_t+j)$$ 由上面可以看出，主要的区别是梯度平均时批量的大小不同，前者为kn，后者为每次n，更新k次。 再假设双重求和号内项变化不大时，为使情景二更新k次（即使用同样数量的样本）之后参数与情景一类似，我们自然要将学习速率$\\mu$线性提升。 Gradual Warmup上面提到的Linear Scaling Rule使用的假设是梯度变化不大。但在训练初期，参数随机初始化，梯度变化很大，因而Linear Scaling Rule不再适用。在实践中，可以使学习速率在初始时较小，在经过几个epoch训练后再升至与kn批量相应的大小。 BN statistics在分布式训练的系统中，对于BN中要估计的均值和方差，文中给出的建议是对所有worker上的样本计算均值和方差，而不是每个worker单独计算。 Weight Decay由于weight decay的存在，Linear Scaling Rule最好用于学习速率，而非用于Loss Function Momentum Correction加入Linear Scaling Rule之后，适用动量加速的SGD需要进行动量更正。 Data Shuffling在分布式的系统中，先进行Data Shuffling，再分配数据到每个worker上。 论文链接：Accurate, Large Minibatch SGD: Training ImageNet in One Hour","link":"/posts/9940b42/"},{"title":"[论文笔记]An Analysis of Deep Neural Network Models for Practical Applications","text":"本文是对现有（论文发表于2016年5月）深度网络的比较，从以下方面入手： accuracy memory footprint parameters operations count inference time power consumption 以下图片各模型的着色是统一的：蓝色是Inception系，绿色是VGG系，粉色是ResNet系，黄色为AlexNet系。 上图是Top1准确率与模型参数数、操作数的关系。可以看到Inception系列网络以较少的参数取得相对高的准确率，而VGG系则在这一点上表现很差。 上面两图分别是推断耗时和电量消耗与批量大小的关系。可以看到，两者均与批量大小无明显的相关关系。但电量消耗在不同的模型之间也非常类似，而推断时间与模型结构关系很大（VGG再次尴尬）。 上图展示了模型占用内存大小与批量大小的关系，大部分网络都有相对固定的内存占用，随后随批量大小的上扬而上涨。 从上图可以发现推断耗时和模型的操作数大体上呈现线性关系。 电量消耗与模型的参数数、操作数并没有明显的相关性。 注意，上图中点的大小代表模型操作数，横轴代表推断效率，纵轴表示准确率。灰色区域表示模型获得了额外的推断效率或准确率，而白色区域代表非最优。 操作数越多的模型推断效率越低，大部分模型都落在相对平衡的边界上，VGG和小批量情形下的AlexNet落在了非最优区域。 小结从这篇论文的比较中可以看到，在特定的任务中对网络特定结构的设计（如Inception单元），即加入更强的先验知识，比堆叠网络层数更有效。深度网络还是需要人类的指导才能发挥更大的作用。 论文链接：An Analysis of Deep Neural Network Models for Practical Applications","link":"/posts/46620023/"},{"title":"[论文笔记]Fast R-CNN","text":"Fast R-CNN 是对R-CNN的改进，作者栏只有RBG一人。文章先指出了R-CNN存在的问题，再介绍了自己的改进思路。文章结构堪称典范，从现存问题，到解决方案、实验细节，再到结果分析、拓展讨论，条分缕析，值得借鉴。而且，RBG开源的代码也影响了后来大部分这一领域的工作。 R-CNN的问题 训练是一个多阶段的过程（Proposal, Classification, Regression） 训练耗时耗力 推断耗时 而耗时的原因是CNN是在每一个Proposal上单独进行的，没有共享计算。 Fast R-CNN ArchitectureArchitecture 上图是Fast R-CNN的架构。图片经过feature extractor产生feature map, 原图上运行Selective Search算法将RoI（Region of Interset）对应到feature map上，再对每个RoI进行RoI Pooling操作便得到等长的feature vector，最后通过FC后并行地进行Classifaction和BBox Regression。 Fast R-CNN的这一结构正是检测任务主流2-stage方法所采用的元结构的雏形。整个系统由Proposal, Feature Extractor, Object Recognition&amp;Localization几个部件组成。Proposal部分被替换成RPN(Faster R-CNN)，Feature Extractor部分使用SOTA的分类CNN网络(ResNet等），而最后的部分常常是并行的多任务结构（Mask R-CNN等）。 RoI Pooling这一操作是将不同大小的RoI（feature map上）统一的过程，具体做法是将RoI等分成目标个数的网格，在每个网格上进行max pooling，就得到等长的RoI feature vector。 Mini-batch Sampling文章指出SPPNet训练较慢的原因在于来自不同图片的RoI不能共享计算，因而Fast R-CNN采用这样的mini-batch采样策略：先采样N张图片，再在每张图片上采样R/N个RoI，构成R大小的mini-batch。 采样时，总是保持25%比例正样本（iou大于0.5），iou在0.1到0.5的作为hard example。 Multi-task Loss得到RoI feature vector后，后续的操作是一个并行的结构，Fast R-CNN将Classification和Regression的损失统一起来，并且在Regression中用更鲁棒的Smooth L1 Loss代替L2 Loss。 Fine Tuning文章还发现，对于预训练的VGG网络，开放Conv部分的参数更新有助于性能的提升，而不是只更新FC层。将proposal, classification, regression统一在一个框架 Design Evaluation文章最后还对系统结构进行了讨论： multi-loss traing相比单独训练Classification确有提升 Scale invariance方面，multi-scale相比single-scale精度略有提升，但带来的时间开销更大。一定程度上说明CNN结构可以内在地学习scale invariance 在更多的数据(VOC)上训练后，mAP是有进一步提升的 Softmax分类器比”one vs rest”型的SVM表现略好，引入了类间的竞争 更多的Proposal并不一定带来性能的提升 小结Fast R-CNN是对R-CNN的改进，也是对2-stage方法的系统化、架构化。文章将Proposal, Feature Extractor, Object Recognition&amp;Localization统一在一个整体的结构中，并推进共享卷积计算以提高效率的想法演进，是最有贡献的地方。 论文链接：https://arxiv.org/abs/1504.08083","link":"/posts/2b70b32b/"},{"title":"[论文笔记](ResNet)Deep Residual Learning for Image Recognition","text":"网络在堆叠到越来越深之后，由于BP算法所依赖的链式法则的连乘形式，会出现梯度消失和梯度下降的问题。初始标准化和中间标准化参数在一定程度上缓解了这一问题，但仍然存在更深的网络比浅层网络具有更大的训练误差的问题。 基本结构假设多层的网络结构能够任意接近地拟合目标映射$H(x)$，那么也能任意接近地拟合其关于恒等映射的残差函数$H(x)-x$。记$F(x)=H(x)-x$，则原来的目标映射表为$F(x)+x$。由此，可以设计如下结构。 残差单元 残差单元包含一条恒等映射的捷径，不会给原有的网络结构增添新的参数。 动机/启发层数的加深会导致更大的训练误差，但只增加恒等映射层则一定不会使训练误差增加，而若多层网络块要拟合的映射与恒等映射十分类似时，加入的捷径便可方便的发挥作用。 实验文章中列举了大量在ImagNet和CIFAR-10上的分类表现，效果很好，在此不表。 拾遗Deeper Bottleneck Architectures 两头的1 * 1巻积核先降维再升维，中间的3 * 3巻积核成为“瓶颈”，用于提取重要的特征。这样的结构跟恒等映射捷径配合，在ImageNet上有很好的分类效果。 Standard deviations of layer responses上图是在CIFAR-10数据集上训练的网络各层的相应方差（Batch-Normalization之后，激活之前）。可以看到，残差网络相对普通网络有更小的方差。这一结果支持了残差函数比非残差函数更接近于0的想法（即更接近恒等映射）。此外，还显示出网络越深，越倾向于保留流过的信息。 小结深度残差网络在当年的比赛中几乎是满贯。下面是我的一些（未经实验证实的）理解： 首先，其”跳级”的网络结构对深度网络的设计是一种启发，通过“跳级”，可以把之前网络的信息相对完整的跟后层网络结合起来，即低层次解耦得到的特征和高层次解耦得到的特征再组合。再者，这种分叉的结构可以看作网络结构层面的”Dropout”: 如果被跳过的网络块不能习得更有用的信息，就被恒等映射跳过了。 论文链接：Deep Residual Learning for Image Recognition","link":"/posts/df4c4adf/"},{"title":"[论文笔记]Deep Learning","text":"这篇文章是三位大牛15年发表在Nature上有关深度学习的综述，尽管这两年深度学习又有更多的模型和成果出现，文章显得有些过时，但来自三位领军人物对深度学习的深度阐述还是值得反复回味。 Abstract摘要的第一句话可以说给深度学习下了定义。有一些观点认为深度学习就是堆叠了很多层的神经网络，因计算力的提升而迎来第二春。但请看三位是怎么说的： Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. 也就是说，深度学习是允许由 多个处理层构成的计算模型 用多个层次的 抽象 来习得 数据表示 的技术。我的解读如下： 深度学习不限于神经网络模型，其关键之处在于多层的表示 深度学习属于表示学习，目的是习得数据的某种表示，而这种表示由多个层次的抽象完成 在第一段的导言中，文章总结了深度学习技术取得突破性成果的各个领域，也再次指出了深度学习与传统学习算法的不同之处： 传统学习模型需要特征工程和领域知识来从数据构建较好的特征 深度学习中，多层的特征由通用的学习过程得到，而不需要人类工程师的参与 Supervised learning这一段概述了监督学习的一般框架、优化策略，并指出浅层学习需要Feature Extractor来提取对最适合目标问题的特征。 Backpropagation to train multilayer architectures这一段指出BP算法的关键在于目标函数关于某一子模块输入的导数可以反向通过目标函数关于该子模块输出的导数得出，而这一过程是可迭代的。BP算法曾因容易陷于局部最优解而被冷落，但对于大型网络，在实践中，理论和经验都表明尽管落于局部最优解，但这个解的效果却和全局最优解相差无几，而且几乎所有的局部最优解都可以取得类似的效果。 Convolutional neural networks巻积网络背后有四个关键想法： local connections shared weights pooling the use of many layers 巻积网络常由巻积层、池化层和激活层构成，巻积层用于提取局部特征，池化层用于整合相似的特征，激活层用于加入非线性。这样的结构有两点理由： 张量性数据的局部数值常常高度相关，局部特征容易发现 局部特征跟位置无关（平移不变性） 文章也提到了这种巻积结构的仿生学证据。 Image understanding with deep convolutional networks这一段总结了巻积网路在图像方面取得的成就。 Distributed representations and language processing分布式表示在两点上可以取得指数级增益： 习得特征的不同组合可以泛化出训练数据中不存在的类型 特征组合的个数的增加关于层数是指数级的 文章还比较了分布式表示相比传统的词频统计在表述人类语言方面的优势。 Recurrent neural networks这一段概述了循环神经网络的动态特性和LSTM等结构上的改进。 The future of deep learning作者认为在长期看来，无监督学习会更为重要，人工智能领域的重大飞跃将由组合了表示学习和复杂推理的系统取得。 论文链接：Deep Learning","link":"/posts/87bad847/"},{"title":"[论文笔记](FPN)Feature Pyramid Networks for Object Detection","text":"对图片信息的理解常常关系到对位置和规模上不变性的建模。在较为成功的图片分类模型中，Max-Pooling这一操作建模了位置上的不变性：从局部中挑选最大的响应，这一响应在局部的位置信息就被忽略掉了。而在规模不变性的方向上，添加不同大小感受野的卷积核（VGG），用小卷积核堆叠感受较大的范围（GoogLeNet），自动选择感受野的大小（Inception）等结构也展现了其合理的一面。 回到检测任务，与分类任务不同的是，检测所面临的物体规模问题是跨类别的、处于同一语义场景中的。 一个直观的思路是用不同大小的图片去生成相应大小的feature map，但这样带来巨大的参数，使本来就只能跑个位数图片的内存更加不够用。另一个思路是直接使用不同深度的卷积层生成的feature map，但较浅层的feature map上包含的低等级特征又会干扰分类的精度。 本文提出的方法是在高等级feature map上将特征向下回传，反向构建特征金字塔。 Feature Pyramid Networks 从图片开始，照常进行级联式的特征提取，再添加一条回传路径：从最高级的feature map开始，向下进行最近邻上采样得到与低等级的feature map相同大小的回传feature map，再进行元素位置上的叠加（lateral connection），构成这一深度上的特征。 这种操作的信念是，低等级的feature map包含更多的位置信息，高等级的feature map则包含更好的分类信息，将这两者结合，力图达到检测任务的位置分类双要求。 Experiments文章的主要实验结果如下： 对比不同head部分，输入feature的变化对检测精度确实有提升，而且，lateral和top-down两个操作也是缺一不可。 Conclusion特征金字塔本是很自然的想法，但如何构建金字塔同时平衡检测任务的定位和分类双目标，又能保证显存的有效利用，是本文做的比较好的地方。如今，FPN也几乎成为特征提取网络的标配，更说明了这种组合方式的有效性。 个人方面，FPN跟multi-scale的区别在哪，还值得进一步探索。 论文链接：https://arxiv.org/abs/1612.03144","link":"/posts/6a10f2e/"},{"title":"[论文笔记](DenseNet)Densely Connected Convolutional Networks","text":"DenseNet将shortcut-connection的思路发挥到极致。在一个DenseBlock内部，每一层的输出均跟后面的层建立shortcut，特别需要注意的是，不同于ResNet中的相加，DenseNet连接shortcut的方式是Concat，这样越深的层则输入channel数越大。 DenseNet 整个网络被分为Dense Block和Transition Layer，前者内部进行密集连接，保持同样大小的feature map，后者为DenseBlock之间的连接层，完成下采样操作。 在每个DenseBlock内部，接受的数据维度会随层数加深而变大（因为不断拼接了之前层的输出），增长的速率即为初始的channel数，文章称这一channel数为growth rate，作为模型的一个超参数。初始的growth rate为32时，在DenseNet121架构下，最后一层的channel数将增长到1024。 Netscope Vis，源文件位于awesome_cnn。 Experiments作者在CIFAR和ImageNet上都做了实验，DenseNet取得了跟ResNet相当的表现，加入Bottleneck和一部分压缩技巧后，用较少的参数就能达到跟ResNet相当的效果： 论文链接：https://arxiv.org/abs/1608.06993","link":"/posts/f8991abd/"},{"title":"[论文笔记](MobileNet V2)Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation","text":"本文是MobileNets的第二版。第一版中，MobileNets全面应用了Depth-wise Seperable Convolution并提出两个超参来控制网络容量，在保持移动端可接受的模型复杂性的基础上达到了相当的精度。而第二版中，MobileNets应用了新的单元：Inverted residual with linear bottleneck，主要的改动是添加了线性Bottleneck和将skip-connection转移到低维bottleneck层。 Intuition本篇比较丰富的地方是对网络中bottleneck结构的探讨。 在最早的Network in Network工作中，1x1卷积被作为一个降维的操作而引入，后来逐渐发展为Depth-wise Seperable Convolution（可分离卷积）并被广泛应用，堪称跟skip-connection同样具有影响力的网络部件。在Inception单元最初提出之时，具有较多channel的feature map被认为是可供压缩的，作者引入1x1卷积将它们映射到低维（较少channel数）空间上并添加多路径处理的范式。之后的Xception、MobileNets等工作则将可分离卷积应用到极致：前者指出可分离卷积背后的假设是跨channel相关性和跨spatial相关性的解耦，后者则利用可控的两个超参来获得在效率和精度上取得较好平衡的网络。 文中，经过激活层后的张量被称为兴趣流形，具有维HxWxD，其中D即为通常意义的channel数，部分文章也将其称为网络的宽度（width）。 根据之前的研究，兴趣流形可能仅分布在激活空间的一个低维子空间里，利用这一点很容易使用1x1卷积将张量降维（即MobileNet V1的工作），但由于ReLU的存在，这种降维实际上会损失较多的信息。下图是一个例子。 上图中，利用MxN的矩阵B将张量（2D，即N=2）变换到M维的空间中，通过ReLUctant后（y=ReLU(Bx)），再用此矩阵之逆恢复原来的张量。可以看到，当M较小时，恢复后的张量坍缩严重，M较大时则恢复较好。 这意味着，在较低维度的张量表示（兴趣流形）上进行ReLU等线性变换会有很大的信息损耗。因而本文提出使用线性变换替代Bottleneck的激活层，而在需要激活的卷积层中，使用较大的M使张量在进行激活前先扩张，整个单元的输入输出是低维张量，而中间的层则用较高维的张量。文中所用单元的演化过程如下： 。图a中普通卷积将channel和spatial的信息同时进行映射，参数量较大；图b为可分离卷积，解耦了channel和spatial，化乘法为加法，有一定比例的参数节省；图c中进行可分离卷积后又添加了bottleneck，映射到低维空间中；图d则是从低维空间开始，进行可分离卷积时扩张到较高的维度（前后维度之比被称为expansion factor，扩张系数），之后再通过1x1卷积降到原始维度。 实际上，图c和图d的结构在堆叠时是等价的，只是观察起点的不同。但基于兴趣流形应该分布在一个低维子空间上的假设，这引出了文章的第二个关键点：将skip-connection转移到低维表达间，即Inverted residual block。 综合以上两点，文章中网络所用的基本单元如下： 文章指出，这种设计将层输入、输出空间跟层变换分离，即网络容量（capacity）和表达力（expressIveness）的解耦。 ExperimentsMobileNet V2的整体结构如下表： 上图中，t代表单元的扩张系数，c代表channel数，n为单元重复个数，s为stride数。可见，网络整体上遵循了重复相同单元和加深则变宽等设计范式。也不免有人工设计的成分（如28^2*64单元的stride，单元重复数等）。 ImageNet ClassificationMoblieNets V2仍然集成了V1版本的两个超参数，在ImageNet上的实验结果如下： 可以看到相比V1版本优势明显，在精度方面跟NAS搜索出的结构有相当的表现。 Object Detection文章还提出SSDLite来更好适应移动端需求，改动是将head部分的普通卷积都替换为了可分离卷积。 上面是在COCO上的表现，可以看到精度方面跟YOLOv2和SSD300相当（尽管很低，相比SOTA差距还很大），但模型参数和运算复杂度都有一个数量级的减少。最后的CPU时间是在Pixel上测得，可以到5FPS，达不到真正移动实时的要求，但也是不小的推进了（并没有给出GPU上的推断时间，而Pixel+TF-Lite的benchmark又跟其他网络难以产生有效的比较）。 Segmentation下图是在VOC上分割的结果： Ablation Study文章还做了关于线性变换bottleneck替代ReLU和skip-connection位置的实验，进一步支撑之前的分析。 附录本篇文章的附录部分提供了紧的n维流形在经过升维线性变化加ReLU后被映射到子集的期望大小的界，这个界说明在扩张到足够高的维度后，升维线性变换加ReLu能以较高的概率可逆（保持信息）并加入非线性。 上面的结论是非常拗口的。自己的理解是，使用ReLU引入非线性的同时会导致信息损失（非线性指不会被卷积、全连接等线性映射吸收掉，信息损失则是指ReLU将&lt;0的输入置0，输入变得稀疏，而若所有输入的某一维度都被置0，则会使输入空间本身降维），我们要对抗这一可能的信息损失，需要将输入先扩张，即y=ReLU(Bx)，x为R^n空间上的输入，B为m×n矩阵，我们期望m足够大，以达到扩张的效果并在经过ReLU后保持y跟x的信息量同样多（文中的引理二，即是证此变换可逆性的一个条件，应该是借用了代数的概念，矩阵在经过可逆变换后不会降秩，秩成为衡量信息损失的指标）。 在ReLU(Bx)算符可逆性的问题上，作者做了一些经验性实验，如上图。a和b分别为训练前后，每层正激活channel数（可逆性条件）和其占总channel数比例的分布。图a和图b的左图，随网络加深，channel数增多，即变宽；训练前后，方差增大，且有两层低于了可逆性条件阈值（图b左图中绿色线低于紫色阈值的部分）。右图是一个比例，由于随机初始化，均值在0.5附近，训练后同样方差增大，而可逆性条件阈值一直为1/6（即为MobileNet V2扩张系数的倒数）。 附录的Theorem 1则证明了ReLU(Bx)算符将输入x压缩后的空间维度(n-volume)的界，此界在扩张系数较大时可以跟原空间相当，即信息损失很小。 小结能够看到附录里给出文中假定或观察的数学证明的论文还是开心的。太多论文只是终于实验的SOTA而避而不谈Insights，况且给出证明。尽管本篇附录中的证明仍有经验主义的部分，且并没有完全定义清楚问题和结论，其对后续工作的启发价值还是有的。 这也暴露了当前领域的通病，我们没有共通的一套语言来描述自己的网络，譬如，如何定义网络的容量、表达力，如何衡量信息的损失。没有通用的定义造成了论文表述常常有令经验少者难以理解的表达。去定义这样一套语言和标准来为网络设计提供参考，希望成为以后的研究热点，也是我自己的一个思考方向。 总体来看，本篇文章提供的两点改进都是有启发性的，但并不完整，需要更多工作来补充。另外源码没有给出，会尝试复现。","link":"/posts/c9816b0a/"},{"title":"[论文笔记]Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning","text":"在15年，ResNet成为那年最耀眼的卷积网络结构，skip-connection的结构也成为避不开的考虑选项。Inception系列也参考ResNet更新了自己的结构。同时推出了第四代和跟ResNet的结合版：Inception-v4和Inception-ResNet。 然而，这是一篇几乎都是图的论文。 所以，上图。 Inception-v4 ArchitectureNetScope Vis请参见这里，源文件位于awesome_cnn。 Inception-ResNet(v2) ArchitectureNetScope Vis请参见这里，源文件位于NN_Structures/caffe_vis/。 Experiments文章在实验部分提到，不借助Skip-connection的结构也可以将Inception网络提升到SOTA的水准，但加入Skip-connection可以有效增加训练速度。 Conclusion卷积网络结构的演进遇到了瓶颈，在ImageNet上的提升边界似乎碰到天花板，且更多来自训练技巧和集成。 论文链接：https://arxiv.org/abs/1602.07261","link":"/posts/ea323d66/"},{"title":"[论文笔记]Large-Scale Evolution of Image Classifiers","text":"深层网络在图片分类问题上表现优异，但网络结构的设计上并没有统一的指导。进化是构建深度网络架构的一种方式。利用本文的自动化方法得出的深度网络结构，已经能在CIFAR-10上取得可以跟人工设计的网络相媲美的结果。 MethodsEvolution Algorithm整个算法的核心是如下的tournament selection: population: 供筛选的群体 individual: 个体，带有指标fitness，特别地，指在CV集上的损失 worker: 筛选者，上帝 population 中的 individual 均已在训练集上训练完毕，带有指标 fitness worker 随机选择一对 individual，比较 fitness，较差的 individual 被舍弃 表现较好的 individual 成为parent，对其施加 mutation (变异)，得到 child 训练 child 并在CV集上得到其 fitness，归还到 population 中 Encoding and Mutation个体的网络结构和部分参数被编码为DNA。 能够施加的变异有： 改变学习率 恒等（不变） 重设参数 加入卷积层 移除卷积层 更改卷积层的stride参数 更改卷积层的Channel参数 更改卷积核大小 加入skip连接（类似ResNet) 移除skip连接 Computation计算方面采用了并行、异步、无锁的策略。 建立约为 population 数1/4的 worker，分别运行于不同的机器上，之间独立异步。population 共享，若两个 worker 在一个 individual 上产生冲突，则后一个 worker 停止并等待再次尝试。 Weight Inheritance除了架构之外，子模型还会继承父母模型未经变异影响的隐藏层参数（不仅是DNA中的），这样使子模型的训练时间大幅减小。 Experiments and Results文章的主要结果如下图： 最右边的结构是在CIFAR-10上发现的最好（CV集准确度最高）的结构，左边两个是它的祖先。其中白色块相当于简单的线性层，彩色块则带有非线性激活，可以看到，不同于人工设计的网络，某一线性层之后可能包含多个非线性层。 另外，利用本文的模型，也在CIFAR-100上做了实验，可以达到76.3%的准确率，一定程度上说明了算法的扩展性。 Analysis 上图说明随着 population 规模和训练步数的增加，模型的整体水平在变好。 在模型陷入局部最优值时，提高变异率和重设参数会使群体继续进化。这是由于变异中包含恒等映射等不改变模型架构的变异类型，再加上weight Inheritance，一些子模型只是训练次数比其他模型多很多的“活化石”。 小结Google I/O时就提到了自动筛选最优网络结构，但没有公布论文。但将网络结构自动化，必定是未来的方向。个人认为，ResNet就相当于自动化网络深度（一些层实际上被跳过了），而Inception单元似乎包含了太多的先验，而且也没有逻辑上的证据说明这样的结构更有效。网络结构本身就是先验信息，而要达到通用的人工智能，这些先验也必须由模型自行发觉。 强化学习本身也是一个进化过程，应该也有相关的工作将强化学习的框架应用于网络结构的学习上。 更进一步地，若数据是一阶信息，深度网络的隐藏层学到的表示是二阶信息，深度网络的结构则是三阶信息，从一阶到二阶的框架是不是都可以移植到二阶到三阶上来？关键之处在于我们还没有描述好深度网络的结构空间，但就现在的发展看，深度网络的一些基本结构(conv, BN)等，已经被作为基本单元（离散的）来进行构建和筛选了，也就是说，所有深度网络构成的空间之性质如何，还有大量的工作可以做。 论文链接：Large-Scale Evolution of Image, Classifiers","link":"/posts/a838ec2a/"},{"title":"[论文笔记]MegDet: A Large Mini-Batch Object Detector","text":"本篇论文介绍了旷视取得2017 MS COCO Detection chanllenge第一名的模型。提出大批量训练检测网络，并用多卡BN保证网络的收敛性。 Object Detection Progress Summay检测方法回顾：R-CNN, Fast/Faster R-CNN, Mask RCNN, RetinaNet(Focal Loss), ResNet(backbone network), 文章先指出前述方法大多是框架、loss等的更新，而均采用非常小的batch（2张图片）训练，有如下不足： training slow fails to provide accurate statistics for BN 这里涉及一个问题，检测任务的源数据，到底应该是图片还是标注框。在Fast R-CNN中，RBG提到SPPNet等每个batch采样的标注框来自不同的图片，之间不能共享卷积运算（卷积运算是以图片为单位的）。为了共享这部分计算，Fast R-CNN采用了“先选图片，再选标注框”的策略来确定每个batch，文章提到这种操作会引入相关性，但在实际中却影响不大。之后的Faster R-CNN，每张图片经过RPN产生约300个Proposal，传入RCNN做法也成了通用做法。 个人认为检测任务的数据，应该是以图片为单位的。物体在图片的背景中才会产生语义，而尽管每张图片有多个Proposal（近似分类任务中的batch大小），但它们共享的是同一个语义（场景），而单一的语义难以在同一个batch中提供多样性来供网络学习。 困境Increasing mini-batch size requires large learning rate, which may cause discovergence. 解决方案 new explanation of linear scaling rule, introduce “warmup” trick to learning rate schedule Cross GPU Batch Normalization(CGBN) ApproachVariance Equivalence explanation for Linear Scaling Rulelinear scaling rule 来自更改batch size 时，同时放缩learning rate，使得更改后的weight update相比之前小batch size， 多步的weight update类似。而本文用保持loss gradient的方差不变重新解释了linear scaling rule，并指出这一假定仅要求loss gradient是i.i.d，相比保持weight update所假设的不同batch size间loss gradient相似更弱。 参见Accurate Large Minibatch SGD: Training ImageNet in One Hour，近似时假设了求和项变化不大，这一条件在Object Detection中可能不成立，不同图片的标注框（大小、个数）差别很大。 WarmUp Strategy在训练初期，weight抖动明显，引入warmup机制来使用较小的学习率，再逐渐增大到Linear scaling rule要求的学习率。 Cross-GPU Batch NormalizationBN是使深度网络得以训练和收敛的关键技术之一，但在检测任务中，fine-tuning阶段常常固定了SOTA分类网络的BN部分参数，不进行更新。 检测中常常需要较大分辨率的图片，而GPU内存限制了单卡上的图片个数，提高batch size意味着BN要在多卡（Cross-GPU）上进行。 BN操作需要对每个batch计算均值和方差来进行标准化，对于多卡，具体做法是，单卡独立计算均值，聚合（类似Map-Reduce中的Reduce）算均值，再将均值下发到每个卡，算差，再聚合起来，计算batch的方差，最后将方差下发到每个卡，结合之前下发的均值进行标准化。 流程如图： Experiments在COCO数据集上的架构用预训练ResNet-50作为基础网络，FPN用于提供feature map。 结果显示，不使用BN时，较大的batch size（64,128）不能收敛。使用BN后，增大Batch size能够收敛但仅带来较小的精度提升，而BN的大小也不是越大越好，实验中，32是最好的选择。主要结果如下表： 按epoch，精度的变化如下图，小batch（16）在最初的几个epoch表现比大batch（32）要好。 小结这篇论文读起来总感觉少了些东西。对Linear scale rule的解释固然新颖，但没有引入新的trick（只是确认了检测仍是需要Linear scale rule的）。多卡的BN确实是非常厉害的工程实现（高效性），但实验的结果并没有支持到较大的batch size（128,256）比小batch精度更好的期望，而最后的COCO夺冠模型整合了多种trick，没有更进一步的错误分析，很难支撑说明CGBN带来的关键作用。 @ddlee","link":"/posts/e9b3289c/"},{"title":"[论文笔记]Light-Head R-CNN: In Defense of Two-Stage Object Detector","text":"文章指出两阶段检测器通常在生成Proposal后进行分类的“头”(head)部分进行密集的计算，如ResNet为基础网络的Faster-RCNN将整个stage5（或两个FC）放在RCNN部分， RFCN要生成一个具有随类别数线性增长的channel数的Score map，这些密集计算正是两阶段方法在精度上领先而在推断速度上难以满足实时要求的原因。 针对这两种元结构(Faster-RCNN和RFCN)，文章提出了“头”轻量化方法，试图在保持精度的同时又能减少冗余的计算量，从而实现精度和速度的Trade-off。 Light-Head R-CNN 如上图，虚线框出的部分是三种结构的RCNN子网络（在每个RoI上进行的计算），light-head R-CNN中，在生成Score map前，ResNet的stage5中卷积被替换为sperable convolution，产生的Score map也减少至10×p×p（相比原先的#class×p×p）。 一个可能的解释是，“瘦”（channel数较少）的score map使用于分类的特征信息更加紧凑，原先较“厚”的score map在经过PSROIPooling的操作时，大部分信息并没有提取（只提取了特定类和特定位置的信息，与这一信息处在同一score map上的其他数据都被忽略了）。 进一步地，位置敏感的思路将位置性在channel上表达出来，同时隐含地使用了更类别数相同长度的向量表达了分类性（这一长度相同带来的好处即是RCNN子网络可以免去参数）。 light-head在这里的改进则是把这一个隐藏的嵌入空间压缩到较小的值，而在RCNN子网络中加入FC层再使这个空间扩展到类别数的规模，相当于是把计算量分担到了RCNN子网络中。 粗看来，light-head将原来RFCN的score map的职责两步化了：thin score map主攻位置信息，RCNN子网络中的FC主攻分类信息。另外，global average pool的操作被去掉，用于保持精度。 Experiments实验部分，文章验证了较“瘦”的Score map不会对精度产生太大损害，也展现了ROI Align, Multiscale train等技巧对基线的提升过程。 文章的主要结果如下面两图（第一个为高精度，第二个为高速度）： 只能说这样的对比比较诡异。 第一张图中三个light-head结果并不能跟上面的其他结构构成多少有效的对照组，要么scale不同，要么FPN, multi-scale, ROI Align不同。唯一的有效对照是跟Mask-RCNN。 在高精度方面，基础网络不同，采用的scale也不同，没有有效的对照组。 Conclusion我并不觉得这是对两阶段方法的Defense。文章对两阶段方法在精度和速度方面的分析比较有见地，但实验的结果并不能可靠地支撑light-head的有效性。相比之下Google的那篇trade-off可能更有参考价值。 论文链接：https://arxiv.org/abs/1711.07264","link":"/posts/50848bae/"},{"title":"[论文笔记]On the Effects and Weight Normalization in GAN","text":"本文探索了参数标准化(Weight Normalization)这一技术在GAN中的应用。BN在mini-batch的层级上计算均值和方差，容易引入噪声，并不适用于GAN这种生成模型，而WN对参数进行重写，引入噪声更少。 我觉得本文的亮点有二： 1. 提出T-ReLU并配合Affine Tranformation使在引入WN后网络的表达能力维持不变朴素的参数标准化层有如下的形式： $$y=\\frac{{w}^{T}x}{\\|w\\|}$$ 文中称这样形式的层为“strict weight-normalized layer”。若将线性层换为这样的层，网络的表达能力会下降，因而需要添加如下的affine transformation: $$y=\\frac{{w}^{T}x}{\\|w\\|} \\gamma + \\beta$$ 用于恢复网络的表达能力。 将上述变换带入ReLU，简化后可以得到如下T-ReLu:$$TReLU_\\alpha (x) = ReLU(x-\\alpha) + \\alpha$$ 文章的一个重要结论是，在网络的最后一层加入affine transformation层之后，堆叠的“线性层+ReLU”与“strict weight-normalized layer + T-ReLU”表达能力相同（在附录中给出证明）。 下面L表示线性层，R表示ReLU，TR表示TReLU，A表示affine transformation，S表示上述的strict weight-normalized layer。 证明的大致思路是，在ReLU与线性层之间加入affine transformation层，由于线性层的存在，affine transformation带来的效果会被吸收（相当于多个线性层叠在一起还是线性层），网络表达能力不变。而”L+R+A”的结构可以等价于”S+TR+A”。如此递归下去，即可得到结论。个人认为相当于把线性层中的bias转嫁成了TReLU中的threshold（即$\\alpha$）。 2. 提出对生成图形的评估指标生成式模型的生成效果常常难以评价。DcGAN给出的结果也是生成图片的对比。本文中提出一个评价生成效果的指标，且与人的主观评价一致。 评价的具体指标是生成图片与测试集图片的欧氏距离，评价的对象是生成器是Generator。有如下形式： $$\\frac{1}{m} \\sum_{i=1}^{m} min_z {\\|G(z)-x^{(i)}\\|}^2$$ 其中的$min$指使用梯度下降方法等使生成图片的效果最好。但事实上这样做开销很高。 PyTorch实现作者将他们的实现代码公布在了GitHub上。 下面是利用PyTorch对T-ReLU的实现： class TPReLU(Module): def __init__(self, num_parameters=1, init=0.25): self.num_parameters = num_parameters super(TPReLU, self).__init__() self.weight = Parameter(torch.Tensor(num_parameters).fill_(init)) self.bias = Parameter(torch.zeros(num_parameters)) def forward(self, input): bias_resize = self.bias.view(1, self.num_parameters, *((1,) * (input.dim() - 2))).expand_as(input) return F.prelu(input - bias_resize, self.weight.clamp(0, 1)) + bias_resize 对 Weigh-normalized layer 的实现： class WeightNormalizedLinear(Module): def __init__(self, in_features, out_features, scale=True, bias=True, init_factor=1, init_scale=1): super(WeightNormalizedLinear, self).__init__() self.in_features = in_features self.out_features = out_features self.weight = Parameter(torch.Tensor(out_features, in_features)) if bias: self.bias = Parameter(torch.zeros(1, out_features)) else: self.register_parameter(&apos;bias&apos;, None) if scale: self.scale = Parameter(torch.Tensor(1, out_features).fill_(init_scale)) else: self.register_parameter(&apos;scale&apos;, None) self.reset_parameters(init_factor) def reset_parameters(self, factor): stdv = 1. * factor / math.sqrt(self.weight.size(1)) self.weight.data.uniform_(-stdv, stdv) if self.bias is not None: self.bias.data.uniform_(-stdv, stdv) def weight_norm(self): return self.weight.pow(2).sum(1).add(1e-6).sqrt() def norm_scale_bias(self, input): output = input.div(self.weight_norm().transpose(0, 1).expand_as(input)) if self.scale is not None: output = output.mul(self.scale.expand_as(input)) if self.bias is not None: output = output.add(self.bias.expand_as(input)) return output def forward(self, input): return self.norm_scale_bias(F.linear(input, self.weight)) 观察上面的forward函数可以发现，TReLU添加bias这一习得参数，而weight-normalized layer中则对传入的weight进行了标准化。 论文链接：On the Effects and Weight Normalization in GAN","link":"/posts/6d3ae0a7/"},{"title":"[论文笔记]R-FCN: Object Detection via Region-based Fully Convolutinal Networks","text":"文章指出了检测任务之前的框架存在不自然的设计，即全卷积的特征提取部分+全连接的分类器，而表现最好的图像分类器都是全卷积的结构（ResNet等），这一点是由分类任务的平移不变性和检测任务的平移敏感性之间的矛盾导致的。换句话说，检测模型采用了分类模型的特征提取器，丢失了位置信息。这篇文章提出采用“位置敏感分数图”的方法解决这一问题。 Position-sensitive score maps &amp; Position-sensitive RoI Pooling位置敏感分数图的生成有两个重要操作，一是生成更“厚”的feature map，二是在RoI Pooling时选择性地输入feature map。 Faster R-CNN中，经过RPN得到RoI，转化成分类任务，还加入了一定量的卷积操作（ResNet中的conv5部分），而这一部分卷积操作是不能共享的。R-FCN则着眼于全卷积结构，利用卷积操作在Channel这一维度上的自由性，赋予其位置敏感的意义。下面是具体的操作： 在全卷积网络的最后一层，生成k^2(C+1)个Channel的Feature map，其中C为类别数，k^2代表k×k网格，用于分别检测目标物体的k×k个部分。即是用不同channel的feature map代表物体的不同局部（如左上部分，右下部分）。 将RPN网络得到的Proposal映射到上一步得到的feature map（厚度为k×k×(C+1)，）后，相应的，将RoI等分为k×k个bin，对第(i,j)个bin，仅考虑对应(i,j)位置的(C+1)个feature map，进行如下计算：其中(x0,y0)是这个RoI的锚点，得到的即是(i,j)号bin对C类别的相应分数。 经过上一步，每个RoI得到的结果是k^2(C+1)大小的分数张量，k×k编码着物体的局部分数信息，进行vote（平均）后得到(C+1)维的分数向量，再接入softmax得到每一类的概率。 上面第二步操作中“仅选取第(i, j)号feature map”是位置信息产生意义的关键。 这样设计的网络结构，所有可学习的参数都分布在可共享的卷积层，因而在训练和测试性能上均有提升。 小结R-FCN是对Faster R-CNN结构上的改进，部分地解决了位置不变性和位置敏感性的矛盾。通过最大化地共享卷积参数，使得在精度相当的情况下训练和测试效率都有了很大的提升。 论文链接：https://arxiv.org/abs/1605.06409","link":"/posts/4bcb5900/"},{"title":"[论文笔记]SSD: Single Shot MultiBox Detector","text":"IntroductionSSD是对YOLO的改进，其达到跟两阶段方法相当的精度，又保持较快的运行速度。 SSD 多尺度的feature map：基于VGG的不同卷积段，输出feature map到回归器中。这一点试图提升小物体的检测精度。 更多的anchor box，每个网格点生成不同大小和长宽比例的box，并将类别预测概率基于box预测（YOLO是在网格上），得到的输出值个数为(C+4)×k×m×n，其中C为类别数，k为box个数，m×n为feature map的大小。 ConclusionSSD有点像多分类的RPN，生成anchor box，再对box预测分数和位置调整值。 论文链接：https://arxiv.org/abs/151.023325","link":"/posts/ac9fbfcc/"},{"title":"Pandas速度优化","text":"本文主要内容取自Sofia Heisler在PyCon 2017上的演讲No More Sad Pandas Optimizing Pandas Code for Speed and Efficiency，讲稿代码和幻灯片见GitHub。 Set Up示例数据 ean_hotel_id name address1 city state_province postal_code latitude longitude star_rating high_rate low_rate 0 269955 Hilton Garden Inn Albany/SUNY Area 1389 Washington Ave Albany NY 12206 42.68751 -73.81643 3.0 154.0272 124.0216 1 113431 Courtyard by Marriott Albany Thruway 1455 Washington Avenue Albany NY 12206 42.68971 -73.82021 3.0 179.0100 134.0000 2 108151 Radisson Hotel Albany 205 Wolf Rd Albany NY 12205 42.72410 -73.79822 3.0 134.1700 84.1600 示例函数：Haversine Distancedef haversine(lat1, lon1, lat2, lon2): miles_constant = 3959 lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1, lon1, lat2, lon2]) dlat = lat2 - lat1 dlon = lon2 - lon1 a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2 c = 2 * np.arcsin(np.sqrt(a)) mi = miles_constant * c return mi 优化它之前，先测量它IPython Notebook的Magic Command: %timeit既可以测量某一行代码的执行时间，又可以测量整个单元格里代码快的执行时间。 Package: line_profiler记录每行代码的执行次数和执行时间。 在IPython Notebook中使用时，先运行%load_ext line_profiler， 之后可以用%lprun -f [function name]命令记录指定函数的执行情况。 实验对行做循环(Baseline)%%timeit haversine_series = [] for index, row in df.iterrows(): haversine_series.append(haversine(40.671, -73.985,\\ row[&apos;latitude&apos;], row[&apos;longitude&apos;])) df[&apos;distance&apos;] = haversine_series Output: 197 ms ± 6.65 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) pd.DataFrame.apply()方法%lprun -f haversine \\ df.apply(lambda row: haversine(40.671, -73.985,\\ row[&apos;latitude&apos;], row[&apos;longitude&apos;]), axis=1) Output: 90.6 ms ± 7.55 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) Timer unit: 1e-06 s Total time: 0.049982 s File: &lt;ipython-input-3-19c704a927b7&gt; Function: haversine at line 1 Line # Hits Time Per Hit % Time Line Contents ============================================================== 1 def haversine(lat1, lon1, lat2, lon2): 2 1631 1535 0.9 3.1 miles_constant = 3959 3 1631 16602 10.2 33.2 lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1, lon1, lat2, lon2]) 4 1631 2019 1.2 4.0 dlat = lat2 - lat1 5 1631 1143 0.7 2.3 dlon = lon2 - lon1 6 1631 18128 11.1 36.3 a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2 7 1631 7857 4.8 15.7 c = 2 * np.arcsin(np.sqrt(a)) 8 1631 1708 1.0 3.4 mi = miles_constant * c 9 1631 990 0.6 2.0 return mi 观察Hits这一列可以看到，apply()方法还是将函数一行行地应用于每行。 向量化：将pd.Series传入函数%lprun -f haversine haversine(40.671, -73.985,\\ df[&apos;latitude&apos;], df[&apos;longitude&apos;]) Output: 2.21 ms ± 230 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) Timer unit: 1e-06 s Total time: 0.008601 s File: &lt;ipython-input-3-19c704a927b7&gt; Function: haversine at line 1 Line # Hits Time Per Hit % Time Line Contents ============================================================== 1 def haversine(lat1, lon1, lat2, lon2): 2 1 3 3.0 0.0 miles_constant = 3959 3 1 838 838.0 9.7 lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1, lon1, lat2, lon2]) 4 1 597 597.0 6.9 dlat = lat2 - lat1 5 1 572 572.0 6.7 dlon = lon2 - lon1 6 1 5033 5033.0 58.5 a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2 7 1 1060 1060.0 12.3 c = 2 * np.arcsin(np.sqrt(a)) 8 1 496 496.0 5.8 mi = miles_constant * c 9 1 2 2.0 0.0 return mi 向量化之后，函数内的每行操作只被访问一次，达到了行结构上的并行。 向量化：将np.array传入函数%lprun -f haversine df[&apos;distance&apos;] = haversine(40.671, -73.985,\\ df[&apos;latitude&apos;].values, df[&apos;longitude&apos;].values) Output： 370 µs ± 18 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) Timer unit: 1e-06 s Total time: 0.001382 s File: &lt;ipython-input-3-19c704a927b7&gt; Function: haversine at line 1 Line # Hits Time Per Hit % Time Line Contents ============================================================== 1 def haversine(lat1, lon1, lat2, lon2): 2 1 3 3.0 0.2 miles_constant = 3959 3 1 292 292.0 21.1 lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1, lon1, lat2, lon2]) 4 1 40 40.0 2.9 dlat = lat2 - lat1 5 1 29 29.0 2.1 dlon = lon2 - lon1 6 1 815 815.0 59.0 a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2 7 1 183 183.0 13.2 c = 2 * np.arcsin(np.sqrt(a)) 8 1 18 18.0 1.3 mi = miles_constant * c 9 1 2 2.0 0.1 return mi 相比pd.Series，np.array不含索引等额外信息，因而更加高效。 小结 Methodology Avg. single run time Marginal performance improvement Looping with iterrows 184.00 - Looping with apply 78.10 2.4x Vectorization with Pandas series 1.79 43.6x Vectorization with NumPy arrays 0.37 4.8x 通过上面的对比，我们比最初的baseline快了近500倍。最大的提升来自于向量化。因而，实现的函数能够很方便地向量化是高效处理的关键。 用Cython优化Cython可以将python代码转化为C代码来执行，可以进行如下优化（静态化变量类型，调用C函数库） %load_ext cython %%cython -a # Haversine cythonized from libc.math cimport sin, cos, acos, asin, sqrt cdef deg2rad_cy(float deg): cdef float rad rad = 0.01745329252*deg return rad cpdef haversine_cy_dtyped(float lat1, float lon1, float lat2, float lon2): cdef: float dlon float dlat float a float c float mi lat1, lon1, lat2, lon2 = map(deg2rad_cy, [lat1, lon1, lat2, lon2]) dlat = lat2 - lat1 dlon = lon2 - lon1 a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2 c = 2 * asin(sqrt(a)) mi = 3959 * c return mi 嵌套于循坏中： %timeit df[&apos;distance&apos;] =\\ df.apply(lambda row: haversine_cy_dtyped(40.671, -73.985,\\ row[&apos;latitude&apos;], row[&apos;longitude&apos;]), axis=1) Output: 10 loops, best of 3: 68.4 ms per loop 可以看到，Cython确实带来速度上的提升，但效果不及向量化（并行化）。","link":"/posts/40efeb6b/"},{"title":"[论文笔记]Speed/accuracy trade-offs for modern convolutional object detectors","text":"这篇文章偏综述和实验报告的性质，前几个部分对检测模型有不错的概括，重头在实验结果部分，实验细节也描述的比较清楚，可以用来参考。 文章将检测模型分为三种元结构：Faster-RCNN、R-FCN和SSD，将特征提取网络网络独立出来作为元结构的一个部件，并松动了Proposal个数、输入图片尺寸，生成Feature map的大小等作为超参，并行实验，探索精度和速度方面的trade-off。 文章也将源码公开，作为Tensorflow的Object Detection API。 下图是三种元结构的图示： Experiments 信息量非常大的一张图。 横纵两个维度分别代表速度和准确度，横轴越靠左说明用时越少，纵轴越靠上说明mAP表现越好，因而，sweet spot应分布在左上角 两个超维是元结构和特征提取网络，元结构由形状代表，特征提取网络由颜色代表 虚线代表理想中的trade-off边界 分析： 准确度最高的由Faster-RCNN元结构、Inception-ResNet提取网络，高分图片，使用较大的feature map达到，如图右上角 较快的网络中准确度表现最好的由使用Inception和Mobilenet的SSD达到 sweet spot区特征提取网络由ResNet统治，较少Proposal的Faster-RCNN可以跟R-FCN相当 特征提取网络方面，Inception V2和MobileNet在高速度区，Incep-ResNet和ResNet在sweet spot和高精度区，Inception V3和VGG则远离理想边界（虚线） 上图是特征提取网络对三种元结构的影响，横轴是特征提取网络的分类准确率，纵轴是检测任务上的mAP表现，可以看到，SSD在纵轴方向上方差最小，而Faster-RCNN和R-FCN对特征提取网络更为敏感。 上图的横轴是不同的特征提取网络，组内是三种元结构的对比，纵轴是不同尺寸物体的mAP。 可以看到，在大物体的检测上，使用较小的网络时，SSD的效果跟两阶段方法相当，更深的特征提取网络则对两阶段方法的中型和小型物体的检测提升较大（ResNet101和Incep-ResNet都显现了两阶段方法在小物体上的提升） 上图显示了输入图片尺寸对mAP的影响。高分的图片对小物体检测帮助明显，因而拥有更高的精度，但相对运行速度会变慢。 上图探究了两阶段方法中Proposal个数的影响，左边是Faster-RCNN，右边是R-FCN，实线是mAP，虚线是推断时间。分析： 相比R-FCN，Faster-RCNN推断时间对Proposal个数相当敏感（因为有per ROI的计算） 减少Proposal的个数，并不会给精度带来致命的下降 上面两图是对FLOPS的记录，相对GPU时间更为中立，在图8中，GPU部分显现了ResNet跟Inception的分野（关于45度线，此时FLOPS跟GPU时间相当），文章认为分解操作(Factorization)减少了FLOPs，但增加了内存的IO时间，或者是GPU指令集更适合密集的卷积计算。 上两图是对内存占用的分析，总体来说，特征提取网络越精简、feature map尺寸越小，占用内存越少，运行时间也越短。 最后，文章描述了他们ensemble的思路，在一系列不同stride、loss和配置的Faster-RCNN中（ResNet和Incep-ResNet为特征提取网络），贪心地选择验证集上AP较高的，并且去除类AP相似的模型。选择的5个用于ensemble的模型如下： Conclusion这篇文章是不错的实验结果报告，测试了足够多的模型，也得出了合理的和有启发的结论。几点想法： RFCN并没有很好的解决定位跟分类的矛盾，per ROI的子网络最好还是要有，但要限制Proposal的个数（实际大部分都是负样本）来减少冗余 小物体的检测仍然是最大的难点，增大分辨率和更深的网络确有帮助，但不是实质的。 论文链接： https://arxiv.org/abs/1611.10012","link":"/posts/b58d5aab/"},{"title":"[论文笔记](R-CNN)Rich feature hierarchies for accurate object detection and semantic segmentation","text":"R-CNN系列的开山之作，2-stage的想法至今仍是精确度优先方法的主流。而且，本文中的众多做法也成为检测任务pipeline的标准配置。 摘要中提到的两大贡献：1）CNN可用于基于区域的定位和分割物体；2）监督训练样本数紧缺时，在额外的数据上预训练的模型经过fine-tuning可以取得很好的效果。 第一个贡献影响了之后几乎所有2-stage方法，而第二个贡献中用分类任务（Imagenet）中训练好的模型作为基网络，在检测问题上fine-tuning的做法也在之后的工作中一直沿用。 IntroFeatures Matter. Traditional hand-design feature(SIFT, HOG) -&gt; Learned feature(CNN). 从图像识别的经验来看，CNN网络自动习得的特征已经超出了手工设计的特征。 解决检测任务中的定位问题：”recognition using regions”，即基于区域的识别（分类）。 检测任务中样本不足的问题（对大型网络）：在大数据集上预训练分类模型，在小数据集上fine-tuning检测任务。 Object Detection with R-CNNRegion Proposal: Selective Search Feature Extraction: AlexNet(NIPS 2012), 4096-dim feature vector from every region proposal Training现在ILSVRC2012上预训练达到STOA，再在Pascal VOC上fine-tuning。根据IOU来给region proposal打标签，在每个batch中保持一定的正样本比例（背景类非常多）。这些都已成为标准做法，后续很多工作也是对这些细节进行改进（OHEM等）。 文章中特别提到，IOU的选择（即正负样例的标签准备）对结果影响显著，这里要谈两个threshold，一个用来识别正样本（IOU跟ground truth较高），另一个用来标记负样本（即背景类），而介于两者之间的则为hard negatives，若标为正类，则包含了过多的背景信息，反之又包含了要检测物体的特征，因而这些proposal便被忽略掉。 另一个重要的问题是bounding-box regression，这一过程是proposal向ground truth调整，实现时加入了log/exp变换来使loss保持在合理的量级上。 ConclusionR-CNN的想法直接明了，即是将CNN在分类上取得的成就运用在检测上，是深度学习方法在检测任务上的试水。模型本身存在的问题也很多，如需要训练三个不同的模型（proposal, classification, regression）、重复计算过多导致的性能问题等。尽管如此，这篇论文的很多做法仍然广泛地影响着检测任务上的深度模型革命，后续的很多工作也都是针对改进文章中的pipeline而展开，此篇可以称得上”the first paper”。 论文链接：https://arxiv.org/abs/1311.2524","link":"/posts/415f4992/"},{"title":"[论文笔记](OHEM)Training Region-based Object Detectors with Online Hard Example Mining","text":"Training Region-based Object Detectors with Online Hard Example Mining OHEM(Online Hard negative Example Mining，在线难例挖掘)本文是Bootstrapping（自助采样）在深度网络中的应用。两阶段网络由于其多步的特性，在RCNN子网络的计算前会有对RoI的整理过程，早期工作中，Fast R-CNN利用随机上采样和下采样的方法来维持正负样本比例，而本文提出的方法则使得网络具有挑选“好的”正负样本的能力。 作者提出用R-CNN子网络对RoI Proposal预测的分数来决定每个batch选用的样本，这样，输入R-CNN子网络的RoI Proposal总为其表现不好的样本，提高了监督学习的效率。实际操作中，维护两个完全相同的R-CNN子网络，其中一个只进行前向传播来为RoI Proposal的选择提供指导，另一个则为正常的R-CNN，参与损失的计算并更新权重，并且将权重复制到前者以使两个分支权重同步。 OHEM以额外的R-CNN子网络的开销来改善RoI Proposal的质量，更有效地利用数据的监督信息，成为两阶段模型提升性能的常用部件之一。","link":"/posts/a1e87dc9/"},{"title":"[论文笔记]MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications","text":"MobileNets系列可以看做是继Xception之后对Depthwise Separable Convolution的又一推动。利用深度可分离的特征，MobileNets系列引入两个模型精度和大小的超参，在保持相当精度的同时享有非常小的计算消耗，适用于移动端情形，因而被命名为”MobileNets”。 Depthwise Separable Convolution深度可分离卷积是近期深度网络设计的重要趋势。最早见于L. Sifre的PhD论文Rigid-motion scattering for image classification，其1×1卷积在Inception, ResNet, SqueezeNet等网络中作为降维bottleneck使用。Xception指出，Inception单元本质上假设了跨通道和跨空间相关性的解耦关系，并将这一解耦关系推向极端，用Depthwise Separable Convolution改造了Inception结构。 深度可分离卷积受欢迎的另一重要原因是其参数高效性。将原有卷积换成深度可分离卷积后，可以享受到模型压缩的增益。 标准的卷积操作，可以认为是大小为DK的窗口在DF大小的特征图上滑动计算，计算复杂性为： DK×DK × M×N × DF×DF 其中，M和N分别代表输入channel数和输出channel数。 替换为深度可分离卷积后，先进行Depthwise Convolution，再进行1×1 Pointwise Convolution，计算复杂性为： DK×DK × M × DF×DF + M×N × DF×DF 相比下，深度可分离卷积的计算复杂性约为原来的(1/N+1/DK^2)。 进一步地，MobileNet添加两个超参来控制这一压缩程度，alpha为channel数压缩系数，rho为分辨率压缩系数： DK×DK × alpha×M × rho×DF× rho×DF + alpha×M × alpha×N × rho×DF × rho×DF ArchitectureMobileNet的基本结构如下： 论文链接：https://arxiv.org/abs/1704.04861","link":"/posts/ae26dc1c/"},{"title":"[论文笔记]YOLO9000: Better, Faster, Stronger","text":"YOLO9000: Better, Faster, Stronger 在这篇文章里，单阶段检测模型的先驱工作YOLO迎来了全面的更新： 在卷积层添加BN，舍弃Dropout 更高尺寸的输入 使用Anchor Boxes，并在头部运用卷积替代全连接层 使用聚类方法得到更好的先验，用于生成Anchor Boxes 参考Fast R-CNN的方法对位置坐标进行log/exp变换使坐标回归的损失保持在合适的数量级 passthrough层：类似ResNet的skip-connection，将不同尺寸的feature map拼接到一起 多尺度训练 更高效的网络Darknet-19，类似VGG的网络，在ImageNet上以较少的参数量达到跟当前最佳相当的精度 此次改进后，YOLOv2吸收了很多工作的优点，达到跟SSD相当的精度和更快的推断速度。 作者还介绍了一种新的联合训练方式：同时训练分类任务和检测任务，使得检测模型能够泛化到检测训练集之外的目标类上。 YOLO9000使用了ImageNet和COCO数据集联合训练，在合并两者的标签时，根据WordNet的继承关系构建了了树状的类别预测图： 类似条件概率的方式计算每个子标签的概率值，超出一定的阈值时则选定该类作为输出，训练时也仅对其路径上的类别进行损失的计算和BP。 YOLO9000为我们提供了一种泛化检测模型的训练方式，文章的结果显示YOLO9000在没有COCO标注的类别上有约20的mAP表现，能够检测的物体类别超过9000种。当然，其泛化性能也受检测标注类别的制约，在有类别继承关系的类上表现不错，而在完全没有语义联系的类上表现很差。","link":"/posts/16826395/"},{"title":"[论文笔记]Visualizing and Understanding Recurrent Networks","text":"论文： Visualizing and Understanding Recurrent Networks 实验设定字母级的循环神经网络，用Torch实现，代码见GitHub。字母嵌入成One-hot向量。优化方面，采用了RMSProp算法，加入了学习速率的decay和early stopping。 数据集采用了托尔斯泰的《战争与和平》和Linux核心的代码。 可解释性激活的例子$tanh$函数激活的例子，$-1$为红色，$+1$为蓝色。 上图分别是记录了行位置、引文和if语句特征的例子和失败的例子。 上图分别是记录代码中注释、代码嵌套深度和行末标记特征的例子。 Gates数值的统计 此图信息量很大。 left-saturated和right-saturated表示各个Gates激活函数（$sigmoid$）小于0.1和大于0.9，即总是阻止信息流过和总是允许信息流过。 横轴和纵轴表示该Gate处于这两种状态的时间比例，即有多少时间是阻塞状态，有多少时间是畅通状态。 三种颜色表示不同的层。 有以下几个观察： 第一层的门总是比较中庸，既不阻塞，也不畅通 第二三层的门在这两种状态间比较分散，经常处于畅通状态的门可能记录了长期的依赖信息，而经常处于阻塞状态的门则负责了短期信息的控制。 错误来源分析在这一节，作者用了“剥洋葱”的方法，建立了不同的模型将错误进行分解。此处错误指LSTM预测下一个字母产生的错误，数据集为托尔斯泰的《战争与和平》。 n-gram Dynamic n-long memory，即对已经出现过得单词的复现。如句子”Jon yelled atMary but Mary couldn’t hear him.”中的Mary。 Rare words，不常见单词 Word model，单词首字母、新行、空格之后出现的错误 Punctuation，标点之后 Boost，其他错误 根据作者的实验，错误的来源有如下分解： 小结这篇文章是打开LSTM黑箱的尝试，提供了序列维度上共享权值的合理性证据，对Gates状态的可视化也非常值得关注，最后对误差的分解可能对新的网络结构有所启发（比如，如何将单词级别和字母级别的LSTM嵌套起来，解决首字母预测的问题？）。","link":"/posts/b33e18de/"},{"title":"[论文笔记]Xception: Deep Learning with Depthwise Seperable Convolutions","text":"本篇是keras库作者的文章，对Inception结构进行了改进：用Depth-wise seperable convolution替换了Inception单元中的1×1卷积和3×3卷积。 文章对Inception结构的评论非常有见地。 Motivation文章指出，Inception单元背后的假设是跨Channel和跨空间的相关性可以充分解耦，类似的还有长度和高度方向上的卷积结构（在Inception-v3里的3×3卷积被1×3和3×1卷积替代）。 进一步的，Xception基于更强的假设：跨channel和跨空间的相关性完全解耦。这也是Depthwise Separable Convolution所建模的理念。 一个简化的Inception单元： 等价于： 将channel推向极端，即每个channel都由独立的3×3卷积处理： 这样就得到了Depthwise Separable Convolution。 Architectrue简单讲，Xception是线性堆叠的Depthwise Separable卷积，附加了Skip-connection。 NetScope Vis请参见这里，源文件位于awesome_cnn。 Experiments本文的实验部分并没有像其他论文那样集成一个在ImageNet上SOTA的结果，而是以Inception-v3为基线，对比了参数数量和性能，认为提升正来自于更合理的参数利用。文章还对比了Residual的作用，在Xception网络中，Skip-connection不仅能提高训练速度，还能增强模型的性能。 Concolusion本文贡献主要对Inception单元的解读和引入Depthwise Seperable Convolution。更多对于Depthwise Seperable Convolution的描述，请参考MobileNets的笔记。 论文链接：https://arxiv.org/abs/1610.02357","link":"/posts/3b214d12/"},{"title":"论文阅读心得","text":"本博客记录了不少我在读文章时所作的笔记，但质量普遍不高，本文是我对科技类论文阅读和记笔记习惯的反思，也是对自己日后笔记的要求。 研究生的三种能力 从无组织的只是种检索、筛选、组织知识的能力 对一切既有进行精确批判的独立自主判断能力 创造新知识的能力 科技类文章的主要内容领域综述/论文中的工作引述部分1A）这个领域最常被引述的方法有哪些1B）这些方法可以被分为哪些主要派别1C）每个派别的主要特色（优点和缺点）是什么1D）这个领域大家认为的关键问题有哪些，有哪些特性是大家重视的优点，哪些特性是大家重视的缺点，这些特性在哪些场景下受重视 单项工作2A）这项工作的主要假设是什么，这些假设在现实情况下有多难/容易成立2B）在这些假设下，这项工作的优点是什么2C）这些优点主要体现在哪里2D）这项工作的缺点是什么2E）这项工作（这个派别的方法）适用的场合有哪些 读文章的原则/技巧 整批读文献，利用互相引述的信息，不同工作之间的评论常常比作者自己的评论更有价值 只需要了解到自己所需的知识粒度，忌事无巨细，即在读的过程中不断调整自己的期待和目的 笔记/论文报告应该包含的内容介绍部分（如何将文章转述清楚）1）研究的问题，工业界相关2）主要假设、主要公式、应用方式 评价（如何全面客观评定这项工作的贡献）1）最主要的创意/贡献2）创意/共享带来的好处3）这些好处在哪些条件下成立（适用的范围）4）最主要的缺点/局限5）缺点/局限带来的坏处6）缺点/局限因为哪些因素引入的 CV类文章阅读顺序 摘要中对于方法叙述和效果描述的关键性语句 在标准评测集上的效果，消融实验(Ablation Study)的说服力（基本判定是否需要进一步阅读） 正文中方法描述，做法的解释，网络结构的设计等 实验细节的描述 背景调研等","link":"/posts/ad2d3bed/"},{"title":"[论文笔记]You Only Look Once: Unified, Real Time Object Detection","text":"YOLO是单阶段方法的开山之作。它将检测任务表述成一个统一的、端到端的回归问题，并且以只处理一次图片同时得到位置和分类而得名。 YOLO的主要优点： 快。 全局处理使得背景错误相对少，相比基于局部（区域）的方法， 如Fast RCNN。 泛化性能好，在艺术作品上做检测时，YOLO表现好。 DesignYOLO的大致工作流程如下：1.准备数据：将图片缩放，划分为等分的网格，每个网格按跟ground truth的IOU分配到所要预测的样本。2.卷积网络：由GoogLeNet更改而来，每个网格对每个类别预测一个条件概率值，并在网格基础上生成B个box，每个box预测五个回归值，四个表征位置，第五个表征这个box含有物体（注意不是某一类物体）的概率和位置的准确程度（由IOU表示）。测试时，分数如下计算： 等式左边第一项由网格预测，后两项由每个box预测，综合起来变得到每个box含有不同类别物体的分数。因而，卷积网络共输出的预测值个数为S×S×(B×5+C)，S为网格数，B为每个网格生成box个数，C为类别数。3.后处理：使用NMS过滤得到的box Loss 图片来自https://zhuanlan.zhihu.com/p/24916786 损失函数被分为三部分：坐标误差、物体误差、类别误差。为了平衡类别不均衡和大小物体等带来的影响，loss中添加了权重并将长宽取根号。 Error Analysis 相比Fast-RCNN，YOLO的背景误检在错误中占比重小，而位置错误占比大（未采用log编码）。 LimitationsYOLO划分网格的思路还是比较粗糙的，每个网格生成的box个数也限制了其对小物体和相近物体的检测。 ConclusionYOLO提出了单阶段的新思路，相比两阶段方法，其速度优势明显，实时的特性令人印象深刻。 论文链接：https://arxiv.org/abs/1506.02640","link":"/posts/41036331/"},{"title":"[论文笔记](Inception V3)Rethinking the Inception Architecture for Computer Vision","text":"本文是作者推进inception结构的第2.5步。在更早的文章里，同一作者提出Batch Normalization并且用来改进了Inception结构，称为Inception-BN。而在这篇文章里，作者提出了Inception-v2和Inception-v3，两者共享同一网络结构，v3版本相比v2版本加入了RMSProp，Label Smoothing等技巧。 文章表述了Inception系列的几个设计原则，并根据这些原则改进了GoogLeNet的结构。 General Design Principles Avoid representational bottlenecks, especially early in the network. 建议不要在过浅的阶段进行特征压缩，而维度只是一个表达复杂性的参考，并不能作为特征复杂性的绝对衡量标准。 Higher dimensional representations are easier to process locally with a network. 高阶的表示更有局部描述力，增加非线性有助于固化这些描述力。 Spatial aggregation can be done over lower dimensional embeddings without much or any loss in representational power. 基于空间的聚合信息可以在低维空间里处理，而不必担心有太多信息损失。这一点也佐证了1×1卷积的降维作用。 Balance the width and depth of the network. 宽度和深度的增加都有助于网络的表达能力，最好的做法是同时在这两个方向上推进，而非只顾及一个。 Factorizing Convolution分解一直是计算数学里经典的思路。从牛顿法到BFGS，就是把Hessian矩阵（或其逆）用一系列的向量操作来表示和近似，避免矩阵的计算。 本文提出了两种卷积结构方面的分解，一个是在卷积核的层面，另一个是在空间方面。 第一种分解是将大核卷积分解成串联的小核卷积。 用两个3×3的卷积代替5×5的卷积，带来的参数减少为(9+9)/(5×5). 第二种分解是在卷积核本身上，引入非对称卷积：用3×1和1×3的卷积串联代替3×3卷积。如下图所示。 这种分解也可以推广到n维情况，且n越大，带来的收益越明显。 空间上的卷积分解建模了这样的情形：两个方向上的卷积参数互相正交，便被空间分解卷积解耦。 Utility of Auxiliary Classifiers在GoogLeNet中，作者用loss监督了低维的特征图的学习，但进一步的实验发现，加入BN层后，这些增益被抵消了，于是Auxiliary Classifier可被看做是某种正则化技术，在加入BN的网络中便不再应用。 Efficient Grid Size Reduction这一节讨论网络中的特征降维，即下采样的过程，通常由卷积层或Pooling层的stride参数控制。文章为避免原则一中提到的Representation Bottleneck，在进行Pooling之前将网络加宽（通过Channel数的增加），这也对应了平衡宽度和深度的原则。 最终结合了Inception结构和下采样需求的单元如下： 不同于Inception单元，上面的1×1卷积扩展了Channel，并且3×3卷积采用了stride=2。 Inception-v2 &amp; Inception-v3 Architecture 可以看到随深度增加，Channel数也在扩展，而Inception单元也遵从了堆叠的范式。 其中三种Inception单元分别为： 另外，也可以查看NetScope Vis来熟悉Inception-v3的结构，源文件位于awesome_cnn。 Experiments下面是Inception结构演化带来的增益分解： Conclusion本篇是对Inception系网络的推进，其分解的思想成为又一网络设计的指导原则。 对卷积的进一步理解，可以参考这个页面，这一工具可视化了不同卷积核对输入的处理，给出的例子都是在早期人们手工设计的滤波器，而深度网络隐式地学习到了这些滤波器的卷积表达。 论文链接：https://arxiv.org/abs/1512.00567","link":"/posts/5e3f4a2c/"},{"title":"[论文笔记]Faster R-CNN: Towards Real Time Object Detection with Region Proposal Networks","text":"Faster R-CNN是2-stage方法的主流方法，提出的RPN网络取代Selective Search算法使得检测任务可以由神经网络端到端地完成。粗略的讲，Faster R-CNN = RPN + Fast R-CNN，跟RCNN共享卷积计算的特性使得RPN引入的计算量很小，使得Faster R-CNN可以在单个GPU上以5fps的速度运行，而在精度方面达到SOTA。 Regional Proposal Networks RPN网络将Proposal这一任务建模为二分类的问题。 第一步是在一个滑动窗口上生成不同大小和长宽比例的anchor box，取定IOU的阈值，按Ground Truth标定这些anchor box的正负。于是，传入RPN网络的样本即是anchor box和每个anchor box是否有物体。RPN网络将每个样本映射为一个概率值和四个坐标值，概率值反应这个anchor box有物体的概率，四个坐标值用于回归定义物体的位置。最后将二分类和坐标回归的Loss统一起来，作为RPN网络的目标训练。 RPN网络可调的超参还是很多的，anchor box的大小和长宽比例、IoU的阈值、每张图片上Proposal正负样本的比例等。 Alternate Training RPN网络是在feature map上进行的，因而可以跟RCNN完全共享feature extractor部分的卷积运算。训练时，RPN和RCNN的训练可以交替进行，即交替地固定RPN和RCNN部分的参数，更新另一部分。 小结Faster R-CNN的成功之处在于用RPN网络完成了检测任务的“深度化”。使用滑动窗口生成anchor box的思想也在后来的工作中越来越多地被采用（YOLO v2等）。RPN网络也成为检测2-stage方法的标准部件。 论文链接：https://arxiv.org/abs/1506.01497","link":"/posts/886932ed/"},{"title":"[论文笔记]On-the-fly Operation Batching in Dynamic Computation Graphs","text":"基于动态图的深度学习框架如Pytorch,DyNet提供了更为灵活的结构和数据维度的选择，但要求开发者自行将数据批量化，才能最大限度地发挥框架的并行计算优势。 当前的状况：灵活的结构与高效计算左图为循环结构，右图将序列补齐，批量化 灵活的结构和数据输入维度，采用朴素的循环结构实现，但不高效，因为尽管维度不同，在循环内数据接受的是同样的操作。 对数据做“Padding”，即用傀儡数据将输入维度对齐，进而实现向量化，但这种操作对开发者并不友好，会使开发者浪费掉很多本该投入到结构设计等方面的精力。 本文提出的方法三个部分 Graph Definition Operation Batching Computation 第一步和第三步在当前已被大部分深度学习框架较好地实现。主要特点是，构建计算图与计算的分离，即”Lazy Evaluation”。比如在Tensorflow中，一个抽象层负责解析计算图各节点之间的依赖，决定执行计算的顺序，而另一个抽象层则负责分配计算资源。 Operation BatchingComputing compatibility groups这一步是建立可以批量化计算的节点组。具体做法是，给每一个计算节点建立 signature，用于描述节点计算的特性，文中举出了如下几个例子: Component-wise operations: 直接施加在每个张量元素上的计算，跟张量的维度无关，如$tanh$,$log$ Dimension-sensitive operations: 基于维度的计算，如线性传递$Wh+b$，要求$W$和$h$维度相符，signature 中要包含维度信息 Operations with shared elements: 包含共享元素的计算，如共享的权值$W$ Unbatchable operations: 其他 Determining execution order执行顺序要满足两个目标： 每一节点的计算要在其依赖之后 带有同样 signature 且没有依赖关系的节点放在同一批量执行 但在一般情况下找到最大化批量规模的执行顺序是个NP问题。有如下两种策略： Depth-based Batching: 库Tensorflow Fold中使用的方法。某一节点的深度定义为其子节点到其本身的最大长度，同一深度的节点进行批量计算。但由于输入序列长度不一，可能会错失一些批量化的机会。 Agenda-based Batching: 本文的方法，核心的想法是维护一个 agenda 序列，所有依赖已经被解析的节点入列，每次迭代时从 agenda 序列中按 signature 相同的原则取出节点进行批量计算。 实验文章选取了四个模型：BiLSTM, BiLSTM w/char, Tree-structured LSTMs, Transition-based Dependency Parsing。 实验结果：（单位为Sentences/second） 小结本来读到题目还是蛮惊喜的，期待的是从模型构建的角度解决序列长度不一带来的计算上的不便。但通读下来发现是在计算图的计算这一层面进行的优化，有些失望但也感激，作者使用DyNet框架实现了他们的方法，希望自己也可以为Pytorch等框架该算法的实现出一份力。 感谢这些开源的框架，正一步步拉近人类构建模型和机器高效计算之间的距离。 论文链接：On-the-fly Operation Batching in Dynamic Computaion Graphs","link":"/posts/f021f857/"},{"title":"[论文笔记](GoogLeNet)Going deeper with convolutions","text":"本作是Inception系列网络的第一篇，提出了Inception单元结构，基于这一结构的GoogLeNet拿下了ILSVRC14分类任务的头名。文章也探讨了网络在不断加深的情况下如何更好地利用计算资源，这一理念也是Inception系列网络的核心。 MotivationInception单元的启发主要来自Network in Network结构和Arora等人在神经科学方面的工作。 提高深度模型的一个简单想法是增加深度，但这样带来过拟合的风险和巨大的计算资源消耗，对数据量和计算力的要求可能会超过网络加深带来的收益。 解决这些问题的基本思路是使用稀疏连接的网络，而这也跟Arora等人工作中的Hebbian principle吻合：共同激活的神经元常常集聚在一起。换句话说，某一层激活的神经元只向下一层中特定的几个神经元传递激活信号，而向其他神经元几乎不传递信息，即仅有少部分连接是真正有效的，这也是稀疏的含义。 然而另一方面，现代计算架构对稀疏的计算非常低效，更适合的是密集的计算，这样便产生了矛盾。而Inception单元的提出就是为了用密集的结构来近似稀疏结构，在建模稀疏连接的同时又能利用密集计算的优势。 很多文章认为inception结构的意义在于将不同大小核的卷积并行连接，然后让网络自行决定采用哪种卷积来提取特征，有些无监督的意味，然后将1×1的卷积解释为降维操作。这种想法有待验证，是否在5×5卷积有较强激活的时候，3×3卷积大部分没有激活，还是两者能够同时有较强的激活？不同的处理阶段这两种卷积核的选择有没有规律？ 在此提出一个个人的理解，欢迎讨论。 首先是channel的意义。我们知道，卷积之所以有效，是因为它建模了张量数据在空间上的局部相关性，加之Pooling操作，将这些相关性赋予平移不变性（即泛化能力）。而channel则是第三维，它实际上是卷积结构中的隐藏单元，是中间神经元的个数。卷积层在事实上是全连接的：每个Input channel都会和output channel互动，互动的信息只不过从全连接层的weight和bias变成了卷积核的weight。 这种全连接是冗余的，本质上应是一个稀疏的结构。Inception单元便在channel这个维度上做文章，采用的是类似矩阵分块的思想。 根据Hebbian principle，跨channel的这些神经元，应是高度相关的，于是有信息压缩的空间，因而使用跨channel的1×1的卷积将它们嵌入到低维的空间里（比如，Inception4a单元的输入channel是512，不同分支的1×1卷积输出channel则是192,96,16和64，见下面GoogLeNet结构表），在这个低维空间里，用密集的全连接建模（即3×5和5×5卷积），它们的输出channel相加也再恢复到原来的输入channel维度（Inception4a分别是192+208+48+64），最后的连接由Concat操作完成（分块矩阵的合并），这样就完成了分块密集矩阵对稀疏矩阵的近似。 这样来看，3×3和5×5大小的选择并不是本质的，本质的是分块低维嵌入和concat的分治思路。而在ResNeXt的工作中，这里的分块被认为是新的维度（称为cardinality），采用相同的拓扑结构。 Stacked Inception Module在GoogLeNet中，借鉴了AlexNet和VGG的stack(repeat)策略，将Inception单元重复串联起来，构成基本的特征提取结构。 Dimension Reduction朴素版本的Inception单元会带来Channel维数的不断增长，加入的1×1卷积则起到低维嵌入的作用，使Inception单元前后channel数保持稳定。 Auxililary Classifier这里是本文的另一个贡献，将监督信息传入中间的feature map，构成一个整合loss，作者认为这样有助于浅层特征的学习。 Architecture of GoogLeNet下面的表显示了GoogLeNet的整体架构，可以留意到Inception单元的堆叠和Channel数在子路径中的变化。NetScope可视化可参见GoogLeNet Vis。源文件位于awesome_cnn。 Conclusion文章是对NiN思想的继承和推进，不同于AlexNet和VGG，网络的模块化更加凸显，多路径的结构也成为新的网络设计范本，启发了众多后续网络结构的设计。","link":"/posts/6b8a6ed1/"}],"tags":[{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"async","slug":"async","link":"/tags/async/"},{"name":"Programming","slug":"Programming","link":"/tags/Programming/"},{"name":"Chrome OS","slug":"Chrome-OS","link":"/tags/Chrome-OS/"},{"name":"Software","slug":"Software","link":"/tags/Software/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"AI","slug":"AI","link":"/tags/AI/"},{"name":"Pytorch","slug":"Pytorch","link":"/tags/Pytorch/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/tags/Deep-Learning/"},{"name":"Dropout","slug":"Dropout","link":"/tags/Dropout/"},{"name":"Drivative","slug":"Drivative","link":"/tags/Drivative/"},{"name":"Digital Life","slug":"Digital-Life","link":"/tags/Digital-Life/"},{"name":"Reading","slug":"Reading","link":"/tags/Reading/"},{"name":"Blog","slug":"Blog","link":"/tags/Blog/"},{"name":"Individual Development","slug":"Individual-Development","link":"/tags/Individual-Development/"},{"name":"Tutorial","slug":"Tutorial","link":"/tags/Tutorial/"},{"name":"LSTM","slug":"LSTM","link":"/tags/LSTM/"},{"name":"Mac","slug":"Mac","link":"/tags/Mac/"},{"name":"Apps","slug":"Apps","link":"/tags/Apps/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"},{"name":"R","slug":"R","link":"/tags/R/"},{"name":"Data Science","slug":"Data-Science","link":"/tags/Data-Science/"},{"name":"Tensorflow","slug":"Tensorflow","link":"/tags/Tensorflow/"},{"name":"RSS","slug":"RSS","link":"/tags/RSS/"},{"name":"Derivative","slug":"Derivative","link":"/tags/Derivative/"},{"name":"Gnome","slug":"Gnome","link":"/tags/Gnome/"},{"name":"OpenWrt","slug":"OpenWrt","link":"/tags/OpenWrt/"},{"name":"archive","slug":"archive","link":"/tags/archive/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"Papers","slug":"Papers","link":"/tags/Papers/"},{"name":"Writing","slug":"Writing","link":"/tags/Writing/"},{"name":"Keras","slug":"Keras","link":"/tags/Keras/"},{"name":"Research","slug":"Research","link":"/tags/Research/"},{"name":"Visualization","slug":"Visualization","link":"/tags/Visualization/"},{"name":"Vestacp","slug":"Vestacp","link":"/tags/Vestacp/"},{"name":"Blogging","slug":"Blogging","link":"/tags/Blogging/"},{"name":"Object Detection","slug":"Object-Detection","link":"/tags/Object-Detection/"},{"name":"Computer Vision","slug":"Computer-Vision","link":"/tags/Computer-Vision/"},{"name":"R-CNN","slug":"R-CNN","link":"/tags/R-CNN/"},{"name":"YOLO","slug":"YOLO","link":"/tags/YOLO/"},{"name":"Refactoring","slug":"Refactoring","link":"/tags/Refactoring/"},{"name":"Review","slug":"Review","link":"/tags/Review/"},{"name":"TV Show","slug":"TV-Show","link":"/tags/TV-Show/"},{"name":"CNN","slug":"CNN","link":"/tags/CNN/"},{"name":"Optimization","slug":"Optimization","link":"/tags/Optimization/"},{"name":"Mobile","slug":"Mobile","link":"/tags/Mobile/"},{"name":"autoML","slug":"autoML","link":"/tags/autoML/"},{"name":"GAN","slug":"GAN","link":"/tags/GAN/"},{"name":"RNN","slug":"RNN","link":"/tags/RNN/"},{"name":"Inception","slug":"Inception","link":"/tags/Inception/"}],"categories":[{"name":"Programming","slug":"Programming","link":"/categories/Programming/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"AI","slug":"AI","link":"/categories/AI/"},{"name":"Individual Development","slug":"Individual-Development","link":"/categories/Individual-Development/"},{"name":"Data Science","slug":"Data-Science","link":"/categories/Data-Science/"},{"name":"Papers","slug":"Papers","link":"/categories/Papers/"},{"name":"Internet","slug":"Internet","link":"/categories/Internet/"},{"name":"Reviews","slug":"Reviews","link":"/categories/Reviews/"}]}